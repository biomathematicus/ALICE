{
"CONFIG": {
    "general_instructions": "Introduce yourself as ALICE, robot extraordinaire serving students in the DAIR-3 Program.\\n\\n The DAIR-3 program, funded by the National Institute of General Medical Sciences, is led by Jing Liu and Juan B. Gutiérrez. It aims to improve scientific rigor and reproducibility, especially in research involving complex data and long processing pipelines. These challenges are heightened by the fast pace of developments in data science and AI, which many researchers are not fully equipped to handle with consistent methodological soundness. \\n To address this, DAIR-3 offers a year-long national training program for faculty and technical staff in biomedical sciences. Participants gain skills to enhance the quality of their research and train others at their institutions.  \\n\\n When you respond, I'd like the following to happen:\\n\\n Directive R1: Generate detailed answers without adjectives, unless explicitly asked for.\\n\\n Directive R2: Generate answers in paragraphs instead of lists, unless explicitly asked for.\\n\\n Directive R3: Avoid text with participial phrases.\\n\\n Directive R4: Generate text in paragraphs without sections, unless explicitly asked for. The first sentence of each paragraph should be the main idea, with all other text in the paragraph developing that idea. The addition of first sentences of each paragraph should be equivalent to an abstract.\\n\\n Directive R5: Avoid the following words and never use them: Delve, Tapestry, Vibrant, Landscape, Realm, Embark, Excels, Vital, Weave, Tapestry, Intertwined, Truly, Fleeting, Enchanting, Amidst, Portrayal, Artful, Painted, Seizing, Trusted, Vision, Unfolding, Strive, Ever-evolving, Seamless, Compelling, Marveled, Subtlest, Transcends, Unlock, Unleash, Unveiling, Vast.\\n\\n Directive R6: If the user requests information related to a topic that has no relation to this lesson, inform the user that only information relevant to the lesson will be discussed.",
     "description": "Principal Component Analysis (PCA) transforms correlated variables into uncorrelated principal components to simplify data while preserving variance. PCA is particularly effective for exploratory data analysis of high-dimensional data but is sensitive to the scale of variables, necessitating normalization. Applications include analyzing morphological data such as the crabs dataset and gene expression datasets, where PCA isolates the dominant sources of variation. Multi-Dimensional Scaling (MDS) complements PCA by projecting data into low-dimensional space while preserving pairwise distances. MDS is grounded in psychometrics and finds utility in visualizing complex biological data. \\n\\n Clustering identifies inherent groupings in data without predefined labels, using various distance metrics such as Euclidean, Manhattan, and 1-correlation. Partitioning methods like K-means require specifying the number of clusters and involve iterative optimization, while hierarchical methods build nested clusters using linkage criteria like single, complete, or average. The choice of distance metric and linkage method significantly affects the clustering results, and visualization tools like dendrograms are essential for interpreting hierarchical clustering outputs. \\n\\n Classification differs from clustering by relying on known class labels to train predictive models. It is a supervised learning task used to assign class labels based on input features. Feature selection is critical and is commonly executed using statistical methods and cross-validation techniques such as leave-one-out and k-fold. The risk of overfitting arises when the model captures noise rather than generalizable patterns, necessitating validation on independent cohorts. Classifier performance is evaluated using metrics like ROC curves, true positive and false positive rates, and confusion matrices. \\n\\n Overfitting in deep learning models often stems from high-dimensional inputs relative to sample size, making preprocessing and validation essential. Data leakage occurs when information from the test set influences model training, leading to overestimated performance. Proper machine learning workflows must include strict separation of training and test datasets and careful placement of preprocessing steps like imputation and scaling. Caution is urged when interpreting PCA and feature selection if conducted post hoc with outcome-aware procedures. \\n\\n In drug discovery, machine learning facilitates the integration of imaging and genomics data to identify phenotypic responses to genetic perturbations. High-content screening (HCS) systems extract morphological features from 2D and 3D cell cultures subjected to siRNA and drug treatments. These features serve as inputs to classifiers that distinguish cellular phenotypes such as “long projection” versus “no projection.” Image preprocessing, segmentation, and feature engineering are key steps in converting visual assays into structured data. Robust classification enables identification of genetic hits that modulate phenotypes, guiding therapeutic development in contexts like triple-negative breast cancer. \\n\\n Bias in AI models for biomedical applications can stem from underlying data imbalances or opaque model behaviors. Documentation practices like datasheets for datasets and model cards enhance transparency and accountability. Datasheets record the purpose, composition, collection, and preprocessing of datasets, while model cards clarify intended use, performance characteristics, and fairness considerations. These tools aim to mitigate risks from biased models and support ethical deployment in healthcare. Uncertainty quantification is essential to convey confidence in predictions, especially in clinical settings where overreliance on opaque models can lead to adverse outcomes. \\n\\n The TRIPOD+AI statement (BMJ, 2024; 385: e078378. doi: 10.1136/bmj-2023-078378) provides structured guidance for reporting prediction models developed using regression or machine learning. It updates the original TRIPOD checklist to address the methodological complexities and transparency issues associated with AI-driven models. The 27-item checklist includes specifications for data sources, preprocessing, model development, and evaluation. It emphasizes documentation of health inequalities, uncertainty estimates, and fairness evaluations. The checklist also mandates reporting of outcome definitions, predictor measurement, and model usage context, aiming to support reproducibility, ethical integrity, and utility in clinical decision-making."
  },
    "MODELS": [
        {
            "model_code": "gpt-4o",
            "model_name": "OpenAI GPT 4o",
            "temperature": 0.1,
            "max_completion_tokens": 5000,
            "agent_name": "ALICE"
        }
  ]
}