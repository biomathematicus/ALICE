{
  "CONFIG": {
    "general_instructions": "This project is an AI assistant for a course. The output of each request must be a response that guides a student in understanding a topic.",
    "description": "The Data and AI Intensive Research with Rigor and Reproducibility (DAIR-3) program is funded by Award 5R25GM151182 of the National Institute of General Medical Sciences, one of the 27 institutes of the National Institutes of Health of the United States. The principal investigators are Jing Liu (University of Michigan) and Juan B. Guti\u00c3\u00a9rrez (University of Texas at San Antonio). \\nThe rigor of scientific research and the reproducibility of research results are essential for the validity of research findings and the trustworthiness of science. However, research rigor and reproducibility remains a significant challenge across scientific fields, especially for research with complex data types from heterogeneous sources, and long data manipulation pipelines. This is especially critical as data science and artificial intelligence (AI) methods emerge at lightning speed and researchers scramble to seize the opportunities that the new methods bring.  \\n\\nWhile researchers recognize the importance of rigor and reproducibility, they often lack the resources and the technical know-how to achieve this consistently in practice. With funding from the National Institutes of Health, a multi-university team offers a nationwide program to equip faculty and technical staff in biomedical sciences with the skills needed to improve the rigor and reproducibility of their research, and help them transfer such skills to their trainees. \\n\\nTrainees will then be guided over a one-year period to incorporate the newly acquired mindset, skills and tools into their research; and develop training for their own institutions.  \\n\\nThe DAIR3 team and instructors include faculty and staff research leaders from the University of Michigan, the College of William and Mary, Jackson State University, and University of Texas San Antonio. This highly diverse team will model the culture of diversity that we promote, and will support trainees who are demographically, professionally and scientifically diverse, and are from a diverse range of institutions, including those with limited resources.",
    "harmonizer_code": "gpt-4o",
    "harmonizer_temperature": 0.1,
    "harmonizer_name": "Harmonizer"
  },
  "MODELS": [
    {
      "model_code": "gpt-4o",
      "model_name": "OpenAI GPT 4o",
      "temperature": 0.15,
      "agent_name": "ALICE AI Agent"
    }
  ],
  "knowledgeBase": [
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Code Book for PDSA Dataset.pdf",
      "summary": "14 PDSA14  Num  8 14: Where were you in life 10 years ago (1 -10)  15 PDSA15  Num  8 15: Number best describes  where would  you like  to be  next year  (1-10)  16 PDSA16  Num  8 16: Number best describes where you expect to be next year (1 -10)  17 PDSA17  Char  1 17: Disappointed if you never reach 15   18 PDSA18A  Num  8 18a: Highest degree/years of school you completed? 37 PDSA28B  Char  1 28b: You/family received +$35K   38 PDSA28C  Char  1 28c: You/family received +$50K   39 PDSA28D  Char  1 28d: You/family $75K   40 PDSA28E  Char  1 28e: You/family $100K   41 PDSA28F  Char  1 28f: You/family $10K   42 PDSA28G  Char  1 28g: You/family $25K   43 PDSA28A  Char  1 28a: What was total combined family income in past year?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Hu article on SDOH in JHS.pdf",
      "summary": "Efird, PhD4,5, \u2219  Danxin\u00a0Wang,\u00a0PhD6, \u2219 Mario\u00a0Sims, PhD7, \u2219 Bei\u00a0Wu, PhD8, \u2219 Morgana\u00a0Mongraw-Chaffin, PhD9, \u2219  Joshua J.\u00a0Joseph, MD, MPH, FAHA10, 1College of Nursing, The Ohio State University, Columbus, OH, USA 2Department of Biostatistics and Data Science, Division of Public Health Sciences, Wake Forest School of Medicine, Winston-Salem, NC, USA 3Center for Biostatistics, College of Medicine Department of Biomedical Informatics, The Ohio State University, Columbus, OH, USA 4Department of Radiation Oncology, School of Medicine, Case Western Reserve University, Cleveland, OH, USA 5Boston VA Cooperative Studies Program Coordinating Center, Boston, MS, USA 6Department of Pharmacotherapy and Translational Research, College of Pharmacy, University of Florida, Gainesville, FL, USA 7University of Mississippi Medical Center, Jackson, MS, USA 8Rory Meyers College of Nursing, New York University, New York, NY, USA 9School of Medicine, Wake Forest University, Winston-Salem, NC, USA 10College of Medicine, The Ohio State University, Columbus, OH, USA  Jie Hu hu.1348@osu.edu Abstract  Background Social determinants of health have a significant impact on health outcomes. Purpose This study examined associations of socioeconomic position (income, education, and occupation), environmental (physical activity  facilities, neighborhood social cohesion, neighborhood problem, and violence), behavioral (physical activity, nutrition, and smoking), and psy - chological factors (depressive symptoms, stress, and discrimination) with glycemic control (hemoglobin A1c [A1c]) using the World Health  Organization Social Determinants of Health framework in African American adults with type 2 diabetes. SDH are \u201cconditions in the environ- ments in which people are born, live, learn, work, play, wor - ship, and age that affect a wide range of health, functioning,  and quality-of-life outcomes and risks\u201d [4]; these factors can  be more important than healthcare utilization or life style  changes in influencing health outcomes. The World Health  Organization (WHO) Social Determinants of Health frame- work posits a complex relationship among the various social  determinants of health that affect health equity and outcomes  in positive and negative ways [3]. Studies  seeking to understand and intervene on socioeconomic  position have struggled with the complexity of multiple  contributors to diabetes and outcomes (e.g., biological, psy- chological) and comparison between studies is complicated  by the varying conceptual frameworks and definitions used  for socioeconomic position [3]. The American Diabetes Association (ADA) scientific review  on socioeconomic position and diabetes concluded that the  complexity and interaction of multiple factors influencing  diabetes control has been understudied, but that priority  should be on interventions that target the root causes of dia- betes inequality and embed social determinants of health in  implementation and dissemination [3]. In line with these strategies and to ad- dress this knowledge gap, we conducted a secondary data  analysis using the Jackson Heart Study (JHS) in a sample of  AA adults with type 2 diabetes. Examining the impact of socioeconomic  position on diabetes outcomes in AAs with type 2 diabetes  and identifying potential factors in the pathway between  socioeconomic position and glycemic control will help lead to  the development of effective diabetes self-management inter - ventions that include addressing socioeconomic position to  improve diabetes outcomes and promote health equity among  AA people with type 2 diabetes. Our study was guided by the WHO Social Determinants  of Health conceptual framework including SEP (income, edu- cation, and occupation), material circumstances (living and  working conditions, food availability), behaviors (physical  activity, healthy eating and smoking), and psychosocial com- ponents (depressive symptoms, stress, and discrimination) as  pathways to health and well-being (Appendix Fig. The aims of this study were to examine the associations be- tween SEP and glycemic control and assess the extent to  which environmental, behavioral, and psychological factors  mediate the effects of SEP in predicting glycemic control over  time among AA adults with type 2 diabetes. Methods Data Source A secondary data analysis of a longitudinal cohort of AAs  with type 2 diabetes was used to examine the aims and test  the hypotheses. The Jackson Heart Study (JHS) is the largest  community-based, longitudinal, and prospective study that examined associations of genetic, environmental, psycho- social risk factors associated with causes of cardiovascular  disease (CVD) in AA adults. The JHS cohort includes 5,306  men and women between the ages of 21-94 at enrollment  residing in the tri-county metro area of Jackson, Mississippi  [15,16]. The  2000-kcal diet included (1) \u2265 4.5 cups of daily fruits and  vegetables; (2) >3.5-ounce servings of fish, twice a week; (3)  \u22653 one-ounce daily servings of whole grains; (4) <1500\u00a0mg/d  of sodium, and (5) \u2264450 kcal per week of sugar beverages. Stress was measured with the Global Perceived Stress  Scale (GPSS) [28], an eight-item scale measuring the severity  of chronic stress over the past 12 months in employment,  relationships, the neighborhood, caring for others, legal  problems, medical problems, experiences of racism and dis- crimination, and meeting basic needs. The Everyday Discrimination Scale (nine items) [32] meas- ures perceptions of everyday discrimination of being treated  with less respect and less courtesy, and among other factors  (e.g., \u201cYou are treated with less courtesy than other people\u201d;  \u201cPeople act as if they are afraid of you\u201d). For each latent factor (SEP,  environment, behavior, and psychological), we specified  a distributionally appropriate generalized linear model  including fixed effects of the covariates and the corres- ponding latent factor and loading. The growth model for log A1c in- cluded fixed effects of the covariates on the intercept and  slope terms as well as random intercepts and slopes for each  subject. The structural part of the model assumes that the  SEP factor is associated with the environmental, behavioral,  and psychological factors. The coefficients for the effect of SEP on each of the other  factors were assigned normal distributions with mean 0 and  variance 1. Missing Data We assume missing data in the indicators of the latent factors  are missing at random conditional on all other covariates and  variables in the model. Table 2 presents the baseline data on mean A1c and longi- tudinal association between time and glycemic control (A1c)  by different levels of each factor in the unadjusted model,  and an adjusted model for age, gender, BMI, types of dia- betes medication and comorbidities. In the adjusted model  of the longitudinal analysis, there was a decreasing trend of  A1c over time among participants with less than high school  education, higher levels of perceived neighborhood problems,  and healthier nutritional intake. Higher values of the envir - onmental factors were associated with higher cohesion scores and lower scores for the facilities, problems, and violence  scales. We estimated negative associations be- tween SEP and the psychological factor with a posterior  mean coefficient of \u22120.46 (95% CI: \u22120.59, \u22120.34) and the  behavioral factor with a posterior mean coefficient of \u22122.54 T able 1. Demographic and Clinical Characteristics of Participants with  Type 2 Diabetes at Baseline (N = 1,242)  Characteristic  n (%)* or Mean (\u00b1SD)  Age in years (n = 1,242) 59.8 (\u00b110.9) Sex (n = 1,242)   Male 421 (34%)   Female 821 (66%) Education (n = 1,236)   <high school education 337 (27%)   \u2265High school 899 (73%) Occupation (n = 1,240)   Management/Professional 382 (31%)   Other 858 (69%) Income (n = 1,029)   Low 205 (20%)   Lower middle 295 (29%)   Upper middle 288 (28%)    Affluent 241 (23%) Body Mass Index (kg/m) (n = 1,240) 34.1 (\u00b17.1) Comorbidities**   MI (n = 1,242) 124 (10%)   Stroke (n = 1,242) 100 (8%)   CHD (n = 1,242) 174 (14%)   HTN (n = 1,242) 997 (80%)   CKD (n = 1,240) 95 (7%)   LVH (n = 699) 97 (8%) Medication Blood pressure (n = 1,233) 975 (79%) Diabetes (n = 1,232) 837 (68%) Types of diabetes medication (n = 1,152)   No diabetes medication 395 (34%)   Oral antihyperglycemic agents (OAA) only 440 (38%)   Insulin only 210 (18%) Both OAA and insulin 107 (9%) * Percentages based on completed items. Finally, we examined associations of the latent factors with  the log A1c conditional on the covariates included in the  model (Table 3). The in- direct effect of SEP on longitudinal A1c through behavioral factors was 0.03 (95% CI: 0.02, 0.04) with posterior prob- ability and the effect greater than 0 of 1. We did not observe  strong evidence for associations with the environmental or  psychological factors at baseline, with the slope of log A1c  over time nor as mediators of the relationship between SEP  and log A1c over time. Associations of the Latent Factors with the Log A1c Conditional on the Covariates at Baseline (Intercept) and Over Time (Slope) Outcome Factor Estimate 95% CI P (estimate > 0)  Environmental factors SEP 0.344 (0.2677, 0.4236) 1 Behavioral factors SEP \u22122.537 (\u22123.4025, \u22121.7429) 0 Psychological factors SEP \u22120.4583 (\u22120.5867, \u22120.3389) 0 A1c Intercept SEP 0.3541 (0.2238, 0.5024) 1 Environmental factors \u22120.0082 (\u22120.0207, 0.0043) 0.0963 Behavioral factors 0.1433 (0.122, 0.1614) 1 Psychological factors \u22120.01 (\u22120.0278, 0.0074) 0.1392 A1c Slope SEP \u22120.0295 (\u22120.0447, \u22120.017) 0 Environmental factors 0.0013 (\u22120.0012, 0.0037) 0.8484 Behavioral factors \u22120.012 (\u22120.015, \u22120.0091) 0 Psychological factors0.002 (\u22120.001, 0.0051) 0.9002 *Note: Higher values of SEP indicate higher levels of SEP; higher values in environmental factors indicate better environmental factors, higher values  of behavioral factors indicate poor health behaviors; higher values of psychological factors indicate worse psychological health (higher stress and more  depressive symptoms). A model of the association between Social Determinants of Health and glycemic control (slope A1c over time) adjusting for the covariates among  African American adults with Type 2 diabetes using SEM. *Higher values of SEP indicate higher levels of SEP; higher values in environmental factors  indicate better environmental factors, higher values of behavioral factors indicate poor health behaviors; higher values of psychological factors indicate  worse psychological health (higher stress and more depressive symptoms). The indirect effect of SEP on longitudinal A1c through behavioral factors was 0.03 (95% CI: 0.004, 0.02) with posterior probability and the  effect was greater than 0 of 1 . There was no strong evidence for associations with the environmental or psychological factors at baseline, with the slope  of log A1c over time nor as mediators of the relationship between SEP and log A1c over time.Downloaded from https://academic.oup.com/abm/article/56/12/1300/6748867 by Sharon Kardia user on 30 April 2025 ann. Environmental, Behavioral and Psychological  Factors as Mediators in the Relationship  Between SEP and Glycemic Control We evaluated the role of environmental factors, behavioral  factors, and psychosocial factors as mediators in the associ- ation of socioeconomic position (income education and oc- cupation) with longitudinal glycemic control. In other words, lower socioeconomic  position was associated with increasing A1c levels in both the  overall and direct longitudinal analysis, but that the indirect  pathway through health behaviors (physical activity, nutrition,  and smoking) was in the opposite direction. As we suspect the baseline association  of higher SEP and poor behaviors with lower A1c is influ- enced substantially by confounding by indication, the longi- tudinal association between health behaviors and A1c could  be biased in the same way. We also note an earlier study which observed that lifestyle  mediated the effect of health and SEP, while the effect of SEP on psychological health was not particularly noteworthy  [39]. While people with  good health tend to achieve better SEP, this does not neces- sarily imply that SEP conveys better health but rather is the  consequence of healthful lifestyle choices at the individual  level (e.g., social causation being the root cause of health in- equalities). One reason why environmental factors possibly failed to  explain the association between SEP and glycemic control in  our study might be related to the demographic characteristics  of the sample from the JHS; most of participants had upper  middle or affluent income and higher than high school level  of education. A recent  study examining contribution of education to behavioral and  psychological antecedence of health in a national sample of  AA adults demonstrated that education was significantly as- sociated with health behaviors that partially explained health  disparities [43]. Neighborhood characteristics, spatial  variation, and dimensions of racial segregation (e.g., evenness,  exposure, clustering, concentration, and centralization) are  important considerations when evaluating glycemic control  in the context of social determinants of health [44]. Third, the study was conducted in one  region of the southeastern US and the SEP of participants  in the JHS is marginally higher than the general AA popu- lations, potentially limiting generalizability. Although beyond the scope of the  current paper, in the future we plan to explore other analytic  approaches to incorporate time-varying covariates, multi- level (hierarchical) effects, and to assess alternative covari- ance forms for modeling random effects and residuals of our  structural equation models [48]. The interrelationship of the factors considered in our ana- lysis are complex and multidimensional in nature; and thus,  they may not depict all the potential interacting and mediating effects of variables of interest. As indicated in the literature,  how a patient perceives the disease diagnosis and progression  of diabetes is an important determinant, mediated by the ef- fectiveness of stress alleviation, avoidance coping, healthful  diet, resilience to depression, and the proper control of their  comorbidities and blood sugar levels with medication [50]. However, the data were in part inconsistent  with the hypothesis that environmental and psychological  factors mediate the relationships between SEP and glycemic  control. The Jackson Heart Study is sup- ported and conducted in collaboration with Jackson State  University (HHSN268201800013I), Tougaloo College  (HHSN268201800014I), the Mississippi State Department  of Health (HHSN268201800015I) and the University  of Mississippi Medical Center (HHSN268201800010I,  HHSN268201800011I and HHSN268201800012I) con- tracts from the National Heart, Lung, and Blood Institute  (NHLBI) and the National Institute on Minority Health  and Health Disparities (NIMHD). The views expressed in this manuscript  are those of the authors and do not necessarily represent the  views of the National Heart, Lung, and Blood Institute; the  National Institutes of Health; the U.S. Department of Health  and Human Services; or the United States Department of  Veteran Affairs. All procedures, including the informed consent pro- cess, were conducted in accordance with the ethical standards  of the responsible committee on human experimentation (in- stitutional and national) and with the Helsinki Declaration of  1975, as revised in 2000. Ethical Approval All procedures performed in this study  were in accordance with the ethical standards of our institu- tional research ethics committee and with the 1964 Helsinki  declaration and its later amendments or comparable ethical  standards. The Estimated Loadings for the Indicators of Each Latent Factor Conditional on the Covariates Factor Variable Level Estimate 95% CI P(estimate>0)  Socioeconomic position Income Poor Lower-middle 0.43 (0.08, 0.8) 0.99 Upper-middle 2.04 (1.56, 2.54) 1 Affluent 3.36 (2.74, 4.08) 1 Education Less than HS HS+ 2.37 (1.85, 2.93) 1 Occupation Other Management/Professional 2.55 (2.04, 3.21) 1 Environmental factorsFacilities \u22120.09 (\u22120.11, \u22120.07) 0 Cohesion 0.1 (0.1, 0.11) 1 Problems \u22120.16 (\u22120.17, \u22120.15) 0 Violence \u22120.11 (\u22120.11, \u22120.1) 0 Psychological factorsDepression 6.18 (5.37, 7.04) 1 Perceived Stress 1.51 (1.19, 1.83) 1 Weekly Stress 39.02 (32.25, 46.13) 1 Daily Discrimination  1 2 0.21 (0, 0.43) 0.98 3 0.58 (0.33,0.85) 1 4 0.74 (0.4, 1.1) 1 5+ 1.24 (0.8,1.7) 1 Behavioral factorsPhysical activity Poor Health Intermediate Health \u22120.13 (\u22120.22, \u22120.07) 0 Ideal Health \u22120.31 (\u22120.46, \u22120.21) 0 Nutrition Poor Health Intermediate Health \u22120.14 (\u22120.22, \u22120.07) 0 Ideal Health \u22120.59 (\u22121, \u22120.32) 0 Current smoker No Yes 0.21 (0.11, 0.32) 1APPENDIXDownloaded from https://academic.oup.com/abm/article/56/12/1300/6748867 by Sharon Kardia user on 30 April 2025 1310 ann.behav. Carnethon MR, Pu J, Howard G, et al.; American Heart As- sociation Council on Epidemiology and Prevention; Council  on  Cardiovascular Disease in the Young; Council on Cardio- vascular and Stroke Nursing; Council on Clinical Cardiology;  Council on Functional Genomics and Translational Biology; and  Stroke\u00a0 Council. Stress and achievement  of cardiovascular health metrics: The American Heart Association  Life\u2019s Simple 7 in Blacks of the Jackson Heart Study."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Moresis article on Minimal Metadata.pdf",
      "summary": "Lab Animal | Volume 53 | March 2024 | 67\u201379  67 lab animalhttps://doi.org/10.1038/s41684-024-01335-0 Perspective A minimal metadata set (MNMS)  to repurpose nonclinical in vivo  data for biomedical research  Check for updates Anastasios Moresis   1,10, Leonardo Restivo2,10, Sophie Bromilow   3, Gunnar Flik4, Giorgio Rosati5,  Fabrizio Scorrano6, Michael Tsoory7, Eoin C. O\u2019Connor   8 , Stefano Gaburro   5  &  Alexandra Bannach-Brown   9  Although biomedical research is experiencing a data explosion, the accumulation of vast  quantities of data alone does not guarantee a primary objective for science: building upon existing knowledge. We conclude with a \u2018call for action\u2019 to key stakeholders in biomedical research to adopt and apply MNMS to accelerate both the advancement of knowledge and the betterment of animal welfare. On the other hand, the mere col - lection of vast amounts of data is not sufficient to ensure scientific  progress if these data cannot be interrogated and reintegrated into the  research cycle. In Europe and North America, legislation for animal experimenta- tion in biomedical research focuses heavily on implementation of the 3Rs  (see definition in Box 1), which encompasses the concepts of replace-ment, reduction and refinement 4. The objective of the 3Rs is to ensure  that animal experimentation achieves the highest level of welfare while  minimizing burden through well-designed and reviewed animal research  protocols and procedures. For example, in the EU REACH (Registration,  Evaluation, Authorisation and Restriction of Chemicals)20, European  Union (EU) biocides21 and EU plant protection products22, there is a  legal requirement to share test and study reports from studies in animals  that are used for registration purposes (see, for example, Article 62 in  Regulation (EC) No. Regulatory submissions to the  US Food and Drug Administration (FDA) must adhere to the Standard  for Exchange of Nonclinical Data (SEND), which requires presentation  of data from nonclinical safety and toxicology studies in a consistent and  machine-readable format. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinize the work adequately, evaluate its methodological rigor and reproduce the methods  and results 18. Raw data: also known as primary or source data, raw data are data (for example, numbers, instrument readings, figures and so on) collected from a source that was not subjected to (1) processing, (2) \u2018cleaning\u2019 by researchers to remove, for example outliers and obvious instrument-reading errors, (3) any analysis (for example, determining central tendency aspects such as the average or median result) or (4) any other manipulation by a software program or a human researcher, analyst or technician. Reproducibility: here we refer to reproducibility broadly, to include  both the stricter definition of reproducibility as \u2018reproducibility of analysis\u2019, referring to the re-analysis of an existing dataset, as well as \u2018reproducibility of experimental findings\u2019, which refers to the collection of new data in experiments as identical as possible to the initial experiment 40,41. Reasons for this limited  progress may include domain-specificity of approaches, technical barriers  to understanding FAIR data standards, a reluctance to share data, a lack  of awareness of potential benefits and an absence of incentives for data  sharing and repurposing. Additionally, we highlight opportunities, challenges and future actions  required to support the adoption of MNMS in biomedical research with a  view to ultimately enable data repurposing, the advancement of scientific  knowledge and the betterment of animal welfare. Conceptual understanding of minimal metadata  selection Before outlining a MNMS for in vivo data, it is first essential to understand  in more detail how metadata can aid the formation of a data repository  and the decision to repurpose data, thus contributing to a reduction  and replacement of animal use. Therefore, the lack of metadata overlap would not allow the researcher to  evaluate the potential to repurpose the data for their own needs. This practice would lead  to the aggregation of data collected either on incompatible sources   (for example, the attempt to aggregate data from distinct mouse strains), or  with discordant methodologies (for example, mice reared under different  housing conditions), which would be inappropriate for data repurposing. Adding the extra MNMS would not automatically extend the  repurposing of the raw data that lay in distant regions of the metadata  space. However, the presence of a complete MNMS would support the  decision of the researcher as to whether include the associated raw data  in a repurposing opportunity. Undoubtedly, the additional burden of log - ging the MNMS is eclipsed by the advantages that such a strategy offers  in terms of data repurposing, including the potential for replacement and  reduction of animal use, and reusage of critical data assets. As a more practical example for how metadata and database for - mation can support data repurposing, a schematic is shown of a data  repository that was implemented at the Roche Innovation Center Basel  (Switzerland) in 2022. In this case, the researcher can confidently operate a choice  for repurposing the data.Lab Animal | Volume 53 | March 2024 | 67\u201379 70 Perspectivehttps://doi.org/10.1038/s41684-024-01335-0 Key principles for the deployment of a MNMS With the conceptual understanding of a MNMS in place, we next high- light key principles required for deploying a MNMS for in vivo research. To enable the interoperable aspect, a structure must be imposed on the  metadata using a well-defined conceptual model to describe relationships  and constraints between the different entities (for example, an animal or a  study). A completeness score associated to the metadata set is critical to enable a threshold-based decision concerning the rejection or inclusion of the  associated raw data within a data repository. Provenance Provenance and ownership of data are important aspects for a MNMS and  are essential for curation in the context of large-scale usage of data and  metadata sets. To enable identification of provenance and ownership, each  data entry in a prospective repository must have the following operational  metadata associated to it: creator of the record (which is also treated as a  FAIR object with an assigned unique identifier), date of creation and date  of modification. Data  can be further segregated (for example, by strain, age and so on), enabling the experimenter to understand the potential for repurposing these data for their  specific questions and needs.Lab Animal | Volume 53 | March 2024 | 67\u201379  71 Perspectivehttps://doi.org/10.1038/s41684-024-01335-0 and are endorsed by peer-reviewed journals, which may facilitate future  adoption of MNMS. This will enable not only FAIR datasets  but, along with other potentially unique identifiers entered (for example, Table 1 | The MNMS (ARRIVE 2.0 Essential 10) ARRIVE topic-essential 10 MNMS MNMS detailed Data type Existing ontology Study design Yes, but only start and end  date of the in-life phaseStart and end date of the in-life phase Date ISO8601 Sample size NA NA NA NA Inclusion/exclusion criteria NA NA NA NA Randomization NA NA NA NA Blinding NA NA NA NA Outcome measuresYes, extended, assay  specificOutcome measure (including any   descriptive statistics if applicable,   for example, average speed)Controlled vocabulary Multiple, assay specific per domain Unit of measurement per measure Controlled vocabulary UO, OBI Statistical methods NA NA NA NA Experimental animals Yes, extended, all assaysUnique animal identifier URI NA Local identifiers/other IDs String NA Species Controlled vocabulary OBI, NCIt Strain (ILAR and short name) Controlled vocabulary ILAR a, MGI Sex Controlled vocabulary NCIt, CDISC/SEND Transgenic Boolean NA Genotype information Controlled vocabulary MGI Allele information Controlled vocabulary MGI Animal vendor (site and location) information Controlled vocabularya Date of birth Date ISO8601 Developmental stage Controlled vocabulary OBO Foundry Animal weight at start of experiment and unit Number + controlled  vocabularyUO Severity grade of manipulation Numbera Experimental proceduresYes, but focused on  compound treatment;   terms for procedures  beyond require  domain-specific alignmentTest substance (common name) Controlled vocabulary ChEBI, DrON Test substance (CAS number) Number NA Numerical dose Number NA Dose unit (ideally mg/kg or mM) Controlled vocabulary UO, OBI Vehicle composition Controlled vocabulary ChEBI Route of administration Controlled vocabulary OBI Administration method Controlled vocabulary OBI Results NA NA NA NA ChEBI, Chemical Entities of Biological Interest; CDISC, Clinical Data Interchange Standards Consortium; DrON, drug ontology; NA, not applicable; NCIt, National Cancer Institute thesaurus; OBO,  Open Biological and Biomedical Ontologies; UO, units of measurement ontology. Furthermore, for multiple  transgenic/mutant alleles additional care should be taken to unambigu-ously map the correct genotype to each allele in the sequence that would  constitute the full genotype (for example, allele 1: Tg/+; allele 2: Tg/Tg).The last essential immutable information is the date of birth of  the animal. From the set of nonimmutable animal metadata, animal weight at  the start of the experiment (with controlled vocabulary for the unit) is  mandatory in the MNMS. These metadata can (1) signify which animals belonged to the same study;  (2) facilitate the reuse of longitudinal data sets, where entries linked to body weight and age can change over the course of the experiment; and  (3) ensure awareness of when the data were produced, which may be an  important consideration in the case of factors such as genetic drift. Other important factors in the admin- istration of a compound are the method of administration and the  administration route (for example, intraperitoneally, per os and so on) and the vehicle composition. To avoid extending  terminology to different diets or feeding schedules and enrichment types,  which may be more reflective of specific experimental procedures and  thus beyond the scope of MNMS, both dietary status and enrichment are  represented with one of only two states (that is, fasted or fed/not fasted,  and the presence of enrichment or not). To this end,  any prospective user-facing system cannot be completely public but rather  based on a registration and authentication service.Box 2 | Key terms related to structured  metadata fields proposed in the MNMS   Administration method: indicates the method that is used for  exposure and excludes the route of administration. The opportunities and challenges for implementing  VCGs were the focus of the IMI eTRANSAFE project, which has collected  and analyzed drug safety and toxicology data from more than 60,000  rats, 1,300 dogs and 500 monkeys (see ref. Meta-research in animal research Meta-analysis of data from existing in vivo studies (within and beyond the scope of systematic reviews) provides a powerful tool to explore the  impact of variations in experimental design and can reduce the need for  further animal use. Meta-analyses of  animal data are also used to inform the optimal design of experiments in  a number of ways, including comparing performance and evaluating the  necessity of outcome tests34, informing sample-size calculations35, refining  the duration of experiments and humane endpoints36 and optimizing the  choice of model induction technique37. Adoption of  MNMS as a reporting standard, for both control and experimental data,  would provide a large step forward to improve the reporting of in vivo  studies and facilitate the overall conduct of meta-analysis. The age-at-test can be obtained by intersecting the date-of-birth and  the date of study start (both items included in MNMS) or the date of  testing that may be embedded in the raw data file (for example, raw data timestamp). Challenges for adopting MNMS The concept of deploying a MNMS to enable the creation of structured data repositories and the opportunity to repurpose data is highly appeal- ing from both a scientific (for example, incremental knowledge and new  insights) and an ethical point of view (that is, replacing and/or reducing  animal use). One expla - nation is that the efforts required to follow such guidelines, and the  rewards gained from doing so, may not be of immediate interest to the  data producer in the laboratory. Historical  practices within laboratories, combined with finite resources, may reflect  the need for further change within the scientific community to recognize  the importance of data sharing and the responsibilities of scientists to report their data. To minimize the effort needed for providing MNMS and maximize  their impact, we have proposed a MNMS that aligns with ARRIVE 2.0,  as set of guidelines that are gaining increasing acceptance within the bio - medical research community and are accepted by peer-reviewed journals. By providing a mandatory and minimal set of controlled terminologies to describe the data, the MNMS would overcome challenges of \u2018free text\u2019  entries required by ARRIVE, which can result in entries of variable quality  that are not easily comparable between publications, or no entries at all. Such  tools may include the use of artificial intelligence to support identification  and reporting of metadata from publications in standardized formats, and  to highlight where certain metadata are not found and must be provided before publication. This vast space does not allow the identification of a minimal set of  metadata that guarantees a decision is always taken on the reuse of data  from across diverse disciplines (for example, cardiology, neuroscience,  oncology and so on). This comprehensive representation underscores MNMS\u2019s role in  advancing responsible, efficient and high-quality research practices.Lab Animal | Volume 53 | March 2024 | 67\u201379  75 Perspectivehttps://doi.org/10.1038/s41684-024-01335-0 and their housing may range over a limited number of dimensions   (for example, genotype, age, weight, light cycle and so on), metadata from  the domain of experimental manipulations cover a far more extensive  space. To address the challenge given by the vast experimental space in  biomedical research, we suggest that an a priori decision must be made  concerning the range of experimental questions (and their associated  outcome measures) that would be of interest to address in a repurposing initiative, such as in the generation of VCGs. Indeed, it is critical that multiple par - ties (for example, domain experts, data architects, funding agencies and so on) join in a concerted action to define the boundaries and bridges of these minimal sets of metadata and to make repurposing of data across  disciplines a successful reality. Although companies are not forced to share data, it would  be prudent to ensure that all the terms of access are fair, reasonable and  nondiscriminatory (that is, those in a similar position should be able to  access the data on equivalent terms). However, contributors  are likely to want the requestor to accept full responsibility for confirming  that the data are suitable for the purposes for which they want to use it  and to accept all liability associated with reuse of the data. This issue is  particularly important where the sharing of the data is not a clear legal  requirement and where there is an intent to charge third parties for access  to the data (which may be viewed as commercial use of the results). Scenarios for MNMS implementation Despite the recognized challenges discussed above, the following sec- tion highlights opportunities to leverage MNMS to support in vivo  data repository creation and data repurposing across different in vivo  research contexts, including behavioral core facilities in academia,  CROs, pharmaceutical companies and in vivo research equipment  providers. Second, the exchange of data from client to CRO, and vice versa, should enhance the inherent robustness of  a given assay, which would benefit both the CRO by emphasizing assay  quality and the client by making robust decisions based on the assay result. VCGs and optimized study designs will  not only result in a reduction in the number of animals and ensure more ethical research, but it will also speed up the drug development trajec- tory and reduce costs, which is often a critical factor for smaller-sized  biotechnology companies. Restrictions on data use may be contained in the agreement  between the CRO and the sponsoring client, and sharing data may require  additional terms to be agreed (as discussed above in legal considerations for data sharing). Pharmaceutical research and development While the vast majority of experimentation in pharmaceutical research and development (Pharma R&D) is undertaken in non-animal studies,  animal research remains an important component to discover new biology  and treatment opportunities, and to predict the efficacy and safety of new  medicines before entering human trials. In this context,  FAIR data storage and the need to avoid continuous data replication of  historical data is of paramount importance to ensure research progress  and optimize insights discovery. Animal research software and/or hardware developers   and providers Animal research is enabled by a rich ecosystem of hardware and software,  including colony animal management software and laboratory information  management systems, tools used in the laboratory for various measure- ments (for example, heart rate monitors or imaging devices) and software  that enables biospecimen analysis and data visualization (for example, image analysis or statistical tools). In addition to enhancing the quality and supporting reproducibility of research, this advance would further Lab Animal | Volume 53 | March 2024 | 67\u201379  77 Perspectivehttps://doi.org/10.1038/s41684-024-01335-0 encourage ethical considerations and ultimately facilitate the process of  animal-data management and repurposing. Obtaining insights  on what tools the research community currently uses (for example,  Research Data Alliance initiatives or domain ontologies and vocabular - ies), and how MNMS can best align and integrate with these tools, will enable the development of new strategies to tackle barriers to adoption  of MNMS and facilitate data sharing. Dissemination activities could include hosting  workshops to showcase MNMS functionality with exemplar projects;  outlining the impact MNMS on research outcomes for each stakeholder  group; developing targeted marketing materials, such as infographics  to highlight the benefits of MNMS; producing educational materials  and documentation to support training efforts on how to effectively use MNMS; and performing pilot experiments to demonstrate the utility of  MNMS in common settings. These strategies can accelerate the uptake  and use of this tool into existing workflows and increase awareness of the  benefits of MNMS for a broad audience. However,  in the absence of tools to effectively reintegrate the vast quantities of  data generated into the research cycle, researchers face a situation of  massive resource inefficiency with minimal scientific gain. Regulation (EC) No 1907/2006 of the European Parliament and of the Council of 18 December 2006 Concerning the Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH), Establishing a European Chemicals Agency, Amending Directive 1999/45/EC and Repealing Council Regulation (EEC) No 793/93 and Commission Regulation (EC) No 1488/94 as Well as Council Directive 76/769/EEC and Commission Directives 91/155/EEC, 93/67/EEC, 93/105/EC and 2000/21/EC (Text with EEA Relevance)   (Publications Office of the European Union, 2006). Regulation (EU) No 528/2012 of the European Parliament and of the Council of 22 May 2012 Concerning the Making Available on the Market and Use of Biocidal productsText with EEA Relevance. Regulation (EC) No 1107/2009 of the European Parliament and of the Council of 21 October 2009 Concerning the Placing of Plant Protection Products on the Market and Repealing Council Directives 79/117/EEC and 91/414/EEC. Communication from the Commission\u2014Guidelines on the Applicability of Article 101 of the Treaty on the Functioning   of the European Union to Horizontal Co-Operation Agreements   Text with EEA Relevance (Publications Office of the European Union, 2011). Open Access This article is licensed under a Creative Commons  Attribution 4.0 International License, which permits use, sharing,  adaptation, distribution and reproduction in any medium or format,  as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-3-design.pdf",
      "summary": "\u2013Design refers to the process of developing a rationale and goals for the research, stating (falsi\ufb01able) hypotheses, and documenting how the data will be collected, analyzed, and interpreted. \u2013Data analysis refers to the execution of a data analysis plan, which in- cludes carrying out the analysis, interpreting the results, and formally assessing the uncertainty of all \ufb01ndings. The set of all humans of interest is the population and the speci\ufb01c humans that we observe and (potentially) manipulate is the sample. For example, in the context of measuring blood pressure, there is a well-known systematic error known as \"white coat hypertension\" in which some people\u2019s blood pressure rises due to the stress of interacting with the person doing the measurement. \u2013Both of the above examples can be viewed in a stylized way by considering the partial correlation coe\ufb03cient, which in the population satis\ufb01es the relationship ${\\rm Cor}(X, Y | Z) = ({\\rm Cor}(X, Y) - {\\rm Cor}(X, Z)\\cdot{\\rm Cor}(Y,Z))/\\sqrt{(1-{\\rmCor}(X,Z)\u02c62)\\cdot(1-{\\rmCor}(Y,Z)\u02c62)}$ Suppose that $X$ is $BMI$ and $Y$ is mortality risk, with marginal correlation ${\\rm Cor}(X, Y) > 0$. \u2022The most basic type of randomization is simple randomization , where each unit is independently assigned to a treatment group, either with uniform probabilities (equal probability of assignment to each arm) or with probabilities that are pre-determined to achieve desired relative group sizes (e.g. assigning to treatment with twice the probability of assigning to control). In 1:1 strati\ufb01ed randomization we would assign exactly 30 of the people with hypertension to the treatment arm, and exactly 15 of the people without hypertension to the treatment arm. \u2013Minimization is a class of methods that addresses the practical issue that in many research studies, subjects are recruited over time, and we do not have a listing of the subjects and their measured confounders at the outset of the study. If subjects do not actually receive the treatment to which they are randomized, one of the following three approaches can be adopted: \u2013In an intention to treat analysis, subjects are analyzed as belonging to 8thetreatmentgrouptowhichtheywereassigned, regardlessofwhether they received and fully complied with the treatment. It is the standard deviation of the sampling 9distribution of the random variable $\\hat{\\theta}$, which is induced by the underlying distribution of the data, $P(D)$. \u2022If the sampling distribution of $\\hat{\\theta}$ is approximately Gaussian, then the standard error is all one needs to fully characterize the estimation errors of an unbiased estimator. Statistical power \u2022Statistical power is a measure of how likely a study is to yield a positive \ufb01nding, if a positive \ufb01nding is the true state of the system being studied. Usually this refers to the power of a hypothesis test, referring to the probability of rejecting the null hypothesis when the null hypothesis is false. For example, we could have high power to reject the null hypothesis in a situation where, due to bias, rejecting the null does not re\ufb02ect the claimed level of evidence. \u2022As a basic example, the standard error of the mean is $\\sigma/\\sqrt{n}$, where $\\sigma\u02c62$ is the variance and $n$ is the sample size. Based on this expression, we know that the only factors that determine the standard error for mean estimation are the sample size and the variance, and that they combine as a speci\ufb01c rational function. To address this, each plot can be divided in half, and the two halves are randomly assigned, one to the treatment and one to the control. Surveys \u2022Asample survey is a research tool in which the goal is to quantify the state of a population, with a primary focus on achieving low bias for a de\ufb01ned target population. the goal of a survey is not usually to assess the e\ufb00ect of an exposure or intervention, and a survey does not usually have \"arms\" corresponding to di\ufb00erent treatments or exposures. 12\u2022The most basic type of sampling is to obtain a simple random sample (SRS), which is a sample of size $k$ from a population of size $n$ in which any subset of size $k$ is equally likely to be selected. For example, if we want to sample the employees of a company or the students enrolled in a school, a sampling frame would generally be available and it would be practical to obtain a simple random sample from it. For example, suppose that one of the research goals is to compare outcomes between Black and White subpopulations, in a setting where the White population is, say, 3 times greater than the Black population. One possibility would be to sample the same number of Black and White subjects, which would maximize statistical power for comparisons between these two races (if the variances within the two races are equal -- if the variances are unequal we would want $n_b/\\sigma_b\u02c62 = n_w/\\sigma_w\u02c62$, where $n_b$ and $n_w$ are the Black and White sample sizes and $\\sigma_b\u02c62$ and $\\sigma_w\u02c62$ are the response variances for Black and White subjects). If we, say, over-sample Black compared to White subjects at a rate of 3 to 1, then when estimating population parameters (not 13race-speci\ufb01c parameters), we would weight the White respondents 3 times more than the Black respondents to compensate for the biased sampling. \u2013Left censoring is less common than right censoring, but it can occur, for example, if a measurement falls below a \"limit of detection\" (e.g. the concentration of a chemical in a blood sample is below the limit of detection for the assay used to assess the chemical). \u2022Since ${\\rm Var}(d) = {\\rm Var}(a) + {\\rm Var}(b) - 2{\\rm Cov}(a, b)$, if $a$ and $b$ are positively correlated, the variance of $d$ is less than the sum of the variance of $a$ and the variance of $b$. \u2022Let $a\u02c6c_i$ and $b\u02c6c_i$ denote the baseline and follow-up measurements for subjects in the control arm and let $a\u02c6t_i$ and $b\u02c6t_i$ denote the baseline and follow-up measurements for subjects in the treated arm. A com- mon situation is that the treatment e\ufb00ect estimate is attenuated (shifted toward the null value) when comparing the estimate obtained using strati- \ufb01cation to the naive estimate. Regression adjustment \u2022Regression analysis is a broad class of techniques that can be used to relate the value of an outcome to the values of one or more explanatory variables . The most basic form of regression analysis is linear regression , usingordinary least squares to \ufb01t the models to data (i.e. to estimate the model parameters). \u2022A basic example is the linear model $E[Y|X,Z] = \\beta_0 + \\beta_1 X + \\beta_2 Z$, where $Y$ is the outcome, $X$ is the treatment or exposure, and $Z$ is a potential confounder. Under certain rather strong assumptions, an estimate of the coe\ufb03cient $\\beta_1$ can be used to assess the relationship between the exposure $X$ and the outcome $Y$, while controlling for the confounder $Z$. One may argue that this is a natural experiment since the factors that led to earlier introduction of cable services may be primarily driven by logistical factors so that the people who gained access to cable TV in, say, 1984 may not be systematically di\ufb00erent from those who gained access to cable TV in 1985. Thegoalof1:1matching is to identify a set of pairs $1 \\le j_{1i}, j_{2i} \\le n$ such that subject $j_{1i}$ is exposed, i.e. $x_{j_{1i}}=1$, subject $j_{2i}$ is not exposed, i.e. $x_{j_{2i}}=0$, and subjects $j_{1i}$ and $j_{2i}$ are similar in terms of the covariates, i.e. $z_{j_{1i}}\\approx z_{j_{2i}}$. If the treated units are much older than the untreated units, and only 5 of the treated units are younger than the oldest untreated unit, then there is very little common support and matching is unlikely to be e\ufb00ective. \u2022Once the weight vector $w$ is constructed, we estimate the counterfactual control value $y\u02c6*$ using $w\u02c6\\prime y$, where $y$ is the $m\\times 1$ vector containing the response values for the controls in $X$."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-4-Lecture01a_basics.pdf",
      "summary": "ML is an  algorithmic field that blends ideas from statistics, computer science and many other disciplines (see below) to design algorithms that process data, make predictions and help make decisions.\u201d \u201cThe phrase \u201cData Science\u201d began to be used to refer  to this phenomenon, reflecting the need of ML algorithms experts to partner with database and distributed-systems experts to build scalable, robust ML systems, and reflecting the larger social and environmental scope of the resulting systems.\u201d \u201cThis confluence of ideas and technology trends has  been rebranded as \u201cAI\u201d over the past few years. Number\u00a0of\u00a0petals\u00a0on\u00a0the\u00a0daisies\u00a0in\u00a0the\u00a0gardens\u00a0of\u00a0Houston \u2022Daisies\u00a0(in\u00a0the\u00a0gardens\u00a0of\u00a0Houston): \u00a0population \u00a0units \u2022Number\u00a0of\u00a0petals:\u00a0discrete\u00a0variable\u00a0(numerical) Car\u00a0brands\u00a0in\u00a0Houston \u2022Cars\u00a0(in\u00a0Houston): \u00a0population \u00a0units \u2022Car\u00a0brand:\u00a0discrete\u00a0variable\u00a0(categorical)Discrete\u00a0and\u00a0Continuous \u00a0Variables \u2022Continuous Any\u00a0real\u00a0value\u00a0in\u00a0a\u00a0range\u00a0(continuous) e.g. Blood\u00a0pressure\u00a0of\u00a0overweight \u00a0Americans \u2022Overweight \u00a0Americans: \u00a0population \u00a0units \u2022Blood\u00a0pressure: \u00a0continuous \u00a0variable\u00a0(numerical) Liters\u00a0of\u00a0wastewater \u00a0produced \u00a0by\u00a0each\u00a0Houston\u00a0inhabitant \u00a0in\u00a02010 \u2022Houston\u00a0inhabitants: \u00a0population \u00a0units \u2022Liters\u00a0of\u00a0wastewater \u00a0(2010):\u00a0continuous \u00a0variable\u00a0(numerical)Discrete\u00a0Analytical \u00a0Distributions \u2022Cast\u00a0a\u00a0(fair)\u00a06\u2010face\u00a0dice,\u00a0observe\u00a0the\u00a0number\u00a0on\u00a0the\u00a0top\u00a0face \u2013Population \u00a0units:\u00a0all\u00a0the\u00a0possible\u00a0dice\u2010casting\u00a0events\u00a0for\u00a0that\u00a0(fair)\u00a06\u2010face\u00a0dice \u2013Discrete\u00a0variable:\u00a0number\u00a0on\u00a0the\u00a0top\u00a0face\u00a0of\u00a0the\u00a0dice \u2022Probability \u00a0distribution P\u00a0(1)\u00a0=\u00a01/6 P \u00a0(4)\u00a0=\u00a01/6 P\u00a0(2)\u00a0=\u00a01/6 P \u00a0(3)\u00a0=\u00a01/6 P\u00a0(5)\u00a0=\u00a01/6 P \u00a0(6)\u00a0=\u00a01/6 \u2022This\u00a0is\u00a0a\u00a0uniform\u00a0discrete\u00a0distribution \u2013It\u2019s\u00a0mathematically \u00a0simple,\u00a0 but\u00a0not\u00a0all\u00a0discrete\u00a0analytical \u00a0distributions \u00a0are\u00a0as\u00a0simplePx\uf028\uf029\uf03d16,x\uf0ce{ 1 ,2 ,3 ,4 ,5 ,6 }Continuous \u00a0Analytical \u00a0Distributions \u2022Since\u00a0the\u00a0variable\u00a0can\u00a0have\u00a0any\u00a0possible\u00a0value\u00a0in\u00a0a\u00a0range,\u00a0the\u00a0 probability \u00a0of\u00a0a\u00a0single\u00a0value\u00a0is\u00a0not\u00a0finite \u2022We\u00a0need\u00a0calculus\u00a0to\u00a0correctly\u00a0handle\u00a0the\u00a0probability \u00a0distribution, \u00a0 which\u00a0is\u00a0called\u00a0density\u00a0functionHypothesis \u00a0Testing Hypothesis \u00a0Testing Empirically  observed frequency (count the number of values observed)Analytical  probability density (area under the curve) Pxa\uf03cx\uf03cxb\uf028\uf029 \uf03df(x)dx xaxb \uf0f2Normal\u00a0DistributionNormal\u00a0Distribution \u2022The\u00a0Normal\u00a0is\u00a0a\u00a0very\u00a0important \u00a0distribution \u2013Often\u00a0found\u00a0when\u00a0measuring \u00a0a\u00a0physical\u00a0property\u00a0multiple\u00a0times (variability \u00a0due\u00a0to\u00a0random\u00a0instrumental \u00a0errors) \u2013Often\u00a0found\u00a0for\u00a0anthropometric \u00a0indexes\u00a0in\u00a0human\u00a0populations \u2013The\u00a0sampling\u00a0mean follows\u00a0the\u00a0normal\u00a0distribution fx\uf028\uf029\uf03d1 \uf0732\uf070e\uf02d(x\uf02d\uf06d)2 2\uf0732Parameters: -\u03bc = Mean (x) -\u03c3 = StDev (x)Hypothesis \u00a0Testing \u03c3 affects the  width of the curve \u03bc affects the  position of the center of the curve\u03c3 = 1 \u03c3 = 2 \u03c3 = 3The normal is  symmetric and centered on \u03bc  \u03bcNormal\u00a0Distribution \u00a0in\u00a0R:\u00a0 Find\u00a0P\u00a0given\u00a0x P (x < b) = \u2026  P (x < a) = \u2026 pnorm (x = \u2026, mean = \u2026, sd = \u2026)a bNormal\u00a0Distribution \u00a0in\u00a0R:\u00a0 Find\u00a0P\u00a0given\u00a0x P (a < x < b) = P (x < b) - P (x < a) pnorm (x = xb.n, \u2026) \u2013 pnorm (x = xa.n, \u2026)Assignment: verify that for any mean and  standard deviation, the probability of x falling within \u03bc \u00b1 2 \u03c3 is about 95% abNormal\u00a0Distribution \u00a0in\u00a0R:\u00a0 Find\u00a0x\u00a0given\u00a0P P (x < \u2026) = P1 qnorm (p = \u2026, mean = \u2026, sd = \u2026)Area = P1Normal\u00a0Distribution: The\u00a0Effect\u00a0of\u00a0Symmetry P (x < \u03bc + k) = 1 - Pk P (x < \u03bc - k) = Pk \u03bc\u03bc\u03bc -k \u03bc + k Assignment: test this property using qnorm ()Pk Pk1-PkThe\u00a0Standard \u00a0Normal and\u00a0the\u00a0z\u2010score \u2022The\u00a0Standard\u00a0Normal\u00a0distribution \u00a0has\u00a0\u03bc\u00a0=\u00a00,\u00a0\u03c3\u00a0=\u00a01 \u2022The\u00a0z\u2010score\u00a0is\u00a0used\u00a0to\u00a0transform \u00a0normally\u00a0distributed \u00a0 variables\u00a0into\u00a0a\u00a0standard\u00a0normal \u2013Z\u00a0follows\u00a0the\u00a0standard\u00a0normal\u00a0\u00a0 \u2013The\u00a0z\u2010score\u00a0is\u00a0often\u00a0interpreted \u00a0as\u00a0the\u00a0number\u00a0of\u00a0standard\u00a0 deviations \u00a0from\u00a0the\u00a0mean \u2013The\u00a0reverse\u00a0formula\u00a0is\u00a0also\u00a0importantz\uf03dx\uf02d\uf06d \uf073 x\uf03d\uf06d\uf02bz\uf0d7\uf073Normal\u00a0Distribution: Find\u00a0x\u00a0given\u00a0P\u00a0using\u00a0the\u00a0Standard P (x < x1) = P1 \u03bc x1P1 0 z1P1P (z < z1) = P1 x1 = \u03bc + z1*\u03c3Hypothesis \u00a0Testing\u2022Test\u00a0this\u00a0relation:\u00a0x1\u00a0=\u00a0\u03bc\u00a0+\u00a0z1*\u03c3 using\u00a0the\u00a0R\u00a0commands \u00a0you\u00a0have\u00a0learnt # Normal x1.n <- qnorm (p = \u2026, mean = \u2026, sd = \u2026) # Standard Normal z1.n <- qnorm (p = \u2026)\uf0e0QQplot \u2022The\u00a0QQ\u2010plot\u00a0of\u00a0an\u00a0observed \u00a0 distribution \u00a0versus\u00a0the\u00a0 normal\u00a0 can\u00a0be\u00a0used\u00a0to\u00a0evaluate\u00a0how\u00a0 close\u00a0the\u00a0observed \u00a0 distribution \u00a0is\u00a0to\u00a0the\u00a0normal \u2013The\u00a0point\u00a0should\u00a0be\u00a0lying\u00a0on\u00a0 a\u00a0line https://en.wikipedia.org/wiki/ Normal_probability_plotHypothesis \u00a0Testing # quasi-normal x.nv <- c (-1.8, -1, -0.75,  -0.5, -0.3, 0, 0.3, 0.45, 0.8, 1.1, 1.6) qqnorm (x.nv, pch = 19)qqline (x.nv)# not normal x.nv <- 2 ^ (1: 12)qqnorm (x.nv, pch = 19)qqline (x.nv)Population \u00a0and\u00a0Sample \u2022Population set\u00a0of\u00a0entities\u00a0(individuals, \u00a0objects,\u00a0events) mean: \u03bc stdev: \u03c3 \u2022Sample subset\u00a0of\u00a0a\u00a0population mean: m stdev: sCorrection \u00a0for\u00a0Sample\u00a0Stdev \u2022Population \u2022Sample\uf073\uf03d1 NM(x)\uf02dxi\uf028\uf0292 Ni\uf03d1 \uf0e5 s\uf03d1 N\uf02d1M(x)\uf02dxi\uf028\uf0292 Ni\uf03d1 \uf0e5 The R function sd ()  uses by default the second definitionHypothesis \u00a0Testing As N increases, the sample means of the statistic become  closer to the population value of the statisticSampling \u00a0Mean\u00a0Distribution \u2022If\u00a0the\u00a0distribution \u00a0of\u00a0x\u00a0is\u00a0normal, the\u00a0distribution \u00a0of\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0is\u00a0normal\u00a0as\u00a0well \u2022Even\u00a0if\u00a0the\u00a0distribution \u00a0of\u00a0x\u00a0is\u00a0not\u00a0normal, when\u00a0sample\u00a0size\u00a0N\u00a0is\u00a0sufficiently \u00a0large the\u00a0distribution \u00a0of\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0is\u00a0normal (Central\u00a0Limit\u00a0Theorem) \u2022For\u00a0practical\u00a0purposes, \u00a0sufficiently \u00a0large\u00a0corresponds \u00a0to\u00a0N\u00a0>\u00a030x x Confidence \u00a0Interval\u00a0of\u00a0the\u00a0Mean \u2022Solution 1. However in R we can use any normal distribution to compute x given the probabilityx  x Hypothesis \u00a0Testing \u2022Given\u00a0a\u00a0sample\u00a0(with\u00a0known\u00a0mean\u00a0and\u00a0stdev),\u00a0we\u00a0want\u00a0 to\u00a0test\u00a0whether\u00a0it\u00a0may\u00a0belong\u00a0or\u00a0not\u00a0to\u00a0a\u00a0population \u00a0 (with\u00a0known\u00a0mean) \u2022We\u00a0can\u00a0use\u00a0the\u00a0framework \u00a0we\u00a0have\u00a0derived\u00a0for\u00a0 confidence \u00a0interval,\u00a0and\u00a0reshape\u00a0it\u00a0as\u00a0a\u00a0test \u2013Application \u00a0example: Monsanto \u00a0claims\u00a0that\u00a0a\u00a0new\u00a0crop\u00a0variety\u00a0has\u00a0a\u00a0higher\u00a0yield Compare\u00a0the\u00a0yield\u00a0of\u00a0a\u00a0sample\u00a0of\u00a0Monsanto\u2019s \u00a0new\u00a0variety\u00a0 versus\u00a0the\u00a0historical\u00a0yield\u00a0average\u00a0of\u00a0the\u00a0traditional \u00a0variety\u00a0and\u00a0 test\u00a0Monsanto\u2019s \u00a0claim\uf0e0\u00a0Hypothesis \u00a0Testing:\u00a0 Null\u00a0and\u00a0Alternative \u00a0Hypothesis Monsanto \u00a0claims\u00a0that\u00a0a\u00a0new\u00a0crop\u00a0variety\u00a0has\u00a0a\u00a0higher\u00a0yield Compare\u00a0the\u00a0yield\u00a0of\u00a0a\u00a0sample\u00a0of\u00a0Monsanto\u2019s \u00a0new\u00a0variety\u00a0versus\u00a0the\u00a0 historical\u00a0yield\u00a0average\u00a0of\u00a0the\u00a0traditional \u00a0variety\u00a0and\u00a0test\u00a0Monsanto\u2019s \u00a0 claim \u2022Test\u00a0Statistic:\u00a0Mean\u00a0 \u2013Distribution: \u00a0t\u2010student \u2022Null\u00a0Hypothesis \u00a0H0:\u00a0\u03bc\u00a0\u2264\u00a0\u03bc0 \u2022Alternative \u00a0Hypothesis \u00a0H1:\u00a0\u03bc\u00a0>\u00a0\u03bc0\u03bc: mean yield of the  new variety \u03bc0: mean yield of the  traditional varietyNull Hypothesis (\u201cstatus quo\u201d): the sample being tested could  have been drawn form the population being testedP (x < m) = 1 - p \u03bc0 t-Student mP (x > m) = pHypothesis \u00a0Testing:\u00a0p\u2010value \u2022Set\u00a0the\u00a0confidence \u00a0interval\u00a0so\u00a0that \u2022p\u00a0=\u00a0probability \u00a0of\u00a0observing \u00a0a\u00a0 population \u00a0sample\u00a0as\u00a0extreme\u00a0or\u00a0 more\u00a0extreme\u00a0than\u00a0the\u00a0one\u00a0being\u00a0 tested\u00a0when\u00a0drawing\u00a0from\u00a0the\u00a0 population \u00a0with\u00a0mean\u00a0\u03bc0 \u2013p\u00a0>>\u00a00:\u00a0null\u00a0hypothesis \u00a0likely \u2013p\u00a0~\u00a00:\u00a0null\u00a0hypothesis \u00a0not\u00a0likelym\uf03d\uf06d0\uf02bt(N\uf02d1)ps N How much do we have to \u201cstretch\u201d the confidence  interval to \u201cexplain\u201d the observed sample mean?Hypothesis \u00a0Testing:\u00a0p\u2010value \u2022Null\u00a0Hypothesis :\u00a0 \u2013statistical \u00a0model\u00a0where\u00a0differences \u00a0 are\u00a0only\u00a0due\u00a0to\u00a0random\u00a0fluctuations \u00a0(sampling) \u2022P\u2010value : \u2013Probability \u00a0that\u00a0the\u00a0null\u00a0hypothesis \u00a0model\u00a0 does\u00a0not\u00a0explain\u00a0the\u00a0data \uf0e0The\u00a0differences \u00a0observed \u00a0are\u00a0probably\u00a0due\u00a0 to\u00a0some\u00a0underlying \u00a0phenomenonHypothesis \u00a0Testing:\u00a0Error\u00a0Types \u2022Depending \u00a0on\u00a0the\u00a0p\u2010value,\u00a0 you\u00a0can\u00a0decide\u00a0to\u00a0reject\u00a0or\u00a0not\u00a0the\u00a0null\u00a0hypothesis \u2013P\u2010value\u00a0threshold \u00a0for\u00a0rejection: \u00a0\u03b1\u00a0(common \u00a0values\u00a00.05,\u00a00.01) \u2013There\u00a0has\u00a0to\u00a0be\u00a0sufficient \u00a0evidence\u00a0to\u00a0reject\u00a0the\u00a0null\u00a0hypothesis (in\u00a0the\u00a0criminal\u00a0trial,\u00a0the\u00a0defendant \u00a0is\u00a0not\u00a0guilty,\u00a0unless\u00a0proved\u00a0guilty) \u2013Multiple\u00a0testing\u00a0issuesH0: FALSE H0: TRUE Type-II Error (False Negative)OK (True Negative)H0NOT REJECTED OK (True Positive)Type-I Error (False Positive)H0REJECTEDHypothesis \u00a0Testing:\u00a0Error\u00a0Types \u2022Depending \u00a0on\u00a0the\u00a0p\u2010value,\u00a0 you\u00a0can\u00a0decide\u00a0to\u00a0reject\u00a0or\u00a0not\u00a0the\u00a0null\u00a0hypothesis \u2013Using\u00a0the\u00a0p\u2010value\u00a0for\u00a0the\u00a0decision\u00a0 \u2022P\u2010value\u00a0<\u00a0\u03b1:\u00a0reject\u00a0H0\u00a0 \u2022P\u2010value\u00a0\u2265\u00a0\u03b1:\u00a0do\u00a0not\u00a0reject\u00a0H0\u00a0 enables\u00a0to\u00a0control\u00a0the\u00a0Type\u2010I\u00a0Error\u00a0but\u00a0not\u00a0the\u00a0Type\u2010II\u00a0ErrorH0: FALSE H0: TRUE Type-II Error (P = \u03b2| H0FALSE)True Negative (P = 1-\u03b1 | H0TRUE)H0NOT REJECTED True Positive (P = 1-\u03b2 | H0FALSE)Type-I Error (P =\u03b1 | H0TRUE)H0REJECTEDOne\u2010tail\u00a0Test P = 1 - p \u03bc0P = p \u03bc0-\u2026 \u03bc0+ \u2026 P = 1 - p \u03bc0P = p \u03bc0-\u2026 \u03bc0+ \u2026\u2022Null\u00a0Hypothesis: \u00a0\u03bc\u00a0\u2264\u00a0\u03bc0 \u2022Alternative \u00a0Hypothesis: \u00a0\u03bc\u00a0>\u00a0\u03bc0 R:\u00a0set\u00a0input\u00a0argument \u00a0of\u00a0the\u00a0test alternative = \"greater\" \u2022Null\u00a0Hypothesis: \u00a0\u03bc\u00a0\u2265\u00a0\u03bc0 \u2022Alternative \u00a0Hypothesis: \u00a0\u03bc\u00a0<\u00a0\u03bc0 R:\u00a0set\u00a0input\u00a0argument \u00a0of\u00a0the\u00a0test alternative = \"less\"Two\u2010tail\u00a0Test \u2022Null\u00a0Hypothesis: \u00a0\u03bc\u00a0=\u00a0\u03bc0 \u2022Alternative \u00a0Hypothesis: \u00a0\u03bc\u00a0\u2260\u00a0\u03bc0 R:\u00a0set\u00a0input\u00a0argument \u00a0of\u00a0the\u00a0test alternative = \"two.sided\" P = 1 - p \u03bc0P = p/2 P = p/2 \u03bc0-\u2026 \u03bc0+\u2026One\u2010sample\u00a0t\u2010Test\u00a0(Mean\u00a0Difference): \u00a0R \u2022Goal:\u00a0does\u00a0the\u00a0sample\u00a0belong\u00a0to\u00a0a\u00a0population \u00a0with\u00a0mean\u00a0 larger/smaller/different \u00a0than\u00a0a\u00a0reference \u00a0population \u00a0with\u00a0mean\u00a0 \u03bc0? Mann\u2010Whitney\u00a0test) \u2013one\u2010sample \u2013Two\u2010samples wilcox.test (\u2026) \u2013The\u00a0test\u00a0works\u00a0on\u00a0the\u00a0ranks\u00a0of\u00a0the\u00a0values \u2013The\u00a0input\u00a0and\u00a0output\u00a0is\u00a0the\u00a0same\u00a0as\u00a0the\u00a0t\u2010testTests\u00a0Based\u00a0on\u00a0Permutations \u2022In\u00a0the\u00a0previous\u00a0tests\u00a0we\u00a0have\u00a0always\u00a0tested\u00a0the\u00a0 difference \u00a0of\u00a0means\u00a0 \u2013between\u00a0populations, \u00a0 but\u00a0using\u00a0limited\u00a0knowledge \u00a0from\u00a0samples \u2022Thanks\u00a0to\u00a0the\u00a0central\u00a0limit\u00a0theorem, \u00a0we\u00a0knew\u00a0how\u00a0the\u00a0 sampling\u00a0mean\u00a0is\u00a0supposed \u00a0to\u00a0be\u00a0distributed \u2013normal\u00a0or\u00a0t\u2010student,\u00a0depending \u00a0on\u00a0sample\u00a0size \u2022What\u00a0if\u00a0we\u00a0are,\u00a0but\u00a0we\u00a0don\u2019t\u00a0know\u00a0how\u00a0the\u00a0sampling\u00a0 distribution?Tests\u00a0Based\u00a0on\u00a0Permutations \u2022A\u00a0common\u00a0approach \u00a0consists\u00a0of\u00a0permuting \u00a0the\u00a0class\u00a0 labels \u2022and\u00a0computing \u00a0the\u00a0count\u00a0ratio\u00a0of \u2013how\u00a0many\u00a0times\u00a0the\u00a0difference \u00a0observed \u00a0for\u00a0real\u00a0data\u00a0is\u00a0 also\u00a0observed \u00a0for\u00a0permuted \u00a0data \u2013the\u00a0number\u00a0of\u00a0permutations \u2022The\u00a0resulting\u00a0index\u00a0is\u00a0called\u00a0empirical \u00a0p\u2010valueTest\u00a0Summary \u00a0Tables Small Sample Population not  normally distr.Small Sample Population  normally distr.Large Sample (N \u2265 30) Wilcoxon test t-Test (t-Student, df = N- 1)z-Test (Standard Normal) Two-tail One-Tail SmallerOne-Tail Greater \u03bc \u2260 \u03bc0 \u03bc < \u03bc0 \u03bc > \u03bc0 One-sample \u03bc1\u2260 \u03bc2 \u03bc1< \u03bc2 \u03bc1> \u03bc2 Two-samplesALTERNATIVE HYPOTHESISTEST AND DISTRIBUTIONTest\u00a0Summary \u00a0Tables Sample units: dependentSample units: independent Paired Not PairedTYPE OF TWO-SAMPLE TEST  (T-TEST OR WILCOXON TEST ALIKE)Other\u00a0Tests \u2022Proportion \u00a0Test\u00a0(Bernoullian \u00a0Probability) \u2022Fisher\u2019s\u00a0Exact\u00a0Test\u00a0(2x2\u00a0contingency \u00a0tables) \u2022X2\u00a0Test\u00a0(2x2\u00a0or\u00a0larger\u00a0contingency \u00a0tables) \u2022Kolmogorov \u2010Smirnov\u00a0(distribution \u00a0inequality) \u2022\u2026Multiple\u00a0Testing \u2022Previously, \u00a0we\u00a0have\u00a0always\u00a0focused\u00a0on\u00a0single\u00a0tests \u2022If\u00a0we\u00a0test\u00a0many\u00a0independent \u00a0samples\u00a0from\u00a0the\u00a0same\u00a0 population, \u00a0some\u00a0of\u00a0them\u00a0will\u00a0lead\u00a0to\u00a0the\u00a0null\u00a0hypothesis \u00a0 rejection\u00a0 \u2022However, \u00a0even\u00a0if\u00a0the\u00a0null\u00a0hypothesis \u00a0is\u00a0TRUE,\u00a0 we\u00a0do\u00a0expect\u00a0a\u00a0rejection\u00a0rate\u00a0>\u00a00: M*\u03b1,\u00a0where\u00a0M\u00a0is\u00a0the\u00a0number\u00a0of\u00a0tests\u00a0performed \u2022How\u00a0to\u00a0account\u00a0for\u00a0this?Multiple\u00a0Testing:\u00a0 Bonferroni \u00a0Correction \u2022The\u00a0Bonferroni \u00a0correction \u00a0is\u00a0very\u00a0conservative: after\u00a0correction, \u00a0the\u00a0probability \u00a0of\u00a0finding\u00a0at\u00a0least\u00a0one\u00a0 false\u00a0positive\u00a0at\u00a0p\u2010value\u00a0\u2264\u00a0\u03b1\u00a0will\u00a0be\u00a0exactly\u00a0\u03b1 \u2022p\u2019\u00a0=\u00a0MIN\u00a0(p\u00a0*\u00a0M,\u00a01) \u2022This\u00a0correction \u00a0is\u00a0usually\u00a0overly\u00a0conservative \u00a0for\u00a0most\u00a0 genomic\u00a0applications \u00a0(e.g.\u00a0gene\u00a0expression \u00a0microarrays) \u2022It\u00a0is\u00a0sometimes \u00a0recommended \u00a0for\u00a0biomarkers \u00a0and\u00a0risk\u00a0 factorsMultiple\u00a0Testing:\u00a0 Benjamini \u2010Hochberg\u2019s \u00a0FDR \u2022The\u00a0Benjamini \u2010Hochberg \u00a0FDR\u00a0transforms \u00a0the\u00a0p\u2010value\u00a0into\u00a0 a\u00a0q\u2010value \u2022Let\u2019s\u00a0consider\u00a0the\u00a0q\u2010value\u00a0qi,\u00a0 that\u00a0is\u00a0the\u00a0false\u00a0positive\u00a0rate\u00a0when\u00a0considering \u00a0all\u00a0tests\u00a0 with\u00a0q\u00a0\u2264\u00a0qi \u2022qi=\u00a0MIN\u00a0(pi*\u00a0M\u00a0/\u00a0i,\u00a01) followed\u00a0by\u00a0monotonicity \u00a0correction \u00a0(i.e.\u00a0values\u00a0have\u00a0to\u00a0be\u00a0 monotonically \u00a0increasing)Multiple\u00a0Testing:\u00a0 Benjamini \u2010Hochberg\u2019s \u00a0FDR \u2022For\u00a0each\u00a0p\u2010value\u00a0pi \u2013Expected\u00a0number\u00a0of\u00a0false\u00a0positives\u00a0if\u00a0the\u00a0null\u00a0hypothesis \u00a0is\u00a0true: pi\u00a0*\u00a0M\u00a0(\u03b1\u00a0=\u00a0pi) \u2013Observed \u00a0number\u00a0of\u00a0positives: i( p1,\u00a0\u2026,\u00a0pi\u00a0\u2264\u00a0\u03b1) \u2013Ratio\u00a0between\u00a0expected\u00a0false\u00a0positives\u00a0and\u00a0observed \u00a0positives: pi\u00a0*\u00a0M\u00a0/\u00a0i\u00a0BH\u00a0FDR\u00a0correction http://en.wikipedia.org/wiki/False_discovery _rate#Benjamini.E2.80. 93Hochberg_procedureMultiple\u00a0Testing\u00a0in\u00a0R \u2022Input:\u00a0vector\u00a0of\u00a0p\u2010values # Bonferroni p.adjust (pvalue.nv, method = \"Bonferroni\") # Benjamini-Hochberg FDR p.adjust (pvalue.nv, method = \"BH\")Application \u00a0to\u00a0Microarray \u00a0Analysis \u2022For\u00a0the\u00a0typical\u00a0two\u2010class\u00a0design\u00a0 (e.g.\u00a0disease\u00a0vs.\u00a0control,\u00a0treated\u00a0vs.\u00a0untreated) \u00a0 we\u00a0can\u00a0test\u00a0every\u00a0gene\u00a0using\u00a0a\u00a0two\u2010sample\u00a0t\u2010test\u00a0 (not\u2010paired\u00a0or\u00a0paired) \u2013Each\u00a0biological \u00a0replicate\u00a0corresponds \u00a0to\u00a0a\u00a0sample\u00a0unit \u2022Since\u00a0the\u00a0number\u00a0of\u00a0replicates \u00a0is\u00a0typically\u00a0small,\u00a0 the\u00a0stdev\u00a0estimate\u00a0is\u00a0usually\u00a0unreliable Part\u00a0II:\u00a0Lecture\u00a0by\u00a0Dr\u00a0.Ben\u00a0Chandler\u00a0on\u00a0Oncomine \u00a0and\u00a0 Pathway\u00a0analysisStatistics\u00a0references \u00a0on\u00a0the\u00a0Web \u2022http://www.unt.edu/rss/class/Jon/ \u2022http://davidmlane.com/hyperstat/index.html \u2022http://faculty.chass.ncsu.edu/garson/PA765/statnote.ht m\u00a0 \u2022http://www.khanacademy.org/math/statistics \u00a0Statistical \u00a0Rethinking, \u00a0 McElreath Multivariate \u00a0generalizations \u00a0of\u00a0the\u00a0Wald\u2010 Wolfowitz \u00a0test\u00a0(example \u00a0in\u00a02D) \u2022Minimal\u00a0spanning\u00a0trees\u00a0(MST) Multivariate \u00a0generalizations \u00a0of\u00a0the\u00a0 Wald\u2010Wolfowitz \u00a0test\u00a0(example \u00a0in\u00a02D) \u2022Minimal\u00a0spanning\u00a0trees\u00a0(MST) Test statistic: how many edges of the MST, crossover between  two groups?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-4-Lecture01b-Exploratory Data Analysis.pdf",
      "summary": "https://www.amazon.com/Exploratory-Data- Analysis-John-Tukey/dp/0201076160Stem and Leaf Diagrams A stem-and-leaf plot of prime  numbers under 100 shows that the most  frequent tens digits are 0 and 1 while the  least is 9 https://en.wikipedia.org/wiki/Stem-and- leaf_display#/media/File:Stem-and- leaf_time_tables_in_Japanese_train_stations.jpgTechniques EDA Techniques: -Primarily graphical,  supplemented by  quantitative methods. - Strategic positioning of plots leverages our natural pattern-recognition abilities.Bihistograms Purpose of the adjoining histograms: \u25cfBi-histograms serve as a great alternative to two- sample t-test as it is a graphical way of  representing a variety of features of the subgroups  simultaneously on a single plot such as: \u2022Skewness \u2014 shows how distorted the normal  distribution of the two subgroups is. \u2022Location \u2014 shows at which point on the x-axis the  data of the two subgroups is centred. https://www.geeksforgeeks .org/introduction-to-bi- histograms/ Used to observe any changes occurring in the two  subgroups of data in terms of: \u2022Location (observed when performing t-test) \u2022Variation (observed when performing f-test) \u2022Distribution (observed when performing Kolmogorov- Smirnov test)Youden Plots The Youden plot can be used to answer the  following questions: \u25cfAre all labs equivalent? https://towardsdatascience.com/exploratory-data- analysis-visual-790990f64c7cExample: Anscombe quartet -Quantitative Analysis Shortcomings: - Identical summary statistics for all datasets: - Mean of X = 9.0, Mean of Y = 7.5 - Intercept = 3, Slope = 0.5 - Residual standard deviation \u2248 1.237 - Correlation \u2248 0.816 - Fails to reveal the true nature of the datasets! - Assumes uncorrelated data with a constant deterministic component and a random  component of fixed variation.Extending Univariate to Multivariate & Model Validation -Generalizing the Model: - The univariate model scales to multivariate scenarios where the deterministic component is a  complex function of variables. - Invalid assumptions lead to unpredictable processes and unreliable outcomes.Four Techniques to Test Underlying Assumptions -The following EDA techniques are simple, efficient, and powerful for the routine  testing of underlying assumptions: - run sequence plot (Yiversus i) - lag plot (Yiversus Yi-1) - histogram (counts versus subgroups of Y) - normal probability plot (ordered Y versus theoretical ordered Y)Interpreting the Run Sequence and Lag Plots -Testing Fixed Location and Variation: - Run Sequence Plot: - A flat, non-drifting pattern indicates a stable mean (fixed location). -Assessing Randomness: - Lag Plot: - A lack of discernible structure or pattern implies true randomness in the data.Interpreting the Histogram and Normal Probability Plot -Evaluating Distribution: -Histogram: - A bell-shaped distribution suggests symmetry and potential normality. -Normal Probability Plot: (or Q-Q plot with a reference normal) - Linearity in the plot supports the assumption of a normal distribution. - This indicates predictability and reliability in the process being analyzed.Example: Assumptions Hold This plot of 500 normal random numbers reveals a process that has fixed location, fixed variation, is random,  apparently has a fixed approximately normal distribution, and has no outliers. -Addressing Non-Randomness: - Recognizing non-randomness is the first step to rectifying model assumptions and ensuring  the integrity of the data analysis.Consequence of Non-Fixed Location Parameter -Location Parameter - The Mean: - Standard estimate of location:  -When Location Isn't Fixed: -Potential Drift: Location may change over time, making a single estimate unreliable. -Quality of Estimate: The standard deviation may not accurately reflect the true variability of the  data. Consequences Related to Distributional Assumptions -Consequences of Distributional Assumptions in Data Analysis - The Role of Distribution in Estimation: - Choice of location estimator (mean, median, etc.) - What are the parameter estimates for the distribution?PPCC (probability plot correlation coefficient) Plot -Purpose: To find the best shape parameter for a  distribution family. -Scanning all plots helps identify the strongest pairwise relationships.https://blogs.sas.com/content/graphicallyspeaking/2012/1 0/07/scatter-plot-matrix-with-a-twist/Scatter Plot Matrix -Structure: - Each cell in the matrix represents a scatter plot, with one variable on the x-axis and another on  the y-axis. -Note: -The conditioning plot goes beyond the scatterplot matrix by revealing the influence of a third variable  on the relationship between two other variables.Conditioning Plot -Purpose: - To investigate the relationship between two variables while considering the influence of a third variable. -Distribution: The shape of the histograms can suggest changes in the distribution, such as  skewness.https://www.geeksforgeeks.org/introduction-to-bi-histograms/Bihistogram -Detailed Observations: -From the sample bihistogram, batch 1 (top) shows a rightskew, while batch 2 (bottom) appears more  symmetric, possibly with a slight right skew. -Techniques: - Least Squares Fitting, Scatter PlotHomogeneity in Variance  (affects regression  assumptions) Plot with random data showing homoscedasticity: at  each value of x, they-value of the dots has about the  samevariance .Plot with random data showing heteroscedasticity: The  variance of the y-values of the dots increases with  increasing values of x.https://en.wikipedia.org/wiki/Homosceda sticity_and_heteroscedasticityTime Series -Data: - A column of time dependent numbers, Y. -Measures of Location, Confidence Limits for the Mean and One Sample t-Test, Two Sample t-Test  for Equal Means, One Factor Analysis of Variance, Multi-Factor Analysis of Variance -Scale (or variability or spread): (covered in Lec 1?) - More sensitive near the center of the distribution than at the tails.Distributional Measures: Kolmogorov-Smirnov Test -Test Statistic - F is the theoretical CDF of the distribution being tested. https://www.anyamemensah.com/blog/set-missing-valuesTypes and Patterns of Missing Data -Types of Missing Data: -MCAR (Missing Completely at Random): The missingness of data is independent of both  observed and unobserved data. -MAR (Missing at Random):  The propensity for a data point to be missing is not related to the  missing data, but is related to some of the observed data. -MNAR (Missing Not at Random): The missingness is related to the value of the variable that's  missing. -Pros and Cons: Easy to implement but distorts the distribution and underestimates variability.Advanced Imputation Techniques -K-Nearest Neighbors (KNN) Imputation: -Description: Imputes missing values based on the k-nearest neighbors found in the observed  portion of the dataset. -Pros and Cons: Provides a robust way to handle missing data by incorporating randomness  and producing valid statistical inferences.Model-Based Methods for Missing Data -Maximum Likelihood Estimation (MLE): -Description:  Estimates parameters by maximizing the likelihood function, accounting for the  missing data pattern. -Pros and Cons: Can provide accurate estimates but assumes that the missing data  mechanism is correctly specified.Iterative Imputation and Machine Learning -Iterative Imputation: -Description: A more sophisticated form of imputation that models each feature with missing  values as a function of other features in a round-robin fashion. -Pros and Cons: Useful when internal data is insufficient, but risks of incompatibility with  current data patterns.Practical Considerations in Handling Missing Data -Assessing Missing Data Mechanism: - Importance of understanding the underlying mechanism to choose the appropriate handling  method. - Consideration of the learning curve and community support for each tool.Sensitivity Analysis and Validation -Sensitivity Analysis: -Description: A method to test how sensitive conclusions are to different assumptions about  the missing data. Thank you!Quantile-quantile plot and KS test to test  equality of distributions A Q\u2013Q plot comparing the distributions  ofstandardized daily maximum  temperatures at 25 stations in the US  state of Ohio in March and in July. The  curved pattern suggests that the  centralquantiles are more closely  spaced in July than in March, and that  the July distribution is skewedto the left  compared to the March distribution. \u2022 Illustration with gene expression data.EDAWhat is PCA The goal of principal component analysis (PCA) is to  transform  a number of possibly correlated variables into a  smaller number of uncorrelated variables called principal  components. PCs are orthogonal (i.e. uncorrelated).EDAWhat does it mean for data to be  \"correlated\"?set.seed(2707) x1 <- rnorm(500,0,1) y1 <- rnorm(500,0,1) y2 <- 2*x1 + y1 y2 <- y2-mean(y2) y2 <- y2 / sd(y2) plot(x1, y1) plot(x1, y2) Opar <- par(no.readonly=TRUE) par(mfrow = c(2,2)) hist(x1) hist(y2) plot(x1, y1) plot(x1, y2) par(Opar) Correlations between real world data are ubiquitous, due to causal  relationships or confounding factors.EDAPCA and correlation Principal component analysis (PCA) converts a set of observations of possibly correlated  variables into a set of values of uncorrelated variables called principal components . The first principal component has as high a variance as possible  (that is, accounts for as  much of the variability in the data as possible); each succeeding component in turn has  the highest variance possible under the constraint that it be orthogonal  to (uncorrelated  with) the preceding components. Therefore the PCs provide a view on the structure of the data that best explains its  variance. Wikipedia: Principal component analysisEDAPCA and correlation The example data is  two-dimensional, but  most of the  information is  contained along a  dimension shown  here by the red vector. EDAInterpretation of PCs Given a set of points in Euclidean  space, the  first principal component   corresponds to a line that passes  through the multidimensional mean  and minimizes the sum of squares of  the distances of the points from the  line. One way to address this is to scale  variables to have unit variance.EDAapplication to gene expression (when you want to..) \u2022 Dimension reduction (simplify a dataset) \u2022 Clustering (too many samples) \u2022 Discriminant analysis (find a group of genes that  discriminates two categories)  \u2022 Exploratory data analysis tool (are there correlations) \u2022 Find the most important signal in data 2D projections  (clusters? )EDACrabs data The crabs data frame has 200 rows and 8 columns, describing 5  morphological measurements on 50 crabs each of two colour forms and  both sexes, of the species Leptograpsus variegatus  collected at Fremantle,  W.Australia. plot(crabs[, 4:8], pch=as.numeric(fac)) plot(crabs[, 4:5], pch=as.numeric(fac)) EDACrabs data There are four distinct groups of crabs in the data, but it seems difficult to tell them apart based on the  data.EDACrabs data pcaCrabs <- princomp(crabs[, 4:8]) plot(pcaCrabs) summary(pcaCrabs) > summary(pcaCrabs) Importance of components: Comp.1      Comp.2      Comp.3       Comp.4       Comp.5 Standard deviation     11.8322521 1.135936870 0.997631086 0.3669098284 0.2784325016 Proportion of Variance  0.9824718 0.009055108 0.006984337 0.0009447218 0.0005440328 Cumulative Proportion   0.9824718 0.991526908 0.998511245 0.9994559672 1.0000000000 EDACrabs data biplot(pcaCrabs, xlabs=as.numeric(fac)) legend(81, -63,c(\"1: B.F\", \"2: B.M\", \"3: O.F\", \"4: O.M\"), box.col=1, bg=\"lightgrey\") EDA Crabs data biplot(pcaCrabs, xlabs=as.numeric(fac), choices = c(1, 3)) legend(84, -63, c(\"1: B.F\", \"2: B.M\", \"3: O.F\", \"4: O.M\"), box.col=1, bg=\"lightgrey\")EDA crabs data biplot(pcaCrabs, xlabs=as.numeric(fac), choices = c(2, 3)) legend(-14.8, 16.2, c(\"1: B.F\", \"2: B.M\", \"3: O.F\", \"4: O.M\"), box.col=1, bg=\"lightgrey\")EDAapplication to gene expression CHO cell cycle data set for 384 genes (Cho et.al,  Molecular Cell, 1998). Exercise: include the first fivePCs in the same  plot.matplot(pcaCho$loadings[, 1:3],         type=\"b\", lwd=3,         ylab=\"PCs\") legend(14, -0.4,         c(\"PC1\", \"PC2\", \"PC3\"),        bg=\"lightgrey\",        col=1:3, lty=1:3, lwd=2,        pch=as.character(1:3))EDAapplication to gene expression Choose some  gene indices  and plot the  selected  expression  profiles  separately.EDAapplication to gene expression Sel1 <-c(73, 235, 83, 216) Sel2 <-c(86, 148, 72, 104) Opar <-par(no.readonly = TRUE) matplot(t(cho.data.std[Sel1, ]),  type=\"b\", lwd=3, col=\"1\", ylab=\"Clustered genes\", xlab = \"Timepoints\", ylim = c(-2, 3)) par(new=TRUE) matplot(t(cho.data.std[Sel2, ]), type=\"b\", lwd=3, col=\"2\", ylab=\"\", xlab=\"\", ylim = c(-2, 3)) par(Opar)EDAConclusion \u2022 PCA is a powerful tool for Exploratory Data Analysis (may need to  standardize data) \u2022 Can be very useful to detect confounding variables. \u2022Model based methods can be applied on the fly.EDAMulti-Dimensional Scaling (MDS) \u25cfSlides courtesy Prof. George Michailidis, University of Michigan EDAOverview of MDS \u25cfOriginated in psychometrics, where researchers wanted to visualize the \u2018similarity\u2019  space of various stimuli \u25cfAlso, widely used as a dimension reduction technique, when one is particularly  interested in visualizationEDAMDS as a dimension reduction technique \u25cfGoal is to map multidimensional space into few dimensions (usually 2-3) so as to be  able to visualize the results \u25cfIn addition, we want \u25cbCapture as much as possible of the underlying variation \u25cbHowever, the technique works very differently than PCAEDAMDS as a dimension reduction technique \u25cfMDS works by minimizing differences between inter- object distances in high and low dimensional space \u25cfFrom a mathematical point of view, borrows ideas from  distance geometryA cool application  (from Tenenbaum et  al.) EDASome additional remarks \u25cfThe only requirement in applying MDS is that some  basis exists for rating or ranking the objects in terms of  similarity/dissimilarity \u25cfObjects can be either observations or variables \u25cfAs long as the \u201cdistance\u201d between the objects can be  assessed in some fashion, MDS can be used to find the  lowest dimensional space that still adequately captures  the distances between objects. \u25cfOnce the number of dimensions is identified, a further  challenge is identifying the meaning of those  dimensions.Look at a trivial example (distances between European cities) Athens Berlin Dublin London Madrid Paris Rome Warsaw Athens 0 1119 1777 1486 1475 1303 646 1013 Berlin 1119 0 817 577 1159 545 736 327 Dublin 1777 817 0 291 906 489 1182 1135 London 1486 577 291 0 783 213 897 904 Madrid 1475 1159 906 783 0 652 856 1483 Paris 1303 545 489 213 652 0 694 859 Rome 646 736 1182 897 856 694 0 839 Warsaw 1013 327 1135 904 1483 859 839 0-3.00-2.00-1.00.001.002.003.00 -3.00 -2.00 -1.00 .00 1.00 2.00 3.00BerlinWarsaw RomeParis MadridLondonDublin AthensEDAExample (contd) \u25cfIn this example, the meaning of the dimensions is quite clear  (north-south, east-west) \u25cfThe technique successfully reconstructs the physical map. \u25cfMetric MDS \u25cfNon-metric MDS (more to come\u2026)EDAAn interesting application \u25cf30 biological samples and 7000 variables \u25cfCalculate correlation matrix (treating the objects as \u2018variables\u2019) \u25cfWe can examine the heatmap of the correlation matrix \u25cfThe correlation matrix can be thought of as a \u2018similarity\u2019 mapEDAA look at the math of MDS \u25cfMDS requires as input an NxN matrix of dissimilarities \u25cfIf we have similarities, then need to turn them to dissimilarities \u25cfIf dissimilarities satisfy the triangle inequality, then we are dealing with metric scaling,  otherwise with non-metric scaling \u25cfQuestions: how many dimensions are enough for embedding?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-5-JDSSV_V3_I1.pdf",
      "summary": "Open sharing not only allows results to be disseminated and built upon, but also allows scrutiny and verification of the research and is fundamental to the scientific process itself. For example, most of the journals sponsored by the Interna- tional Statistical Association and American Statistical Association require data and code be posted along with analysis (Journal of the American Statistical Association 2022). For example, the package may not be available for the current version of the language or dependencies of the package may fail to install. For example, troubleshooting failed installations of dependencies can often lead down a chain of fixing cryptic installation errors which is difficult even for an experienced user.Journal of Data Science, Statistics, and Visualisation 3 In addition to the challenges of taking analysis from one computer and running it on another, a second major challenge is difficulty understanding or interacting with code. Containerization is a flexible approach that allows one to encapsulate any format or organization of analysis according to their preferences and assessment of the best way to organize and share the analysis. While virtualization has been around for decades, containerization is the latest incarnation of the technology and comes with several key advantages over itsJournal of Data Science, Statistics, and Visualisation 5 predecessors. Containers only virtualize the high-level components of the operating system (e.g., code, configuration files, software and data) and seamlessly re-use the stable low-level processing components of the host operating system (Turnbull 2014). Indeed, starting up a container doesn\u2019t actually start up a second instance of an operating system; it largely just changes all references for re- sources, system libraries, files, and data, to refer to a particular isolated section of the computer. Furthermore, since starting a container largely just changes the references to resources in the environment, containers are user-friendly, start up nearly instantaneously, and run code at speeds nearly identical to the host computer (Felter et al. 2015). We will present an archetypal example of containerizing and sharing an analysis from three different perspectives: (1) the high- level view of sharing containerized analyses, (2) the end-user experience of interacting with a third-party containerized analysis, and (3) the first-party task of containerizing an analysis for dissemination. All of the data, code, dependencies, configurations and software are precisely set up as in the original environment, and thus set up to reproduce the analysis exactly. The goal of containerization is to ensure that if the code worked when containerized, it will work when the image is run by a third party. First, the container is downloaded and started with a single 1An \u201cimage\u201d refers to the actual file that may be uploaded, downloaded or shared, while a \u201ccon- tainer\u201d refers to an ephemeral instance running on the computer.6 Containerization for Reproducible Analysis imageimagecloudcontainer (Copy of Computing Environment) Original Computing Environment imagecontainerization(1) upload(2) download(3)run container(4)Original Analysis Third Party Figure 2: Typical sharing of containerized analysis. However, in addition to merely allowing inspection of the data or scripts, the container also comes with an installation ofRso that the user can actually run the code and analysis through the interactive notebook interface. It is important to keep in mind that while the end-user accesses the container and its contents through the web browser on the host computer, the data, code, software installations and back-end to the interface all actually reside in the container. The web browser merely provides a window into the running container through which one may use the tools installed in the container and interact with the code and data it contains. This is the power of sharing containerizing analyses \u2013 it allowsJournal of Data Science, Statistics, and Visualisation 7 (A) T erminalHost Computer Desktop (B) web browser code \ufb01les-p: ports for browser Figure 3: Example of interacting with a containerized analysis. The container has the necessary data and code files and an installation of Rto run the analysis through this web interface. While the end-user may interact naturally with the analysis through a web-browser on the host computer, all of the code, files, and software reside in the container\u2019s pre-configured environment. In five lines the configuration specifies a base image with RandJupyteralready installed, installs a desired Radd-on package, copies over data and analysis code, and starts the Jupyter lab interface. On top of this base image one needs only to install the necessary software packages or language add-ons and copy over the data and code. Once the configuration file has been written, the image needs to be built, after which, (B) Building(A)base image with R and jupyter desired name Figure 4: (A) Example configuration file for building an image using Docker. First argument to COPYis location on host, second argument is desired location in container, the flag \u2013chownsets the ownership of the file to the container\u2019s user. While all of the containerization tools we discuss in this section can help provide a10 Containerization for Reproducible Analysis Table 1: Comparison of Docker, Singularity, and Podman for containerization of repro- ducible analyses. Otherwise, the added effort of interacting with analyses through a container has the potential to hinder the accessibility of the anal- ysis and code. Consequently, notebooks not only encourage good coding practices, but also facilitate a rich discussion of the code, its relation to the output, and the bearing of this outputJournal of Data Science, Statistics, and Visualisation 11 (A) RStudio Server (B) Jupyter Lab (C) Zeppelin  (1)  text   (2)  code  (3)  plots(1)  text   (2)  code   (3)  plots(1)  text   (2)  code   (3)  plots Figure 5: Interactive notebook environments run through the web browser using (A) RStudio Server , (B) Jupyter Lab , and (C) Zeppelin. While different notebook formats and software tools exist, all notebooks share the feature of organizing analysis as a sequence of chunks of (1) text or (2) code and its associated (3) output. Indeed, embedding output directly alongside the code allows one to document the entire analysis pipeline including expository plots such as diagnostic and exploratory plots that may inform small decisions made in the course of analysis. Nonetheless, documentation of these types of micro-decisions is important for properly documenting an analysis pipeline and is necessary for transparent and reproducible research (National Academies of Sciences and Medicine 2019). This can be useful in a research context where both code and output evolve over time and it is easy to mismatch ver- sions of results/figures to the correct versions of the underlying analysis. Another advantage of using notebooks for explaining and showcasing analysis is that they give users the option to run the code and explore it interactively. For example, one can pick a segment of the analysis they wish to explore, edit the chunk of code, run it, and observe the subsequent change in output. This can be used to provide a natural way to play with code in order to build up an understanding of how the code works and test the robustness of the analysis to alterations. However, if we containerize notebook software in addition to the code, data, and other dependencies, then we can bring the full power of popular coding environments as an interactive interface to our containerized analysis. This combination is the best of both worlds as it brings the native feel of doing analysis on one\u2019s own computer to completely self-contained and reproducible analyses. Furthermore, RStudiohas extensive support forreticulate , which allows analysis using both RandPythonat the same time in a shared computing environment.Journal of Data Science, Statistics, and Visualisation 13 An important distinction is the format of the notebook file and how it interacts with third-party software. This is useful for showcasing results because, unlike a traditional code scripts, the notebook has output embedded and one need not re-run the code to view the results. In particular, one cannot easily track changes to these notebooks in a human-readable format using version control software like Git since small changes to output can prompt a cascading change to hundreds of lines of the dense encoding. An advantage of such an approach is that the input code and commentary are saved in a human-readable format which is more versatile for edit- ing by general software and can be meaningfully tracked by version control schemes. Despite these format differences, from the viewpoint of interacting and exploring analyses all three of RStudio,JupyterandZeppelin have broadly similar behavior, and allow users to edit and run code chunks one at time, viewing output in-line in the editor. A common challenge when using notebooks is that chunks need to be run sequentially and so to explore chunks later in the analysis one needs to run earlier time-intensive14 Containerization for Reproducible Analysis code. Once running, the container is accessible through the host computer\u2019s web browser where a start-page offers several options to interact with the analysis including browsing the files (e.g., to view the HTML rendering) or opening the notebooks in a graphical interface like JupyterorRStudio. While a small amount of time would need to be devoted to teaching students some simple mechanics of containerization, in our estimation this is not more complicated than other coding tasks required in many courses and would provide an opportunity for a discussion with students about research reproducibility, replicability as well as good coding practices. It also provides an opportunity to re-run the analysis in a hands-off manner to ensure that the notebooks and the entire code pipeline actually correctly produce the results when run sequentially."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-6-A_meta-analysis_of_GFR_slope_as_a_surrogate_endpoint_for_kidney_failure.pdf",
      "summary": "In an analysis of individual participant data, for each of 66 studies (total of 186,312 participants), we estimated treatment effects on the total GFR slope, computed from baseline to 3\u2009years, and chronic slope, starting at 3\u2009months after randomization, and on the clinical endpoint (doubling of serum creatinine, GFR\u2009<\u200915\u2009ml\u2009min \u22121 per 1.73\u2009m2 or kidney  failure with replacement therapy). e-mail: lesley.inker@tuftsmedicine.orgNature Medicine | Volume 29 | July 2023 | 1867\u20131876 1868 Analysis https://doi.org/10.1038/s41591-023-02418-0studies in diabetes, CKD and GN, but not for CVD, there was an average  benefit of the active treatments on the 3-year total slope and on the  chronic slope compared to the control arms under a random-effects  meta-analysis (Fig. Over the full study duration,  a total of 11,396 (6.1%) patients reached the primary clinical endpoint,  defined as the composite of kidney failure with replacement therapy  (KFRT) (initiation of chronic treatment with dialysis or kidney trans - plantation); sustained GFR\u2009<\u200915\u2009ml\u2009min\u22121 per 1.73\u2009m2; or doubling of  serum creatinine (equivalent to 57% decline in GFR). Trial-level analysis in the overall study population We used Bayesian mixed-effects meta-regression analyses to relate the  treatment effects on the clinical endpoint to the treatment effects on the total and chronic GFR slopes across the 66 studies 41. The slope of the meta-regression line was \u22120.35\u2009ml\u2009min\u22121 per  1.73\u2009m2 per year (95% BCI \u22120.42 to \u22120.29), indicating that a 0.75\u2009ml\u2009min\u22121  per 1.73\u2009m2 per year greater beneficial effect of the treatment on the  total GFR slope is associated with an average 23.3% lower HR for the clin - ical endpoint (95% BCI 19.3\u201327.2%). The intercept of the meta-regression  was \u22120.04 (95% BCI \u22120.09 to 0.01), indicating that, in the absence of a  treatment effect on the 3-year total slope, the average treatment effect  on the clinical endpoint is likely to be small (that is, 95% probability for  the HR to be between 0.91 and 1.01). The slope of the meta-regression line dif- fered substantially from 0, at \u22120.33 (95% BCI \u22120.46 to \u22120.20), indicating  that a 0.75\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year greater beneficial treatment  effect on the total GFR slope is associated with an average 21.8% lower  hazard for the clinical endpoint (95% BCI 14.1\u201329.4%). The intercept of  the regression line is nearly indistinguishable from 0 (\u22120.01, 95% BCI  \u22120.10 to 0.10), indicating low risk of a false-negative conclusion of the  absence of a treatment effect on the clinical endpoint when there is no  treatment effect on chronic slope (that is, 95% probability for the HR to be between 0.90 and 1.10). Together, these data have the potential to strengthen the evidence  for the validity of GFR slope as a surrogate endpoint for kidney failure,  providing support for its use as a primary endpoint for trials of CKD  progression across a broad series of settings. Studies of patients with CKD from other causes or cause not speci - fied reported lower mean estimated glomerular filtration rate (eGFR)  than the studies of patients with diabetes, glomerular diseases (glo - merulonephritis (GN)) or cardiovascular disease (CVD), and studies of  patients with CVD reported lower levels of urine albumin-to-creatinine  ratio (ACR) and slower progression than the other disease groups (Table 1   and Supplementary Table 4). Treatment effects on the GFR slope and the clinical endpoint Patterns of change in GFR (GFR slope) after initiation of an interven - tion are often nonlinear, with possibly differing direction and rates  of changes in early follow-up (herein called acute slope) versus  longer-term follow-up (herein called chronic slope)39. We used a shared-parameter  mixed-effects model to estimate the effects of the treatment on the  total GFR slope at 3\u2009years (herein called 3-year total slope), as this was the approximate mean length of the included studies and on chronic slope, computed from 3\u2009months after randomization 8,40. The median inter- cept of the meta-regressions for both chronic slope and total slope  were now negative and had credible intervals that did not overlap 0,  indicating that, on average, a modest benefit on the clinical endpoint  may be present in the absence of a treatment effect on GFR slope. For both  the 3-year total slope and the chronic slope, for each disease group the  BCIs for the meta-regression slopes do not cross 0, and the BCIs for the  meta-regression intercepts do cross 0 (Table 2  and Fig. CKD refers to diseases other than diabetes or glomerular disease or cause not yet specified.Nature Medicine | Volume 29 | July 2023 | 1867\u20131876 1870 Analysis https://doi.org/10.1038/s41591-023-02418-0there is a suggestion of modest heterogeneity among the posterior  distribution of the meta-regression slopes (range for median slope  from \u22120.24 for diabetes to \u22120.48 for CVD) and intercepts (range for  median intercept from \u22120.12 for GN to 0.04 for CVD) across the dis - ease groups but with widely overlapping BCI. Assessment of model adequacy and outliers We evaluated model adequacy and identified potential outliers by  comparing, for each study, the observed HRs for the clinical end - point to the posterior predictive distribution (PPD) for the esti - mated treatment effect on the clinical endpoint computed under  a meta-regression model fit with that study left out. For the 3-year  total slope, nine (13.6%) of 66 studies had observed HRs that fell out - side of the middle 90% intervals of the PPD; for the chronic slope,  10 (15%) of the observed HRs fell outside of the 90% intervals (Sup - plementary Table 8). Prediction intervals and positive predictive value For application of these results to the use of slope as a surrogate end- point in a future trial, we applied the above meta-regression results to  compute Bayesian prediction intervals (BPIs) that provide a 95% prob - ability of including the true treatment effect on the clinical endpoint,  for varying estimated treatment effects on the slope endpoints for  hypothetical large (total sample size of 1,600), medium (total sample size of 800) and small (total sample size of 400) trials.As expected, with greater treatment benefit on GFR slope, the  estimated treatment benefit on the clinical endpoints also increases  (Table 3 and Supplementary Table 11). For example, in a large future trial, the 95% BPI for the HR on  the clinical endpoint associated with an estimated treatment effect  of 0.75\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year definitively excludes an HR of 1 or  greater for the 3-year total slope (0.60\u20130.89) but not the chronic slope  (0.51\u20131.18). Similarly, the threshold for a treatment effect on the GFR  slope to assure the posterior probability of a clinical benefit, which  we defined as an HR for the clinical endpoint of less than 1, of greater  than or equal to 97.5% is substantially smaller for the 3-year total slope  than for the chronic slope (0.44\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year versus  1.26\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year). Within the different disease groups, the 95% BPI for the HR on  the clinical endpoint associated with an estimated treatment effect  of 0.75\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year is also wider for the chronic slope  than for the 3-year total slope (Extended Data Table 7). The magnitude  of the difference is smaller for the CKD (chronic slope versus 3-year  total slope (0.54\u20130.96) versus (0.57\u20130.90)) and diabetes ((0.63\u20131.13)  versus (0.59 to 0.93)) disease groups compared to that for the CVD  ((0.30\u20131.52) versus (0.61\u20130.97)) and GN ((0.34\u20131.12) versus (0.52\u20130.95))  disease groups. We found that with analysis of  GFR slope using a robust method for each study, treatment effects on  the total slope computed at 3\u2009years accounted for an estimated 97%  of the variation between studies in treatment effects on the clinical  endpoint, with similar results across CKD severity and diverse disease  groups. Our results indicate potential concerns with the use of the chronic  slope, which ignores the acute effect of a drug on the GFR slope\u2014an  indication that the acute reduction in GFR due to treatment initiation  might affect the clinical endpoint. Together, these data pro - vide the necessary evidence to support use of total GFR slope in RCTs  evaluating therapies of CKD progression as a valid, fit-for-purpose and  robust surrogate endpoint that can be presented to regulatory agen- cies for approval for marketing authorization, to payors to support funding of these therapies and to healthcare professionals and patients  to inform of their benefit in slowing CKD progression and preventing  kidney failure. The  earlier analyses demonstrated that treatment effects on chronic  slope accounted for a median 96% (95% BCI 63\u2013100%) of the varia - tion between studies in treatment effects on the clinical endpoint,  similar to that of the total slope in those prior analyses (97% (95% BCI  78\u2013100%)) (ref. Because the total slope includes both the acute and  chronic GFR slope, the superior performance of total slope compared  to chronic slope in the current analysis of a more diverse set of studies  suggests that the acute effect might be correlated with a component  of the primary clinical endpoint. Table 2 | Trial-level analysis by subgroups Group Subgroup Number of studies  (number of interventions)Meta-regression slope Intercept R2RMSE Total slope computed over 3\u2009years Overall 66 (17) \u22120.35 (\u22120.42, \u22120.29) \u22120.04 (\u22120.09, 0.01) 0.97 (0.82, 1.00) 0.05 (0.02, 0.12) Disease CKD 28 (9) \u22120.36 (\u22120.52, \u22120.25) \u22120.05 (\u22120.14, 0.04) 0.91 (0.51, 1.00) 0.06 (0.01, 0.14) Diabetes 21 (10) \u22120.32 (\u22120.42, \u22120.21) \u22120.05 (\u22120.12, 0.01) 0.89 (0.49, 1.00) 0.06 (0.01, 0.16) Glomerular 10 (2) \u22120.33 (\u22120.46, \u22120.22) \u22120.06 (\u22120.32, 0.07) 0.99 (0.85, 1.00) 0.06 (0.01, 0.23) CVD 7 (5) \u22120.34 (\u22120.43, \u22120.25) \u22120.02 (\u22120.10, 0.10) 0.98 (0.82, 1.00) 0.05 (0.01, 0.15) GFR <60 40 (14) \u22120.30 (\u22120.44, \u22120.14) \u22120.07 (\u22120.17, 0.01) 0.83 (0.25, 0.99) 0.06 (0.02, 0.13) \u226560 26 (11) \u22120.37 (\u22120.46, \u22120.28) \u22120.02 (\u22120.11, 0.07) 0.98 (0.83, 1.00) 0.06 (0.01, 0.19) Restricted to studies with ACR available55 (14) \u22120.35 (\u22120.45, \u22120.27) \u22120.07 (\u22120.14, \u22120.01) 0.96 (0.75, 1.00) 0.06 (0.02, 0.14) Restricted to studies with ACR available and participants with ACR\u2009>\u200930\u2009mg\u2009g \u2212155 (14) \u22120.34 (\u22120.44, \u22120.23) \u22120.06 (\u22120.13, 0.02) 0.95 (0.69, 1.00) 0.05 (0.02, 0.13) Chronic slope Overall 66 (17) \u22120.33 (\u22120.46, \u22120.20) \u22120.01 (\u22120.10, 0.10) 0.55 (0.25, 0.77) 0.19 (0.13, 0.27) Disease CKD 28 (9) \u22120.33 (\u22120.53, \u22120.15) \u22120.06 (\u22120.19, 0.06) 0.74 (0.18, 0.99) 0.09 (0.01, 0.20) Diabetes 21 (10) \u22120.24 (\u22120.37, \u22120.12) 0.02 (\u22120.09, 0.14) 0.71 (0.23, 0.99) 0.11 (0.02, 0.22) Glomerular 10 (2) \u22120.41 (\u22120.83, \u22120.20) \u22120.12 (\u22120.50, 0.10) 0.96 (0.23, 1.00) 0.12 (0.01, 0.57) CVD 7 (5) \u22120.48 (\u22121.33, \u22120.07) 0.04 (\u22120.14, 0.27) 0.47 (0.01, 0.99) 0.23 (0.05, 0.53) GFR <60 40 (14) \u22120.15 (\u22120.27, \u22120.03) \u22120.12 (\u22120.23, \u22120.03) 0.47 (0.02, 0.94) 0.09 (0.02, 0.18) \u226560 26 (11) \u22120.56 (\u22120.80, \u22120.33) 0.12 (\u22120.03, 0.29) 0.77 (0.35, 0.95) 0.23 (0.11, 0.38) Restricted to studies with ACR  available55 (14) \u22120.30 (\u22120.44, \u22120.18) \u22120.04 (\u22120.14, 0.07) 0.65 (0.30, 0.88) 0.15 (0.08, 0.24) Restricted to studies with ACR available and participants with  ACR\u2009>\u200930\u2009mg\u2009g \u2212155 (14) \u22120.22 (\u22120.35, \u22120.11) \u22120.07 (\u22120.18, 0.03) 0.66 (0.21, 0.94) 0.12 (0.03, 0.21) To convert ACR in mg\u2009g\u22121 to mg\u2009mmol\u22121, multiply by 0.113.Nature Medicine | Volume 29 | July 2023 | 1867\u20131876 1872 Analysis https://doi.org/10.1038/s41591-023-02418-0In such circumstances, the chronic slope may represent the more  conservative endpoint39. The observation of weaker associations for chronic slope in the  CVD group might suggest that the less favorable results for the chronic  slope in the current analysis compared to earlier analyses may be  related to inclusion of these studies. The strength of this  evidence is indicated in the lower limit for the 95% credible interval  for the trial-level R2 of 0.82, an increase from 0.78 in our prior results,  now substantially exceeding the threshold of 0.72 proposed for a  strong surrogate43. First, we evaluated the associa - tion between the treatment effects on GFR slope and on the clinical end - points ascertained over the average follow-up period of approximately  3 years for the trials included in our analysis. Second, our calcula - tions of the prediction intervals and trial-level positive predictive  value (PPV) for a future trial assume that the relationship between the  treatment effects on the slope and clinical endpoints is similar between  the future trial and the previously conducted trials. Studies should evaluate it as  an indicator of treatment effects before widespread use in clinical trials.Table 3 | Application of GFR slope as a surrogate endpoint in a new RCT: predicted treatment effect on clinical endpoint   and PPV GFR slope Observed treatment  effect on change in GFR  slopeLarge RCT Medium RCT Small RCT Median HR and 95% BPIPPV trial Median HR and  95% BPIPPVtrial Median HR and 95% BPIPPV trial Total slope computed at  3\u2009years0.5 0.80 (0.66, 0.98) 0.98 0.80 (0.62, 1.03) 0.96 0.80 (0.58, 1.12) 0.91 0.75 0.74 (0.60, 0.89) 1.00 0.74 (0.57, 0.94) 0.99 0.74 (0.53, 1.02) 0.97 1 0.68 (0.54, 0.82) 1.00 0.68 (0.52, 0.86) 1.00 0.68 (0.48, 0.93) 0.99 Threshold for treatment effect on GFR slope  associated with 97.5% probability of clinical  benefit0.44 0.58 0.79 Chronic slope0.5 0.84 (0.55, 1.28) 0.80 0.84 (0.54, 1.32) 0.78 0.84 (0.51, 1.40) 0.75 0.75 0.78 (0.51, 1.18) 0.89 0.78 (0.49, 1.22) 0.87 0.78 (0.47, 1.29) 0.84 1 0.72 (0.47, 1.09) 0.94 0.72 (0.45, 1.12) 0.93 0.72 (0.43, 1.18) 0.91 Threshold for treatment effect on GFR slope associated with 97.5% probability of clinical  benefit1.26 1.35 1.51 Units of GFR are ml\u2009min\u22121 per 1.73\u2009m2. The PPVtrial should be interpreted in relation to estimated probabilities of clinical benefit of 0.67, 0.63 or 0.60  for large, median and small RCTs, respectively, when there is no estimated treatment effect on the 3-year total slope, or 0.51, 0.51 and 0.52 when there is no estimated treatment effect on the chronic slope.Nature Medicine | Volume 29 | July 2023 | 1867\u20131876 1874 Analysis https://doi.org/10.1038/s41591-023-02418-0In aggregate, the results presented here indicate that GFR slope  can be used as a validated surrogate endpoint for CKD progression. The  selection of total slope versus chronic GFR slope, and the duration of time   over which the total GFR slope is computed, should be made with con- sideration of the study design, population and intervention under inves - tigation and in the context of the specific drug development program. Overview Our meta-analytic approach followed seven main steps: (1) search and  identify data from published RCTs using a standardized approach; (2)  obtain agreement for use of individual data and transfer to the Data  Coordinating Center at Tufts Medical Center or identify methods  for cloud-based data access; (3) within each RCT, use intent-to-treat  analyses to estimate (a) the effect of the treatment on GFR slope under  a shared-parameter mixed-effect model and (b) the effect of the treat - ment on clinical endpoint (defined as a composite of kidney failure,  sustained GFR\u2009<\u200915\u2009ml\u2009min\u22121 per 1.73\u2009m2 or doubling of serum creatinine)  under a Cox proportional hazards regression model; (4) quantify the  association between treatment effects on the GFR slope and treatment  effects on clinical endpoints across RCTs using trial-level Bayesian  meta-regression analysis; (5) identify outliers and evaluate model ade- quacy across the individual trials by using a cross-validation approach  to compare the observed treatment effect on the clinical endpoint in  each trial to the PPD for that trial derived from the trial-level model fit to the remaining trials; (6) quantify the consistency in these associa-tions across disease subgroups using Bayesian meta-regression with partial pooling; and (7) assess the utility of using slope as a surrogate  endpoint in a future trial by providing 95% Bayesian prediction intervals  and trial-level PPVs corresponding with a range of possible treatment effects on the slope endpoint in a hypothetical future trial. The analytic approach is based on the causal association frame - work in which the validity of surrogate endpoints is evaluated based on  the relationship between the average causal effect of the treatment on  the surrogate endpoint and the average causal effect of the treatment  on the clinical endpoint across a population of RCTs. Confidence in the use  of these results for a future new trial is increased when the previously  conducted trials provide evidence that the treatment effect on the  clinical endpoint is consistently predicted from the treatment effect on  the surrogate across a broad collection of RCTs evaluating treatments  that operate through diverse mechanisms and across diverse patient  populations. In comparison to the prior analyses, the current set of studies includes populations with higher mean levels of GFR and populations at high risk for CVD.For each study, we defined the active treatment as the treatment  hypothesized to produce the greater reduction in the risk of the clini- cal endpoint. The exclusion of doubling of serum creatinine from the  secondary clinical endpoint assures that the remaining components  of the composite endpoint signify the occurrence or near-occurrence  of a kidney failure, considered to be the true clinical event, and reduces  the chance that that endpoint would be affected by large acute effects. Compared to the primary clinical endpoint, the secondary clinical  endpoint poses several challenges for our trial-level analyses, includ-ing: (1) treatment effects are estimated with reduced precision due to  fewer events, reducing statistical power, particularly for subgroup  analyses; (2) trial-level analyses are weighted even more heavily toward  the subgroup of trials with lower levels of baseline GFR, as KFRT and  GFR\u2009<\u200915\u2009ml\u2009min\u22121 per 1.73\u2009m2 are rare events for trials with high baseline  GFR; and (3) the competing risk of death will have a greater impact. For these reasons, the composite of KFRT and GFR\u2009<\u200915\u2009ml\u2009min\u22121 per  1.73\u2009m2 is treated as the secondary clinical endpoint, and the broader  composite, which includes doubling of serum creatinine in addition  to these two events, is designated as the primary clinical endpoint in these analyses. Differences  between the randomized groups in the mean GFR levels at 3-month  follow-up, the mean slopes from 3\u2009months onward and the estimated  mean changes from baseline to either 2-year or 3-year follow-up fac - tored by the follow-up duration represented the treatment effects on  the acute, chronic and total slopes, respectively. In studies in which at least 15  individuals died or reached KFRT, the model accounts for informative  censoring by these events by incorporating the mixed model for the  GFR measurements within a shared-parameter model in which the risk  of KFRT or death was assumed to be related to the random slopes and  intercepts of the GFR part of the model62,63. As described above, we applied the mixed-effects models to estimate the treatment effects on GFR slope  within each study by treatment arm, with treatment effects expressed  as differences in the mean GFR slopes between the treatment versus  control groups in units of ml\u2009min\u22121 per 1.73\u2009m2 per year. We next applied a trial-level Bayesian  mixed-effects meta-regression model to relate the treatment effects  on the clinical endpoint to the treatment effects on GFR slope with  study as the unit of analysis41,50. The model relates the treatment effects  on the two endpoints after accounting for the standard errors in the  estimated effects in each study and the correlation of these errors  with each other. The model includes two stages, where the  first stage relates the estimated treatment effects to the true latent  treatment effects within each trial and the second stage describes  the relationships between the true latent treatment effects across the  different trials. We let  \u03b8i and \u03b3i denote the true latent treatment effects on the clinical endpoint  and on the GFR slope in the i th trial and use \u0302\u03b8i and \u0302\u03b3i to indicate the  estimated effects obtained as described above. The first stage of   the model relates the estimated and true latent treatment effects in  the ith trial by: [\u0302\u03b8i \u0302\u03b3i]\u223cMVN([\u03b8i \u03b3i],[\u03c32 iri\u03c3i\u03b4i ri\u03c3i\u03b4i\u03b42 i]) Here, \u03c3i is the standard error of the estimated treatment effect on  the clinical endpoint; \u03b4i is the standard error of the estimated treatment effect on GFR slope in the i th trial; and ri is the correlation between these  estimated treatment effects. The second stage of the model characterizes the variation in the  true latent treatment effects on GFR slope and on the clinical endpoint  across the trials. This second stage is expressed as [\u03b8i \u03b3i]\u223cN([\u03bc\u03b8 \u03bc\u03b3],[\u03c32 \u03b8R\u03c3\u03b8\u03c3\u03b3 R\u03c3\u03b8\u03c3\u03b3\u03c32 \u03b3]) where \u03bc\u03b8 and \u03bc\u03b3 are, respectively, the means of the true latent treatment  effects on the clinical endpoint and on GFR slope in the population of  trials represented by this meta-regression; \u03c3\u03b8 and \u03c3\u03b3 are the standard  deviations of the true latent treatment effects across the population of trials; and R is the correlation between the true latent treatment effects  on the two endpoints. Based on this two-stage model, the slope and  intercept of the meta-regression line predicting the true latent treatment  effect on the clinical endpoint from the true latent treatment effect on  the surrogate endpoint are given by \u03b2\u2009=\u2009R\u03c3\u03b8/\u03c3\u03b3 and \u03b1\u2009=\u2009\u03bc\u03b8\u2009\u2212\u2009\u03b2\u03bc\u03b3, respec - tively, and the residual standard deviation or RMSE, which defines the  uncertainty in the treatment effect on the clinical endpoint given a par- ticular treatment effect on the surrogate endpoint, is RMSE = \u03c3\u03b8\u00d7(1\u2212R2)1 2. The priors for the mean treatment effects on the clinical endpoint  (expressed as a log HR) and on each GFR slope endpoint (expressed as  difference between treatment arms in ml\u2009min\u22121 per 1.73\u2009m2 per year)  were taken to be normal distributions each with mean 0 and variance  10,000; the priors for the variances of the treatment effects on the  clinical endpoint and on the GFR slope endpoints were each taken to  be inverse gamma distributions with shape parameter 0.261. The prior distribution for the clinical endpoint was  selected by the investigators to assign 1/3 prior probabilities each to  low treatment effect heterogeneity (which we defined as a treatment effect standard deviation on the log-scale \u22640.05), medium treatment  effect heterogeneity (defined as a treatment effect standard deviation  on the log-scale between 0.05 and 0.20) and high treatment effect  heterogeneity (defined as a treatment effect standard deviation on  the log-scale >0.20). We checked that the  prior distributions had only a small influence on the results by verifying  that the results of each analysis were similar under alternative inverse  gamma (0.001, 0.001) prior distributions for the variances for the  treatment effects on the clinical endpoint and on GFR slope. The meta-regression supports the validity of GFR slope  as a surrogate endpoint if (1) the slope of the meta-regression line has a large magnitude with a BCI that does not cross 0; (2) the intercept is  close to 0 and with a BCI that crosses 0, implying absence of a substan - tial average effect on the clinical endpoint when the treatment does Nature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0not affect GFR slope; and (3) the R2 of the meta-regression is large,  indicating strong associations (for example, >0.72) (ref. The meta-regression slope provides the mean difference in the log  HR for the clinical endpoint associated with each 1\u2009ml\u2009min\u22121 per 1.73\u2009m2  per year increment in the treatment effect on the GFR slope endpoint. The meta-regression intercepts provide the estimated mean log HR  for the clinical endpoint when the mean treatment effect on the GFR  slope endpoint is equal to 0. To assist with interpretation, we express  the impact under the meta-regression model of a 0.75\u2009ml\u2009min\u22121 per  1.73\u2009m2 difference in the treatment effect on GFR slope on the HR for  the treatment effect on the clinical endpoint using the formula: %DifferenceinHRforclinicalendpoint =100\u00d7(1\u2212exp(0.75 \u00d7(meta\u2212regressionslope ))) For example, a 0.75\u2009ml\u2009min\u22121 per 1.73\u2009m2 per year greater beneficial  effect of the treatment on the 3-year total GFR slope is associated with  an average 23%\u2009=\u2009100\u2009\u00d7\u2009(1\u2009\u2212\u2009exp(0.75\u2009\u00d7\u2009\u22120.35)) lower HR for the clinical  endpoint. In the extended partial-pooling model, the first stage again describes the relationship between the estimated treatment effects and the true latent treatment effects on the slope and clinical endpoints within each trial. The second stage includes separate meta-regressions that describe the relationship between the true latent treatment effects on the slope and clinical endpoints across the studies within each of the designated subgroups of trials. When the data suggest a small amount of variation in a particular meta-regression term (such as the meta-regression slope or intercept) between the subgroups, then the subgroup-specific posterior distributions for that term will be more distinct between subgroups due to a lesser degree of information sharing. For each study, we pro - duced a PPD for the estimated treatment effect on the clinical endpoint  based on the estimated treatment effect on GFR slope in that study and  the meta-regression model fit to the remaining trials with that study  held out. We graphically displayed the  actual observed effect on the clinical endpoint to an interval extending  from the 5th to the 95th percentile of the PPD for each trial, to display  how well the trial-level model predicts the treatment effect in a \u2018new  trial\u2019 based on a model developed from the remaining trials. We obtained 95% prediction  intervals for the treatment effect on the clinical endpoint given a par- ticular value for the true latent treatment effect on GFR slope by simu- lating the posterior distribution of \u03b1  + \u03b2  \u00d7 True.Effslope  + \u03940, where True. Effslope  is the true latent treatment effect on the GFR slope endpoint;   \u03b1 + \u03b2 \u00d7 True.Effslope  represents the predicted mean true latent treatment  effect on the clinical endpoint based on the meta-regression model;  and \u03940 is normally distributed with mean 0 and standard deviation  given by the RMSE from the meta-regression. This prediction interval accounts for uncertainty in the estimation  of \u03b1 and \u03b2  and in the RMSE that defines the meta-regression, as well  as uncertainty due to variation in the treatment effects on the clinical endpoint about the regression line for different trials. When the trial-level meta-regression is applied to a newly con - ducted randomized trial, there is an additional source of uncertainty  that results from imprecision in the estimation of the treatment effect  on GFR slope in the new trial. We obtained 95% prediction intervals for the true latent treatment  effect on the clinical endpoint in a new trial that take into account this additional uncertainty by again sampling from the posterior distribu- tion of \u03b1  + \u03b2  \u00d7 True.Effslope  + \u03940, but now assume that True.Effslope  has a  random distribution to reflect the uncertainty in its estimation in the  new trial instead of taking True.Effslope  to be a fixed value. Specifically, we  assumed that the posterior distribution of True.Effslope  is normally dis- tributed with mean equal to the estimated treatment effect on GFR slope  and standard deviation given by the standard error for the estimated  treatment effect on GFR slope based on the sample size. We used a similar sampling approach for the posterior distribution  of \u03b1 + \u03b2  \u00d7 True.Effslope  + \u03940 to estimate the probability that the treatment  effect of the clinical endpoint in the new trial, expressed as a log HR,  would fall below 0 (corresponding to a non-zero treatment benefit  with an HR for the clinical endpoint less than 1) given either the true  or the estimated treatment effects on GFR slope in the new trial. By considering the PPV as a function of  the estimated treatment effect on GFR slope, we determined the size of the smallest treatment effect on GFR slope that would be required to assure a PPV of at least 0.975 for a benefit on the clinical endpoint. The FSGS/FONT trial, HALT-PKD Study A and HALT-PKD Study B were conducted by the investigators of the respective studies and were supported by the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK). is the National Leader of the ASCEND-D and ASCEND-ND trials of GlaxoSmithKline and the PROTECT and DUPLEX trials of Travere and is a steering committee member for the Novartis APPLAUSE trial and the Vera Therapeutics ATACICEPT trial. Red triangles indicate studies where the estimated treatment effects are beyond the margins.Nature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 1 | Categories of disease by interventionNature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 2 | Mean slopes in treatment and control and treatment effect by intervention, causal disease and  subgroups\u2014total slope computed at 3\u2009years, total slope computed at 2\u2009years, chronic slope and acute slopeNature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 3 | Treatment effects on the clinical endpointNature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 4 | Trial-level analyses for the association between treatment effects on GFR slope over 2\u2009years and  treatment effects on the clinical endpoint by subgroupsNature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 5 | Trial-level results using secondary endpoint (that is, dialysis or GFR\u2009<\u200915 ml\u2009min\u22121 per 1.73\u2009m2)Nature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 6 | Trial-level analyses for the association between treatment effects on GFR slope and treatment  effects on the clinical endpoint by sensitivity excluding disease groupsNature Medicine Analysis https://doi.org/10.1038/s41591-023-02418-0Extended Data Table 7 | Application of GFR slope as surrogate endpoint in a new RCT: predicted treatment effect on clinical  endpoint and PPV for subgroup-specific analyses"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-6-gfr_in_healthy_aging__an_individual_participant.24.pdf",
      "summary": "CLINICAL EPIDEMIOLOGY www.jasn.org GFR in Healthy Aging: an Individual Participant Data Meta-Analysis of Iohexol Clearance in European Population-Based Cohorts Bj\u00f8rn O. Eriksen ,1,2Runolfur Palsson ,3,4Natalie Ebert,5Toralf Melsom,1,2 Markus van der Giet,6Vilmundur Gudnason ,4,7Olafur S. Indridason ,3Lesley A. Inker,8 Trond G. Jenssen,1,9Andrew S. Levey,8Marit D. Solbu,1,2Hocine Tighiouart,10,11and Elke Schaeffner5 Due to the number of contributing authors, the af \ufb01liations are listed at the end of this article. Methods We investigated the cross-sectional association between measured GFR, age, and health in persons aged 50 \u201397 years in the general population through a meta-analysis of iohexol clearance mea- surements in three large European population-based cohorts. The mean GFR was lower in older age by 20.72 ml/min per 1.73 m 2per year (95% con\ufb01dence interval [95% CI], 20.96 to 20.48) for men who were healthy versus 21.03 ml/min per 1.73 m2 per year (95% CI, 21.25 to 20.80) for men who were unhealthy, and by 20.92 ml/min per 1.73 m2per year (95% CI, 21.14 to 20.70) for women who were healthy versus 21.22 ml/min per 1.73 m2per year (95% CI, 21.43 to 21.02) for women who were unhealthy. Email: bjorn.od var.eriksen@unn.no Copyright \u00a9 2020 by the American Society of Nephrology 1602 ISSN : 1046-6673/3107-1602 JASN 31:1602 \u20131615, 2020 Downloaded from http://journals.lww.com/jasn by BhDMf5ePHKav1zEoum1tQfN4a+kJLhEZgbsIHo4XMi0hCywCX1AW nYQp/IlQrHD3i3D0OdRyi7TvSFl4Cf3VC1y0abggQZXdtwnfKZBYtws= on 04/25/2025or improved rather than lowered GFR in a signi \ufb01cant pro- portion of aging persons.5Although this suggests that good health may prevent age-related GFR decline, studiesof kidney biopsy specimens from living kidney donors dem-onstrate that a reduction in nephron number occurs from ayoung age even in the absence of disease. 6 Our current knowledge about aging and GFR in the general population mainly comes from cross-sectional studies per- formed decades ago, which have been summarized in a de-tailed review by Delanaye et al. 7Few, if any, of these studies were population based, and the number of participants olderthan 65 years was very small. Our aims were to study the association of GFR with age in healthy people and predict reference intervals for GFR in healthy aging acrosst h es t u d i e da g er a n g e .B e c a u s ei tw o u l dn o tb ep o s s i b l et operform a population-based study with a high number of trulyhealthy individuals in the oldest age groups, we designed thestudy to use a generalized additive regression model to adjustfor the association of comorbidity and risk factors with GFRand to predict the distribution of GFR in hypothetically healthy persons. Three eligiblecohorts were identi \ufb01ed: the Renal Iohexol Clearance Survey (RENIS) in Troms\u00f8 6 (RENIS-T6; n51632); 21the Berlin Ini- tiative Study (BIS; n5610);22and the Age, Gene/Environment Susceptibility \u2013Kidney Study (AGES-Kidney; n5819) (Figure 1).23 The RENIS cohort included a repeated GFR measurement in the RENIS follow-up study (RENIS-FU) after a mean follow- up of 5.6 years ( n51329).24The examinations in RENIS-T6 and RENIS-FU were both included in this investigation. The RENIS cohort included participants between 50 and 63 years of age at baseline from the sixth wave of a series ofpopulation surveys in the municipality of Troms\u00f8 in northernNorway. AGES-Kidney is a substudy of the AGES-II-Reykjavik Study, which was a follow-up of the population-based Reykjavik Study in Iceland.23T h er e s p o n s er a t ei nt h eA G E S - I I - R e y k j a v i kS t u d yw a s 71%,26and for those eligible for AGES-Kidney the response rate was 65%.23 The inclusion criteria for the three cohorts were similar, except AGES-Kidney excluded individuals receiving active cancer treatment, and BIS excluded persons that requirednursing care during daytime and nighttime. The people invited to AGES-Kidney and RENIS comprised random samples of the general population, and those invited to BIS comprised a random sample from the Allgemeine Ortskrankenkasse Nordost , which provides insurance cover- age to almost 50% of people older than 70 years in Berlin.22 Although participation was voluntary, the three cohorts ofexamined persons were all representative of their source pop-ulations. The prevalence of the most important chronic diseases in BIS was similar to that of all persons older than 70 years in the Allgemeine Ortskrankenkasse Nordost .28Also, the prevalence of diabetes,29myocardial infarction,30angina pectoris,30 stroke,31and cancer32were of a similar order of magnitude as in other German studies of chronic diseases in older adults. The participants in AGES-Kidney were younger, had lower systolic BP, and were less likely to be current smokers or have cardiovascular disease or diabetes than participants in AGES-II-Reykjavik who were not included.23The meanSigni \ufb01cance Statement In populations, mean GFR is lower in older age, but whether healthy aging is associated with preserved rather than lower GFR in some individuals is unknown. The mean and the 97.5th percentile of the GFR distribution were higher in older persons who were healthy than in those who wereunhealthy, but lower than in middle-aged people who were healthy.The GFR-age association was more negative in women than in men. 38The iohexol assays of the three studies were calibrated by reanalyzing thawed samples in the laboratory of the Department of Medical Biochemis- try, University Hospital of North Norway (UNN; Troms\u00f8,Norway). 38No calibration was found to be necessary for the BIS and RENIS samples, but the following equation was usedto calibrate the AGES-Kidney results to the UNN laboratory:log(iohexol UNN)520.09111.0253log(iohexol AGES).38This calibration resulted in a mean difference in GFR of only 0.87 ml/min from the original results. 33,36,40 eGFR was calculated from serum creatinine(eGFRcrea) using the CKD Epidemiology Collaboration equation.41 Statistical Analyses Characteristics of the study participants were provided at thetime of the GFR measurements, i.e., characteristics for the RENIS cohort was reported for both the baseline (RENIS-T6) and the follow-up (RENIS-FU) examination. 42The associations between GFR indexed for body surface area andage, sex, health status, and cohort membership were exploredin generalized additive regression models for location, scale, and shape (GAMLSS) using the gamV procedure from the mgcViz-package in R. 43,44 GAMLSS is a new regression method suitable for modeling the age-dependent distribution of variables. In brief, the mean andSD of the GFR distribution are modeled as separate functionsof the independent variables in the same regression model. In addition to investigating the association of the independent variableswith the mean of the GFR distribution as in ordinary regres-sion methods, GAMLSS makes it possible to investigate theirassociation with the SD of the distribution. The GFR-age associ-ation was de \ufb01ned as the difference in mean GFR per 1-year older age and is represented by the coef \ufb01cient for the age vari- able in the regression model. 45This criterion scores the models for \ufb01t to the data, but penalizes the score for the number of independent variables and complexity of the model. We\ufb01rst analyzed both the mean and the SD of the GFR distribution as functions of the main effects of age, sex, and thehealth status variable. In this model, statistically signi \ufb01cant main effects of all of the independent variables and the age-health status interac-tion were found for the mean of GFR ( P,0.05). To investigate the possibility of different associations be- tween age and GFR distributions across the cohorts, we in-cluded random effects for the interaction between age andcohort in the functions for both the mean and the SD ofGFR. This means that the GFR-age associations may differ between the cohorts, and adding this effect to the func-tion for the mean of the model improved the \ufb01t (AIC533306.61). Next, we tested interactions between age and sex, and health status and sex, for both the mean and SD in this model.Only the interaction between age and sex for the mean wasstatistically signi \ufb01cant ( P50.005). This was done for boththe mean and SD of GFR, but model \ufb01t was no better for these models than for the model without nonlinear terms(AIC533302.98 for the interaction between age and healthstatus; AIC 533304.35 for age and sex). Table 2 shows the observed median and the 2.5th and 97.5th percentiles for GFR according to the health statusvariable for each of the cohorts. Using GAMLSS regression, we analyzed the mean and the SD of the GFR distribution as functions of age, sex, cohort,and the health status variable (Table 3, Supplemental Table 3).The intercept of the model corresponds to the GFR estimatefor a 50-year-old woman who is unhealthy (Table 3). Beinghealthy was associated with a slightly lower mean GFR of3.25 ml/min per 1.73 m 2at age 50 years, but with a markedly higher GFR-age association of 0.30 ml/min per 1.73 m2per year, 1606 JASN JASN 31:1602 \u20131615, 2020CLINICAL EPIDEMIOLOGY www.jasn.org Downloaded from http://journals.lww.com/jasn by BhDMf5ePHKav1zEoum1tQfN4a+kJLhEZgbsIHo4XMi0hCywCX1AW nYQp/IlQrHD3i3D0OdRyi7TvSFl4Cf3VC1y0abggQZXdtwnfKZBYtws= on 04/25/2025as represented by the coef \ufb01cient for the interaction between age and health status in Table 3 ( P,0.001). The GFR-age association was less negative for menthan for women, being respectively 20.72 (95% CI, 20.96 to 20.48) versus 20.92 (95% CI, 21.14 to20.70) ml/min per 1.73 m 2per year for people who were healthy, and 21.03 (95% CI,21.25 to20.80) versus 21.22 (95% CI, 21.43 to21.02)ml/min per 1.73 m2per year for those who were unhealthy (P50.005 for the interaction between sex and the GFR-age association). Characteristics of the population-based cohorts Characteristic RENIS-T6aRENIS-FUaBIS AGES-Kidney Number of participants, n(%) 1622 (100.0) 1324 (100.0) 547 (100.0) 716 (100.0) Age, yr (SD) 58.1 (3.8) 63.6 (4.0) 78.4 (6.2) 80.3 (4.1) Male sex, n(%) 797 (49.1) 657 (49.6) 311 (56.9) 317 (44.3) Body weight, kg (SD) 79.7 (14.4) 79.4 (14.3) 77.3 (14.0) 77.1 (14.1)Height, cm (SD) 170.6 (8.7) 170.6 (8.7) 166.2 (8.5) 167.7 (9.4) Body mass index, kg/m 2(SD) 27.3 (4.0) 27.2 (4.1) 27.9 (4.3) 27.4 (4.3) Body surface area, m2(SD) 1.9 (0.2) 1.9 (0.2) 1.9 (0.2) 1.9 (0.2) Cardiovascular disease, n(%) Myocardial infarction 1 (0.1) 18 (1.4) 83 (15.2) 89 (12.4) Myocardial revascularization 5 (0.3) 26 (2.0) 93 (17.0) 113 (15.8)Angina pectoris 2 (0.1) 12 (0.9) 56 (10.2) 60 (8.4)Stroke 3 (0.2) 24 (1.8) 42 (7.7) 53 (7.4) Diabetes, n(%) 19 (1.2) 42 (3.2) 136 (24.9) 81 (11.3) Cancer, n(%) 76 (4.7) 120 (9.1) 123 (22.5) 134 (18.7) Hypertension, n(%) b692 (42.7) 693 (52.3) 503 (92.0) 623 (87.0) Systolic BP, mm Hg (SD) 129.7 (17.6) 130.7 (17.0) 144.9 (21.5) 142.3 (20.3) Diastolic BP, mm Hg (SD) 83.4 (9.8) 81.9 (9.3) 82.3 (13.0) 69.6 (10.7)Antihypertensive medication, n(%) 298 (18.4) 420 (31.7) 425 (77.7) 524 (73.2) Digoxin or digitoxin, n(%) 1 (0.1) 6 (0.5) 18 (3.3) 24 (3.4) Lipid-lowering medication, n(%) 106 (6.5) 232 (17.5) 202 (36.9) 287 (40.1) Antidiabetic medication, n(%) 0 (0.0) 11 (0.8) 99 (18.1) 44 (6.1) Smoking, n(%) Never 503 (31.0) 432 (32.6) 263 (48.1) 295 (41.2)Current 344 (21.2) 177 (13.4) 32 (5.9) 42 (5.9)Previous 775 (47.8) 715 (54.0) 252 (46.1) 379 (52.9) Absolute GFR, ml/min (SD) 104.0 (20.1) 98.5 (19.8) 64.8 (19.2) 66.7 (19.4) Body surface area \u2013indexed GFR, ml/min per 1.73 m 2(SD) 94.0 (14.4) 89.1 (14.5) 60.5 (16.3) 61.9 (16.6) CKD-EPI estimate of GFR based on creatinine, ml/min per 1.73 m3(SD) 94.9 (9.5) 88.2 (10.5) 68.8 (17.1) 65.5 (17.1) Urinary ACR $30.0 mg/g, n(%) 24 (1.5) 26 (2.0) 126 (23.0) 110 (15.4) Urinary ACR $300.0 mg/g, n(%) 1 (0.1) 2 (0.2) 19 (3.5) 15 (2.1) Data are shown as mean (SD) or n(%). The random effects in the model demonstrate there were differences between the cohorts with regard to the associationbetween GFR and male sex ( P50.003), in the GFR-age asso- ciation ( P50.03), and in the SD of the GFR distribution (P,0.001) (Supplemental Table 3). We repeated the analyses of the model shown in Table 3 with nonindexed GFR, measured in ml/min, as the dependentvariable and height and weight added as independent vari-ables. Measurements for both the baseline (RENIS-T6) and the follow-up examinations (RENIS-FU) of the same persons in the RENIS cohort are shown. In potential living kidney donors, point estimates between20.5 and 20.9 ml/min per 1.73 m 2per year have been found.51\u201353,56 \u201358 If adjustment for health status had eliminated the GFR-age association, this would have supported the hypothesis thatpoor health fully accounts for the \ufb01nding of lower mean GFR in old age. A similar \ufb01nding regarding the 95th percentile was observed in a study of po-tential living kidney donors by Chakkera et al. 59The results a r ea l s oc o n s i s t e n tw i t hh i s t o l o g i c \ufb01ndings in biopsies from living kidney donors, which indicate that nephron number islower at older age even in people who are apparently healthy,although the study by Denic et al. 6only included persons younger than 75 years and may not be representative of older healthy people in the general population. However, the study may have been biased by the use of creat- inine clearance for assessing GFR and the inclusion of patientswith diabetes in the healthy group. General additive mixed model analysis of GFR mean and SD in three population-based cohorts Variable b(95% CI) PValue Effect of independent variables on mean GFR 50-year-old female who was unhealthy (intercept) 98.91 (97.43 to 100.39) ,0.001 Age, per yr 21.22 (21.43 to 21.02) ,0.001 Healthy (yes/no)a23.25 (24.86 to 21.63) ,0.001 Male sex 20.82 (28.54 to 6.90) 0.84 Interaction between age and being healthya0.30 (0.18 to 0.43) ,0.001 Interaction between age and male sex 0.20 (0.06 to 0.34) 0.005 Effect of independent variables on the SD of GFR 50-year-old female who was unhealthy (intercept) 12.40 (10.53 to 14.61) ,0.001 Percentage change associated with each independent variable Age, per yr 20.1% (20.6% to 0.3%) 0.52 Healthy (yes/no)a218.6% ( 223.9% to 213.0%) ,0.001 Male sex 1.4% (23.5% to 6.6%) 0.59 GFR measured in ml/min per 1.73 m2. 7Accordingly, most previous studies of reference intervals for GFR have in- cluded few individuals older than 70 years and have made no distinction between healthy subjects and others.53,84 \u201386By con- trast, we used a statistical model to estimate the effects of diseaseand risk factors and to predict percentiles of GFR in personswho were healthy and between age 50 and 95 years. Because weadjusted for the heterogeneity between the cohorts, the predic-tions represent an average of the observations in three differentgeographic regions.A comparison between classi \ufb01cation of low GFR based on the 2.5th percentile for persons who are healthy in thisstudy and the currently accepted criterion for CKD stage 3\u20135( G F R ,60 ml/min per 1.73 m 2) shows that the criterion underestimates the prevalence of low GFR in women youn-ger than 67.1 years and in men younger than 70.8 years, andoverestimates the prevalence at higher ages (Figure 3).However, this is the result of applying a low percentile andar a t h e rs t r i c td e \ufb01nition of \u201chealthy \u201dto assess the effect of age on GFR under optimal physiologic conditions. Although the low number of persons who werehealthy in the highest age groups may have limited the powerof statistical tests for the interaction between age, health status, and other variables, it seems unlikely that we have failed to include a signi \ufb01cant number of very old persons who were healthy with preserved GFR that would have changed ourconclusion. 88However, even allowing for great variation and possible nonlinear individual GFR trajectories, the \ufb01nding that the 2.5th percentile in 50-year-old people who are healthy is sim-ilar to the 97.5th percentile in 95-year-old people who arehealthy (Figure 3) suggests that aging with preserved GFRacross this age span must be very uncommon. Levey reports grants from National Institute of Diabetes and Digestive and Kidney Diseases during the conduct of the study, grants from the National Kidney Foundation, and grants from Siemens, outside the sub-mitted work. Schaeffner ES, van der Giet M, Gaedeke J, T\u00f6lle M, Ebert N, Kuhlmann MK, et al.: The Berlin initiative study: The methodology of exploring kidney function in the elderly by combining a longitudinal and cross-sectional approach. Gerontology 48: 22\u201329, 2002 AFFILIATIONS 1Metabolic and Renal Research Group, University of Troms\u00f8 \u2013The Arctic University of Norway, Troms\u00f8, Norway 2Section of Nephrology, Clinic of Internal Medicine, University Hospital of North Norway, Troms\u00f8, Norway 3Division of Nephrology, Landspitali \u2014The National University Hospital of Iceland, Reykjavik, Iceland 4University of Iceland, Reykjavik, Iceland 5Institute of Public Health, Charit\u00e9 \u2013Berlin University of Medicine, Berlin, Germany 6Department of Nephrology, Charit\u00e9 \u2013Berlin University of Medicine, Berlin, Germany 7Icelandic Heart Association, Kopavogur, Iceland 8Division of Nephrology, Tufts Medical Center, Boston, Massachusetts 9Department of Organ Transplantation, Oslo University Hospital and University of Oslo, Oslo, Norway 10Institute for Clinical Research and Health Policy Studies, Tufts Medical Center, Boston, Massachusetts 11Tufts Clinical and Translational Science Institute, Tufts University, Boston, Massachusetts JASN 31:1602 \u20131615, 2020 GFR in Healthy Aging 1615www.jasn.org CLINICAL EPIDEMIOLOGY Downloaded from http://journals.lww.com/jasn by BhDMf5ePHKav1zEoum1tQfN4a+kJLhEZgbsIHo4XMi0hCywCX1AW nYQp/IlQrHD3i3D0OdRyi7TvSFl4Cf3VC1y0abggQZXdtwnfKZBYtws= on 04/25/2025"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-6-meta.pdf",
      "summary": "\u2022Meta analysis is a speci\ufb01c type of research synthesis in which the aim is to quantify a speci\ufb01c parameter or test a speci\ufb01c hypothesis of interest, using results from multiple quantitative sources, and objectively assessing uncertainty for all claims. If $H$ is the harmonic mean of the study-level variances, then the standard deviation of the inverse variance weighted average is $H\u02c6{1/2}/\\sqrt{2}$. \u2022If we are pooling $k$ independent estimates, the standard error of the inverse variance weighted average is $H\u02c6{1/2}/\\sqrt{k}$, where $H$ is the harmonic mean of the $k$ study-level variances. \u2013Include both negative and positive \ufb01ndings \u2013Reporting of quantitative \ufb01ndings (point estimates, standard errors) \u2013Reporting of methods \u2013De\ufb01nition of target study population, and inclusion/exclusion criteria \u2013Handling of confounding factors \u2013Generally exclude studies that are themselves research syntheses \u2013Multiple studies of the same subject pool are not independent \u2013Multiple studies by the same research team may not be independent \u2013Is it possible to include unpublished studies (pre-registration may make this possible) \u2013Publication language \u2013Select by date? \u2013The fact that underpins most p-value combining procedures is that if the null hypothesis is true, the p-value follows a uniform distribution on the interval $(0, 1)$. Under the global null hypothesis, $T$ follows a standard Cauchy distribution, and therefore can be transformed to a p-value using the CDF of the reference distribution. \u2022To account for study heterogeneity, a common approach to meta-analysis is therandom e\ufb00ects orhierarchical approach, in which we posit the model $\\hat{\\theta}_i = \\theta_i + s_i\\epsilon_i$, where the $\\theta_i$ are treated as random variables from a distribution with mean $\\theta$ and variance $\\tau\u02c62$, and the $\\epsilon_i$ are also random variables that are independent of the $\\theta_i$ and that follow a distribution with mean $0$ and variance $1$. If truncation is performed, the bias is positive, and is around 0.15 for very small meta-analyses, and becomes smaller as the number of studies in the meta-analysis grows. If study or study/arm characteristics are known, let $Z_{ij}$ be a vector of characteristics for arm $j$ in study $i$, and use a mean structure model such as $E[Y_{ij}] = \\mu + \\alpha_i + \\beta_j + \\gamma\u02c6\\prime Z_{ij}$ The overall model would be $Y_{ij} = E[Y_{ij}] + s_{ij}\\epsilon_{ij}$, where $s_{ij}$ is the reported standard error for $Y_{ij}$ and the $\\epsilon_{ij}$ are independent unit-standard deviation random terms capturing unexplained variation. When there are large number of treatments, we can visualize the data as a graph, where treatments $j$ and $k$ are connected in the graph if these two treatments are ever present in the same trial. This refers to the possibility that inconclusive studies or studies that contradict the dominant narrative are less likely to be published than studies that support the consensus point of view. \u2022If all studies are assessing the same e\ufb00ect, then the scatter of the standard error of the estimated treatment e\ufb00ect (on the vertical axis) against the estimated treatment e\ufb00ect (on the horizontal axis) can be used to assess publication bias. \u2022Some funnel plots use the precision as the vertical coordinate rather than the standard error (the precision is the reciprocal of the standard error)."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_0 - Pre-Reading Materials (Kelly Only)\\Unit-6-Statistics in Medicine - 2015 - Hoaglin - Misunderstandings about Q and  Cochran s Q test  in meta\u2010analysis.pdf",
      "summary": "Qis a key element of the popular DerSimonian\u2013Laird procedure for random-effects meta-analysis, but the assumptions of that procedure and related procedures do not reflect the actual behaviorof Qandmayintroducebias.TheDerSimonian\u2013Lairdprocedureshouldberegardedasunreliable.Copyright\u00a9 2015John Wiley & Sons,Ltd. In what follows, in the hope of correcting the misunderstandings, Section 2 gives the definition of Q and discusses its customary use in meta-analysis. Definition of Q In a meta-analysis of kstudies, the basic ingredients for Qare the studies\u2019 estimates of the effect and the estimated standard errors of those estimates. In the notation of Cochran [1], the effect estimate fromStudy iisx i,andthecorrespondingestimatedstandarderroris si(i=1,\u2026,k).Qmeasuresheterogeneity of the xiby summarizing their variation around a weighted mean, \u0304xw, in which the weight for xiis the reciprocal ofits estimated variance, wi=1\u2215s2 i: \u0304xw=\u2211k i=1wixi/\u2211k i=1wi. Cochran\u2019s1954 paper For an understanding of Q, it is helpful to examine the setting in William Cochran\u2019s 1954 paper, \u2018The Combination of Estimates from Different Experiments\u2019 [1]: \u2018This paper discusses one of the simpleraspects of the problem, in which there is sufficient uniformity of experimental methods so that the ith experiment provides an estimate x iof\ud835\udf07and an estimate siof the standard error of xi. The experiments may be, for example, determinations of a physical or astronomical constant by different scientists, orbioassayscarriedoutindifferentlaboratories,oragriculturalfieldexperimentslaidoutindifferentpartsofaregion.Thequantity x imaybeasimplemeanoftheobservations,asinaphysicaldetermination,or the difference between the means of two treatments, as in a comparative experiment, or a median lethaldose,oraregressioncoefficient.\u2019If\u2018thevaluesofthe x iagreeamongthemselveswithinthelimitsoftheir experimental errors\u2019,Cochran postulates \u2018anunderlying mathematical model of theform xi=\ud835\udf07+ei, where eiis the experimental error of xi. If the values of the xidiffer by more than can be accounted for bytheir experimental errors,werequirea model of theform xi=\ud835\udf07i+ei, where\ud835\udf07i, which might be called the \u201ctrue value\u201d in the ith experiment, varies from one experiment to another.\u2019Ifsuchvariationexists,Cochranreferstoitas\u2018an interaction [italicsoriginal]oftheeffectwith experiments\u2019. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License D.C.HOAGLIN account the purpose for which the combined estimate is to be made and the reasons for the presence of interaction,insofarasthesecanbediscovered. [illustrationsofinteractionsomitted]thecombinationofthe individual estimates is not a routine matter, but requires clear thinking about both the nature of the data and the function of the combined estimate. For the sorts of xithat Cochran discusses, the degrees of freedom ordinarily come from a mean square (e.g., the sample variance or the residual mean square of a regression). The development in Cochran\u2019s paper has implications for the distribution of Q, the standard error of \u0304xw, estimationofthe variance of the \ud835\udf07i, and potential bias in \u0304xw. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License D. C.HOAGLIN where\u0304xis the(unweighted) mean of the xiand\u0304s2is themean of the s2 i. Hedecomposes \ud835\udf122 total=k\u2211 i=1wix2 i according to \ud835\udf122 total=\ud835\udf122 homog+\ud835\udf122 assoc,i nw h i c h \ud835\udf122 homogassesses the degree of homogeneity among the k measures of association, and \ud835\udf122 assocassesses the significance of the average degree of association. They present fairly general expansions for the first two moments of Qin terms of the weights and the moments of the estimators of the two parameters. )Asanexample,theyapplytheirexpansionstotheriskdifference.On the basis of extensive simulations, they recommend approximating the null distribution of Qby a gammadistributionwhosefirsttwomomentsequaltheestimatesderivedfromtheexpansions.Theyfindthat the resulting test for homogeneity is substantially more accurate than the usual chi-squared test and other tests,especially when thestudies\u2019samplesizes aresmall or moderate. If, for example, the measure of effect size is the log of the odds ratio, they can (for each replication) calculate the study-specificestimates and their estimated variances, as the definition of Qrequires. On the other hand, in a study of confidence intervals (based on Qand other approaches) for the amount of heterogeneity in random-effects meta-analysis, with log-odds-ratio as the measure of effectsize,Viechtbauer[18]generated2 \u00d72tablesbysamplingfromapairofbinomialdistributions.Inapply- ing the asymptotic variance formula to estimate the within-study variances, he added 0.5 to each cell;but,surprisingly,theformulaforthe effect sizeestimatedid not includeany suchadjustment. In the setting of a random-effects model in which the within-study variance of each xiis\ud835\udf0e2and the between-study heterogeneity is \ud835\udf0f2, Higgins and Thompsonintroduced I2as an estimate of \ud835\udf0f2 \ud835\udf0f2+\ud835\udf0e2 (in practice, the within-study variance differs among studies, and \ud835\udf0e2is estimated by a \u2018typical\u2019 within- studyvariance,discussedinthesucceedingtext).Thequantity \ud835\udf0f2/(\ud835\udf0f2+\ud835\udf0e2)\u2018hasanappealinginterpre- tation as the proportion of total variation in the estimates of treatment effect that is due to heterogeneitybetweenstudies.\u2026Thisinterpretationmaybemadeapproximatelyforthestatistic I 2inthegeneralcase Copyright \u00a92015 John Wiley&Sons, Ltd. Statist. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License D. C.HOAGLIN [inwhichthewithin-studyvariancediffersamongstudies].\u2019Withthisformulationof I2,thenullhypoth- esis that\ud835\udf0f2=0 implies that I2=0, and it is easy to interpret a positive value of I2as representing heterogeneity. Even if the null distribution of Qwere chi-squared on k\u22121 degrees of freedom, the probability of values exceeding the mean ( k\u22121)would not be small. If one desires to retain E[ Q] under the null hypothesis as the threshold for positive values of I2,t h e nE [ Q] will have a separate expression for each measure of effect, and, further, each meta-analysis (with the same measure of effect) will potentially yield a different estimate of E[ Q] (with variability totakeintoaccount). Because theyusethe moment-basedestimateof \ud835\udf0f2[20], \u0302\ud835\udf0f2 DL=Q\u2212(k\u22121) \u2211wi\u2212\u2211w2 i\u2211wi (with\u0302\ud835\udf0f2 DL=0w h e n Q<k\u22121), the definition of s2is precisely the one that makes the two expressions forI2equivalent: \u0302\ud835\udf0f2 \u0302\ud835\udf0f2+\u0302\ud835\udf0e2=Q\u2212(k\u22121) Q. Itisinstructivetoconsiderthesenseinwhich s2isa\u2018typical\u2019within-studyvariance.Onewouldnaturally expect it to be some sort of weighted average of the s2 i=1/wi.I nf a c t , s2is a weighted harmonic mean of the s2 iwith weights(\u2211wi\u2212wi)/[(k\u22121)\u2211wi]: 1 s2=1 k\u22121\u22111 s2 i( 1\u2212wi\u2211wi) . See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License D.C.HOAGLIN SE[ln(H)] =1 2ln(Q)\u2212ln(k\u22121)\u221a (2Q)\u2212\u221a (2k\u22123)ifQ>k \u221a{ 1 2(k\u22122)( 1\u22121 3(k\u22122)2)} ifQ\u2a7dk.\u2019 Method III in the appendix (pages 1554 and 1555) \u2018is based on a normal approximation to the \ud835\udf122 distributionforlargedegreesoffreedom: Z=\u221a (2Q)\u2212\u221a (2k\u22123)hasapproximatelyastandardnormal distribution (formula 26.4.13 in Abranowitz [sic] and Stegun [22]), so equating Zwith(ln(Q)\u2212ln(k\u2212 1))\u2215SE[ln(Q)],[they] estimateastandarderrorfor ln( Q)using SE[ln(Q)] =ln(Q)\u2212ln(k\u22121)\u221a (2Q)\u2212\u221a (2k\u22123) Now, since Q=(k\u22121)H2,a n d kis a constant, [they] have var[ln(Q)] =4var[ln(H)]and hence a test-basedstandarderrorfor ln( H)is SE1[ln(H)] =1 2ln(Q)\u2212ln(k\u22121)\u221a (2Q)\u2212\u221a (2k\u22123) Adrawbacktothetest-basedstandarderroristhatitapproacheszeroas Happroaches1,whereas[they] define Hto be 1 whenever Q\u2a7dk\u22121. (1) Miettinen[23]devisedtest-basedconfidencelimitstoavoidcomplexcalculations.Heobtainedthe standard error by standardizing a variance-stabilized function of the point estimate and equatingthe square of that quantity and the value of another statistic that tested the same null hypothesis andhadthechi-squareddistributionon1degreeoffreedomasitsnulldistribution.Inthisinstance, thetwostatisticshave(approximately)thestandardnormaldistribution.Theright-handsideoftheequation, (ln(Q)\u2212ln(k\u22121))\u2215SE[ln(Q)],arisesfromremovingsomeoftheskewnessinthedistri- bution of Qby taking the logarithm, subtracting the mean, and dividing by the standard deviation toobtainaquantitywhoseasymptoticdistribution(asthenumberofdegreesoffreedombecomeslarge)isstandardnormal.ThensolvingforSE [ln(Q)]yieldsthetest-basedestimateofthestandard error.Unfortunately,Halperin[24]andGreenland[25]showedthatthetest-basedapproachisfal-lacious.Theconfidenceintervalinvolvingthetest-basedstandarderrorisvalidonlyunderthenullhypothesis. Thus, considering also the fact that the null distribution of Qis not chi-squared on k\u22121 degrees of freedom, the width of the resulting confidence interval for I2may not reflect heterogeneity when heterogeneity is present. Fortwoversionsofthestandardizedmeandifference,Huedo-Medina et al.[28]studiedaspectsofthe performanceof I 2inrelationtothenumberofindividualstudies,theaveragesamplesizeinthosestudies, the between-studies variance, the ratio of the within-study variance in the experimental group to that inthe control group, and the distribution of individual scores in the two groups. Their simulation sampled true means for the experimental group ( \ud835\udf07 E=\ud835\udf03i)from the random-effects distribution \ud835\udf03i\u223cN(0.5,\ud835\udf0f2), generated random samples of scores for the experimental and control groups (with nE=nC),a n dt h e n calculatedthegroupmeansandwithin-groupstandarddeviations.Thesestepsplausiblyparalleltheway in which data for a meta-analysis might arise. The basic data came from a meta-analysis of 70 trials givenbyOlkin[30].Theirrandom-effectsmodelintroducedan M-foldincreaseintheprecisionofeach study-level estimate (correspondingtoan M-foldincreaseinsamplesize): xM,i=\ud835\udf07+\u221a \ud835\udf0e2 i/M+\ud835\udf0f2ti; for\ud835\udf07, they used the overall estimate from the initial meta-analysis; for \ud835\udf0e2 i,t h e yu s e d s2 i(the within-trial sampling variance); for \ud835\udf0f2, they used the DerSimonian\u2013Laird estimate of the heterogeneity parame- ter (\u0302\ud835\udf0f2 DL),a n d ti\u223cN(0,1). See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License D.C.HOAGLIN Forthe random-effectsmodel xi=\ud835\udf07+\ud835\udeffi+\ud835\udf00i, withE(\ud835\udeffi)=0,var(\ud835\udeffi)=\ud835\udf0f2,E(\ud835\udf00i)=0,var(\ud835\udf00i)=\ud835\udf0e2 i,andindependenceamongthe \ud835\udeffi,amongthe \ud835\udf00i,and betweenthe \ud835\udeffiandthe\ud835\udf00i,andwith wi=1/\ud835\udf0e2 i,thederivationof E(Q)isstraightforward.Whenoneuses wi=1/s2 iinsteadof wi=1/\ud835\udf0e2 i,asDerSimonianandLairddo,thederivationisnolongervalid.Inview of the modest study-level sample sizes in many meta-analyses, such as the example in [30], one cannot take refuge in asymptotic arguments. DerSimonian and Kacker [31] proposed a general method-of-moments estimate for \ud835\udf0f2.F o ra n yfi x e d positive constants a1,\u2026,ak, they define ya=\u03a3iaiyi/\u03a3iai; equate Qa=\u03a3iai(yi\u2212ya)2to its expected value, expressed in terms of \ud835\udf0f2,t h e\ud835\udf0e2 i, and the ai;s o l v ef o r \ud835\udf0f2; and substitute s2 1,\u2026,s2 kfor\ud835\udf0e2 1,\u2026,\ud835\udf0e2 k. In most of their illustrative special cases, however, aiis a function of s2 i, rendering the derivation of the expected value of Qainvalid. Unfortunately, the Hartung\u2013Knapp\u2013Sidik\u2013Jonkman method uses the DerSimonian\u2013Lairdpoint estimate of the overall mean effect, which has potential for bias, and the analysis of IntHout et al.w a s unableto reveal bias. To minimize the computational burden, Kulinskaya et al. [14] developed software in R. In their examples, E[ Q] is somewhat less than k\u22121, and the decrease is enough to affect the result of the test. As a basis for approximating the distribution of Q by a gamma distribution, the expansion for E[ Q] is satisfactory (after an adjustment), but the expansion Copyright \u00a92015 John Wiley&Sons, Ltd. Statist. That choice tends to produce biased estimates of \ud835\udf0f2(e.g., Malzahn et al. [40], Sidik and Jonkman [41]) and has the potential for substantial bias in the pooled estimate of effect size (e.g.,Emerson et al.[32],Raghunathan and Ii[42],B\u00f6hning et al. [43], and Hamza et al.[44]). From the starting point of Qand \u2018Cochran\u2019s Qtest\u2019, the path of this paper has led naturally to two otherwidelyusedmethods, I2andtheDerSimonian\u2013Lairdprocedure.Allthreehaveshortcomings,some potentially serious, that point to a need for modifications in the current practice of meta-analysis."
    }
  ]
}