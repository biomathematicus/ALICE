{
  "CONFIG": {
    "general_instructions": "This project is an AI assistant for a given lesson. The output of each request must be response that guides an student in understanding a topic.  \\n",
    "description": "The Data and AI Intensive Research with Rigor and Reproducibility (DAIR\u00b3) program is funded by Award 5R25GM151182 of the National Institute of General Medical Sciences, one of the 27 institutes of the National Institutes of Health of the United States. The principal investigators are Jing Liu (University of Michigan) and Juan B. Guti\u00e9rrez (University of Texas at San Antonio). \\nThe rigor of scientific research and the reproducibility of research results are essential for the validity of research findings and the trustworthiness of science. However, research rigor and reproducibility remains a significant challenge across scientific fields, especially for research with complex data types from heterogeneous sources, and long data manipulation pipelines. This is especially critical as data science and artificial intelligence (AI) methods emerge at lightning speed and researchers scramble to seize the opportunities that the new methods bring.  \\n\\nWhile researchers recognize the importance of rigor and reproducibility, they often lack the resources and the technical know-how to achieve this consistently in practice. With funding from the National Institutes of Health, a multi-university team offers a nationwide program to equip faculty and technical staff in biomedical sciences with the skills needed to improve the rigor and reproducibility of their research, and help them transfer such skills to their trainees. \\n\\nTrainees will then be guided over a one-year period to incorporate the newly acquired mindset, skills and tools into their research; and develop training for their own institutions.  \\n\\nThe DAIR3 team and instructors include faculty and staff research leaders from the University of Michigan, the College of William and Mary, Jackson State University, and University of Texas San Antonio. This highly diverse team will model the culture of diversity that we promote, and will support trainees who are demographically, professionally and scientifically diverse, and are from a diverse range of institutions, including those with limited resources.",
    "harmonizer_code": "gpt-4o",
    "harmonizer_temperature": 0.1,
    "harmonizer_name": "Harmonizer"
  },
  "MODELS": [
    {
      "model_code": "gpt-4o",
      "model_name": "OpenAI GPT 4o",
      "temperature": 0.15,
      "agent_name": "ALICE AI Agent"
    }
  ],
  "knowledgeBase": [
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\1_goals.pdf",
      "summary": "Reproducible:  Entir e analysis f ully and e xactly r eproducible User friendly:  Easy t o ac cess, inst all, run Transp arent: Easy t o inspect , under stand, modify Reusable:  Other s may build upon the pr oject Version c ontr olled Archiv edFULLY AND EXACTLY REPRODUCIBLE The \u201cmost original\u201d dat a should be av ailable Include all c ode nec essar y to get from the original dat a to the final results The c ode should dir ectly pr oduc e the plots / t ables / number s in the paper All so\u0000w are dependencies should be specified and ide ally included with the c ode Random seeds specified etc.USER FRIENDLY Code e asy t o ac cess and inspect , ide ally e ven without do wnlo ading Should r equir e minimal e\ufb00 ort f or a user t o inst all and run Should c ause minimal disruption t o a user \u2019s resour ces (e.g., not inst all unw anted so\u0000w are on their syst em) etc.T R A N S P A R E N T Code should be w ell-or ganiz ed and document ed, ide ally in a notebook f ormat . Provide both r aw and cle aned/r eformatt ed dat a when nec essar y for clarity .R E U S A B L E Code should be port able acr oss platf orms Code should be modular t o facilit ate re-use in other pr oject Depending on the pr oject , creating a ne w so\u0000w are package may be helpf ul etc.PERMANENTLY ARCHIVED In a (file) f ormat suit able f or long-t erm pr eser vation in a (physic al) f ormat suit able f or long-t erm pr eser vationVERSION CONTROLLED This aids tr ansp arency Ultimat ely, most v aluable f or youGOALS 1. Version c ontr olled These ar e distinct g oals They po se distinct challeng esFOCUS: EVERYDAY REPRODUCIBILITY Most of our g oals ar e readily achie vable f or \u201ceveryday\u201d pr ojects Hard challeng es w e won\u2019t discuss: restrict ed ac cess dat asets massiv e dat asets proprie tary so\u0000w are highly c omput ationally int ensiv e codeDISCUSSION Which r eproducibility g oals hav e you att empt ed on a pr oject ? What lessons hav e you le arned?DISCUSSION What t ools do y ou find helpf ul?SOME USEFUL TOOLS notebooks / mark down R St udio , Jup yter jupyter not ebooks, quart o not ebooks, jupytext and quart o git dependenc y manag ement Dock er venv (python virt ual envir onments) renv (R virt ual envir onments)SOME USEFUL TOOLS R and p ython p ackages results c aching mak efiles pickle etc output f ormatting kable xtable sharing github zenodo"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\2_notebooks.pdf",
      "summary": "NO TEBOOK SCODE NOTEBOOKS In or der t o mak e analysis practic ally r eproducible , one should striv e to mak e analysis 1. easy t o int eract with 2. easy t o under stand code not ebooks  help achie ve these g oals via a literate pr ogramming format that int erweaves 1. text 2. code 3. output all t ogether .POPULAR NOTEBOOKS AND SOFTWARE O\u0000en, c ode not ebooks and their editing so\u0000w are ar e discussed as a single object . (Additionally , one c an dir ectly embed html) One c an also use e xtended mark down languag es lik e myst which enables f eatures lik e references, figur es, bibliogr aphies, \u2026 In any c ase, jupyter\u2019s mark down enables rich-t ext comment ary on both the c ode and the output (In f act, this pr esent ation is writt en in markdown)markdownBASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN BASIC MARKDOWN CODE: BASIC OUTPUT Interweaved mark down c omment ary, int ersper ses code and in-line output , e.g., CODE: INTERACTIVE WIDGETS Example: in R using plotly: CODE: LANGUAGES Ther e ar e many  languag e backends that jup yter can use. Jup yter lists w ell o ver 100 av ailable kernels  including k ernels f or: here python, r, julia, stata, octave, matlab, \u2026E X P O R T I N G One c an e xport  a .ip ynb  not ebook using jup yt er to many di\ufb00 ernt formats lik e: html, markdown pdf, reveal.js html slides, \u2026, and e ven an execut able script . EXPORTING AND INTEROPERABILITY Exporting  via nbconvert mostly immort alizes analysis f or display e.g.\u00a0as HTML or a PDF We c an also e xport e xecut able scripts: production , non-int eractiv e clust er, version c ontr ol Exporting t o display f ormats mak es analysis mor e shar able  and reproducible same analysis, many f ormatsQUARTO: LATEST R STUDIO NOTEBOOK FORMAT quarto is the lat est not ebook f ormat fr om P osit (R Studio). Quarto documents c an be edit ed in Jupyter.QUARTO AND JUPYTER quarto and jupyter di\ufb00 erences: quarto uses mark down-lik e .qmd, jupyter uses JSON .ipynb quarto geared t owards publishing (e.g.\u00a0figur es, t ables, r eferences, \u2026), use myst for jupyter .qmd doesn\u2019t st ore output , .ipynb does A use ful idiom : do analysis in jupyter and mirr or int o ipynb, md, R, qmd,\u2026NOTEBOOKS AND REPRODUCIBILITY Why do not ebooks help reproducibility : literate pr ogramming: int erweaving c ode/ comment ary/output allo ws rich c omment ary on c ode, output develops a narr ativ e that is e asy t o read document diagnostic/ explor atory/micr o-decision analysis keeps c omment ary/output close t o code good t ool f or playing with c ode, immediat ely obser ving outputNOTEBOOKS AND REPRODUCIBILITY Why do not ebooks help reproducibility : good f or sho wcasing r esults and int eroper ability can be c onv erted t o many shar able f ormats (html, pdf , \u2026) can c onv ert among  the not ebook f ormats creates a r eproducible r ecord code aut omatic ally g ener ates results fr om dat a this f orces document ation on ho w the r esults w ere pr oduc edNOTEBOOKS AND REPRODUCIBILITY Why do not ebooks help reproducibility : promot es g ood c ode or ganiz ation via chunking so\u0000w are/formats not pr oprie tary, easy t o distribut eSOME POTENTIAL DOWNSIDES While c ode not ebooks c an be gr eat, ther e ar e some potential issues , including: 1. chunks c an be run in non-sequential or der, making them not reproducible (soln: r e-run all analysis at the end sequentially) 2. saved f ormat of not ebook may mak e version c ontr ol di\ufb00icult (soln: jupytext) 3. not gr eat for non-int eractiv e envir onments (soln: jup ytext) 4. conv ersion among v arious f ormats isn\u2019t 100% f ool-pr oofDISCUSSION Do y ou use not ebooks r egularly?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\3_programming.pdf",
      "summary": "REPRODUCIBLE PROGR AMMINGEVERYDAY PRACTICES FOR REPRODUCIBLE PROGRAMMING Theor y: follo w a c ompr ehensiv e se t of c oding guidelines. In this module, w e cover five idioms that c an help enhanc e reproducibility e veryday: 1. writ e it in c ode, not the c onsole 2. don\u2019t r epe at y ourself, use f unctions 3. avoid magic number s, expose them 4. cache int ermediat e results 5. seed r andom number s1. A less  reproducible pr ocess: A\u0000er closing do wn the c onsole, I don\u2019t  hav e a r eproducible r ecord of what I did t o get results.1. A mor e reproducible pr ocess: A\u0000erwards, I hav e a mor e reproducible script  that sho ws e xactly what was run t o get results.1. Run with the c ommand make and p ass in a named ar gument This helps self -document and c ollect all pr ocessing st eps acr oss languag es/pr ograms.2. For e xample, w e o\u0000 en see c ode lik e this: 2. Adv antages of DRY: 1. mak es y our c ode e asier t o chang e / maint ain (av oiding err ors) 2. mak es y our c ode e asier t o under stand 3. remo ves some clutt er fr om c ode2. \u201cPremat ure optimiz ation is the r oot of all e vil.\u201d \u2013 Don Knuth In this p articular c ase, f actoring out the c all t o lm and knnreg incr eased the number of lines of c ode and made it har der t o read.3. Naming magic number s and other p arame ter choic es 1. mak es the c ode e asier t o read and mor e self -documenting 2. enhanc es reproducibility b y flagging these analysis choic es, exposing them via an int erface for e asy (thir d party) experiment ation4. CACHE INTERMEDIATE RESULTS Ideally, reproducible analysis t akes dat a from (e.g.) raw sour ces, t o cleaned-up pr ocessed dat a, to final r esults/plots/ output If this is all one long script that pr ocesses dat a without saving any intermediat e results along the w ay, it c an be di\ufb00icult t o reproduc e the analysis.4. CACHE INTERMEDIATE RESULTS It is g ood pr actic e to cache  intermediat e results t o enhanc e reproducibility b y creating multiple entr y-points int o the analysis. CACHE INTERMEDIATE RESULTS A usef ul idiom if I hav e a single f unction\u2019 s results I w ant t o cache: 4. To mak e randomness reproducible  we need t o identic ally se t the pseudo - random number g ener ators (PRNG) st ate each time. In R we can do this with set.seed(number) or set.seed(NULL) Example: a simple MC estimat e of the me an of a U(0,1) 5. To mak e randomness reproducible  we need t o identic ally se t the pseudo - random number g ener ators (PRNG) st ate each time. In R we can do this with set.seed(number) or set.seed(NULL) Example: a simple MC estimat e of the me an of a U(0,1) 5. SEED RANDOM NUMBERS If we want t o gener ate a ne w seed w e just r emo ve the c ache 5. BEWARE: PARALLELIZATION As instruct ed, w e se t the seed outside the f unction c all: 5. BEWARE: PARALLELIZATION A very reproducible w ay is t o use the future.apply package: This will still w ork e ven if w e chang e paralleliz ation p arame ters.BONUS: LINTING AND STYLING linting  is checking y our c ode \u2019s adher ence to a stylistic guidelines depending on the languag e, ther e ar e packages that will do this automatic ally f or y ou e.g.\u00a0lintr in R ther e ar e also p ackages that will aut omatic ally find and fix these issues f or y ou e.g.\u00a0styler in RBONUS: LINTING AND STYLING This is ugly , let\u2019s fix it . Go b ack periodic ally, and do things lik e: dele te those c omment ed out lines refactor c opy-and-p asted c ode chunks, rename y our poorly named v ariables, break ap art c ode int o be tter logic ally struct ured chunks/scripts 2. testing y our pipeline (fr om soup t o nuts) dele te all y our c ached int ermediat e results clear y our not ebook outputs remo ve plots/ data pr oduc ed re-run y our whole analysis (ide ally via a makefile) 3. code r eview hav e someone else look at y our c ode 4. avoid pr oprie tary so\u0000w areDISCUSSION How o\u0000 en do y ou g o back and cle an-up c ode ?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\4_versioncontrol.pdf",
      "summary": "VER SION C ONTROLO U T L I N E Brief o verview What it is Why t o use it What (not) t o sav e DiscussionVERSION CONTROL Maint ain di\ufb00 erent v er sions  of y our pr oject , e.g., Stable Development Maint ain a hist or y of y our pr oject Standar d: git Not e: git is separate from github git = MS Wor d, github = a shar ed g oogle docVERSION CONTROL VERSION CONTROL IS FOR Y O U Our g oals: 1. org/github_t utorial/A SHORT TUTORIALGRAPHICAL INTERFACES If you don\u2019t lik e command-line int erfaces, ther e ar e lots of gr aphics interfaces out ther e, e.g.\u00a0 GitHub Desk top GitKr aken Sour cetreeWHAT (NOT) TO SAVEAN INHERENT TRADE-OFF You don\u2019t normally sav e every file in y our git r eposit ory. \u2013 y our git archiv e would b alloon in siz e This happens bec ause git w orks o\ufb00 files di\ufb00 erences (diffs) If you don\u2019t sav e enough, y ou may not be able t o piec e together what you did What should y ou k eep ? Onc e a file has been c ommitt ed t o your r eposit ory, it gener ally c an\u2019t be remo ved.GIT \u2013 DESIGNED FOR TEXT FILES When editing t ext files, git only sav es di\ufb00 er enc es This mak es ar chiving simple t ext files v ery sp ace e\ufb00icient Other files g et comple tely r e-sav ed at e ach c ommit git is designed f or c ode, not other asse ts (output , figur es, dat a, \u2026)WHAT TO KEEP (TRACK) mark down files scripts mak efiles simple t ext document ation etc.WHAT TO IGNORE binar y files pdf, jpg, e tc."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\5_containers.pdf",
      "summary": "Put e verything on githubTHEN TIME PASSES\u2026 When r evising the p aper , we updat ed our c ode, r e-ran the analysis, and\u2026 got v ery di\ufb00 erent r esults f or a me thod w e had c omp ared ag ainst A\u0000er a gr eat de al of debugging, w e disc overed a dependenc y of a dependenc y of a dependenc y had chang ed Mor al: Saving y our c ode is not enough. Writing a p aper with a st udent that analy zed social media dat a (Tweets) The st udent cr eated a f ull analysis pipeline and shar ed on github Fairly simple pipeline, so w aited t o containeriz e until final r evisions comple teANOTHER EXAMPLE (C.\u00a02020) \u2013 NOT EVEN A \u201cDEPENDENCY\u201d! Time p asses\u2026 p aper ac cepted, time t o containeriz e One figur e in the p aper: R andomly select ed e xample tw eets The y chang ed! Packages Fast Easy t o shar e Single file Cross platf orm (Linux, Mac, Windo ws)KEY INGREDIENTS Base imag e Dock erfile or Cont ainerfile Your e xisting analysisBASE IMAGE Minimal Ubunt u R (R ocker) Jup yter Many , many mor eDOCKERFILE R U N N I N G ANOTHER EXAMPLE BRIEF TUTORIAL Many gr eat tutorials online Our p aper: https:// jdssv .org/inde x.php/ jdssv /article/vie w/53T U T O R I A L Using podman, a light -weight impl. Version c ontr olledUSER FRIENDLY Code e asy t o ac cess and inspect , ide ally e ven without do wnlo ading Should r equir e minimal e\ufb00 ort f or a user t o inst all and run Should c ause minimal disruption t o a user \u2019s resour ces (e.g., not inst all unw anted so\u0000w are on their syst em) etc."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\6_pipeline.pdf",
      "summary": "maybe results/cached + results/final output plots, t ables, e tc., to include dir ectly in p aper (some times) not ebook outputM A K E F I L E S  \u2013 sinc e 1976 Created t o pr ovide the c ommands nec essar y to compile a so\u0000w are project Also gr eat for or ganizing a r eproducible analysis Organiz e commands int o \u201crules \u201d that build specific outputsmake ExampleMAKEFILE RULES Like dir ectory struct ure, per sonal and v aries b y pr oject For ne arly all pr ojects: all: runs e verything, typic ally the def ault clean: dele te all output (including pr ocessed dat a, cached r esults) download: (re-)do wnlo ad dat a from its original sour ce Also c ommon: preprocess (or clean_data, or \u2026) main_analysis (might simply c all other rules, e.g., eda, fitmodels, etc.) Ther e is an \u201c obvious \u201d mark down file t o look in It is simple t o read, quick t o run, and (ide ally) e asy t o edit Each mark down file should cle arly sho w its inputs and outputs Mak efiles c an also be used t o specify file dependenciesExample\u201cFROM SOUP TO NUTS\u201dONE COMMAND The user should be able t o run y our entir e analysis \u2013 e verything \u2013 with a single c ommand. Automat e everything Retain the original dat a, but k eep it cle arly sep arated fr om \u201c cleaned\u201d dataFINAL RESULTS (NUTS) \u201cFinal r esults \u201d: Plots Tables Numeric al results (e.g., \u201c \u201d) p=0.02 All final r esults should be output v erbatim b y your analysisFINAL RESULTS (NUTS) Numeric al results (e.g., \u201c \u201d) Embed in a not ebook Should be e asy t o find Tables Plots  (ggplot2) If you absolut ely must edit b y hand: diff and patchp=0.02 xtable kable stargazer annotate() tikzDeviceS H A R I N GEASILY ACCESSIBLE To mak e your analysis e asily ac cessible, Post the c ode some wher e it is e asy t o br owse (e.g., github) Post a f ully self -contained dock er imag e Post (or link t o) the dat a some wher e you c an do wnlo ad it dir ectly Post any p ackages on CR AN, PyPi, e tc."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_5 - Reproducible Workflows - Johann and Greg\\Pre-reading material for participants\\JDSSV_V3_I1.pdf",
      "summary": "For example, it is now commonplace for underlying analysis code and data to be proffered alongside journal publications and conference talks. This makes it difficult to assess the code and its findings, for example, in a peer review process. These technologies are: (1) analysis containerization, which leverages virtualization to fully encap- sulate analysis, data, code and dependencies into an interactive and shareable format, and (2) notebooks, a literate programming format for interacting with analyses. This review surveys how the combination enhances the accessibility and reproducibility of code, analyses, and ideas. Open sharing not only allows results to be disseminated and built upon, but also allows scrutiny and verification of the research and is fundamental to the scientific process itself. The modern notion of sharing research encompasses not only sharing prose and proofs, but also sharing code and data. It is now commonplace for data and the accompanying analysis code to be shared through online repositories. For example, most of the journals sponsored by the Interna- tional Statistical Association and American Statistical Association require data and code be posted along with analysis (Journal of the American Statistical Association 2022). However, CRAN and PyPI are intended for software, not to host full analyses for the purposes of reproducibility. Zenodo is operated by CERN and allows hosting up to 50GB of data while Figshare is operated by Digital Science and has a limit of 20GB. Among these, two important issues are (1) actually running the shared code, and (2) understanding and interacting with the code. For example, the package may not be available for the current version of the language or dependencies of the package may fail to install. Modern analysis often relies on a large and complex collection of interdependent software packages and thus there are many places for such version or dependency issues to arise. For example, troubleshooting failed installations of dependencies can often lead down a chain of fixing cryptic installation errors which is difficult even for an experienced user.Journal of Data Science, Statistics, and Visualisation 3 In addition to the challenges of taking analysis from one computer and running it on another, a second major challenge is difficulty understanding or interacting with code. Containerization is a virtualization technology that allows encapsulation of an entire computing environment including data, code, dependencies, and programs into a reproducible, shareable, and self-contained format (N\u00fcst et al. 2020). Containerization is a flexible approach that allows one to encapsulate any format or organization of analysis according to their preferences and assessment of the best way to organize and share the analysis. Containerizing notebooks makes for some of the most clear, concise, and intuitive ways of documenting and interacting with analysis. In this work, we will review how the merging of containerization and notebook soft- ware can be used to create interactive and reproducible analyses. In addition to an overview, we will also make concrete recommendations for what we believe to be the most straight-forward tools and workflows to enhance reproducibility through con- tainerized notebooks. The remainder of this paper is organized as follows: Section 2 reviews barriers to computational reproducibility in statistics, how containerization helps, and the landscape of available tools. This was emphasized by the American Statistical Association\u2019s 2017 recommendations on reproducible research, which noted that \u201c[reproducible code] may initially sound like a trivial task but experience has shown that it\u2019s not always easy to achieve this seemingly minimal standard.\u201d(Broman et al. 2017) One major source of trouble is ensuring correct code dependencies. The most familiar example of this is installing add-on packages for a language like ggplot24 Containerization for Reproducible Analysis forRornumpyforPython. While add-on dependencies are easy to install in some cases, this can quickly become complicated, for example, if the original analysis used a now out-of-date version of a package. The blue box indicates the system-level dependency of the package for Linux OS Ubuntu ver. The CRAN task view on reproducible research (Blischak and Hill 2021) lists several packages for this purpose like checkpoint (Ooi et al. 2021), ground- hog(Simonsohn and Gruson 2021), and renv(Ushey 2021). One can think of virtualization as making a copy of the computer where the code was originally written. While virtualization has been around for decades, containerization is the latest incarnation of the technology and comes with several key advantages over itsJournal of Data Science, Statistics, and Visualisation 5 predecessors. Containers only virtualize the high-level components of the operating system (e.g., code, configuration files, software and data) and seamlessly re-use the stable low-level processing components of the host operating system (Turnbull 2014). Indeed, starting up a container doesn\u2019t actually start up a second instance of an operating system; it largely just changes all references for re- sources, system libraries, files, and data, to refer to a particular isolated section of the computer. The light-weight nature of such containers means that the resource foot- print is small making them quick to upload, download, and share. Furthermore, since starting a container largely just changes the references to resources in the environment, containers are user-friendly, start up nearly instantaneously, and run code at speeds nearly identical to the host computer (Felter et al. 2015). Containerization in Practice Containerization has been an increasingly adopted tool for reproducibility widely across the scientific community including areas such as geography, psychology, environmental science, metagenomics and many others (Knoth and N\u00fcst 2017; Wiebels and Moreau 2021; Essawy et al. 2020; Visconti et al. 2018; N\u00fcst et al. 2020; Olaya et al. 2020). To set the stage for a review of containerization technology we will first illustrate how containerization is used in practice. We will present an archetypal example of containerizing and sharing an analysis from three different perspectives: (1) the high- level view of sharing containerized analyses, (2) the end-user experience of interacting with a third-party containerized analysis, and (3) the first-party task of containerizing an analysis for dissemination. Fromthere, theimagemaybedownloadedbyathirdparty and with just a few keystrokes, the third party is placed into a duplicate of the original computing environment (called a \u201ccontainer\u201d1). All of the data, code, dependencies, configurations and software are precisely set up as in the original environment, and thus set up to reproduce the analysis exactly. The goal of containerization is to ensure that if the code worked when containerized, it will work when the image is run by a third party. First, the container is downloaded and started with a single 1An \u201cimage\u201d refers to the actual file that may be uploaded, downloaded or shared, while a \u201ccon- tainer\u201d refers to an ephemeral instance running on the computer.6 Containerization for Reproducible Analysis imageimagecloudcontainer (Copy of Computing Environment) Original Computing Environment imagecontainerization(1) upload(2) download(3)run container(4)Original Analysis Third Party Figure 2: Typical sharing of containerized analysis. (4) From there, the third party may use the image to re-create the original computing environment. We can see from Figure 3 that the container\u2019s environment contains all of our files necessary for analysis including data and code scripts. However, in addition to merely allowing inspection of the data or scripts, the container also comes with an installation ofRso that the user can actually run the code and analysis through the interactive notebook interface. It is important to keep in mind that while the end-user accesses the container and its contents through the web browser on the host computer, the data, code, software installations and back-end to the interface all actually reside in the container. The web browser merely provides a window into the running container through which one may use the tools installed in the container and interact with the code and data it contains. This is the power of sharing containerizing analyses \u2013 it allowsJournal of Data Science, Statistics, and Visualisation 7 (A) T erminalHost Computer Desktop (B) web browser code \ufb01les-p: ports for browser Figure 3: Example of interacting with a containerized analysis. The flag -pallows us to specify the port forwarding to enable interaction through the web browser. (B) The container may now be interacted with through the web browser on the host computer via a graphical interface running from thecontainer. The container has the necessary data and code files and an installation of Rto run the analysis through this web interface. While the end-user may interact naturally with the analysis through a web-browser on the host computer, all of the code, files, and software reside in the container\u2019s pre-configured environment. users to bring to bear the full power and convenience of popular graphical interfaces to fully encapsulated analysis environments with a single command. To set up an image, a configuration file must be written giving instructions of which files and programs to be copied and installed. Such repositories make containerizing analyses simple as one can choose a nearly-complete image, with desired software like Jupyter lab andRalready installed,8 Containerization for Reproducible Analysis and simply add a small amount of project-specific code, data, and documentation. In five lines the configuration specifies a base image with RandJupyteralready installed, installs a desired Radd-on package, copies over data and analysis code, and starts the Jupyter lab interface. On top of this base image one needs only to install the necessary software packages or language add-ons and copy over the data and code. Once the configuration file has been written, the image needs to be built, after which, (B) Building(A)base image with R and jupyter desired name Figure 4: (A) Example configuration file for building an image using Docker. First argument to COPYis location on host, second argument is desired location in container, the flag \u2013chownsets the ownership of the file to the container\u2019s user. The Containerization Landscape While virtualization can trace its roots all the way back to early mainframe computers, modern lightweight containerization was largely popularized with the software Docker starting in 2013 (Graziano 2011; Docker Inc. 2021b). While other tools have been developed since then, the present space of user-friendly containerization software for statisticians and scientists has two major players: (1) Docker (Docker Inc. 2021b), and (2) Singularity (Sylabs 2021). Consequently, they both work on Linux.Journal of Data Science, Statistics, and Visualisation 9 However, Singularity does not have native support on Windows or MacOS while Docker has both support and a graphical interface for these systems. As containerization is fundamentally a refinement of older existing FOSS virtualization technology (itself built upon the FOSS Linux kernel) the core software defining Docker, Singularity, and Podman are publicly available under copyleft/permissive licenses. This leaves open the question of where to store images for the purposes of reproducibility. Other researchers will simply need to locate the files using the DOI and download/run the images. For containerizing shareable and reproducible analyses we recommend Podman or Docker as they are widely used con- tainerization software with cross-platform support, a user-friendly interface, and a huge ecosystem of base images off of which one may build. While all of the containerization tools we discuss in this section can help provide a10 Containerization for Reproducible Analysis Table 1: Comparison of Docker, Singularity, and Podman for containerization of repro- ducible analyses. Otherwise, the added effort of interacting with analyses through a container has the potential to hinder the accessibility of the anal- ysis and code. In Section 3 we discuss notebooks and how they can be used to help provide an accessible and intuitive graphical interface to writing and interacting with containerized analyses. In the remainder of this section we will describe notebooks, highlight some of their advantages, and review popular options. While there are several variants of notebooks, they all structure analysis as a sequence of \u201cchunks\u201d that can be edited and evaluated one at a time. In the software development community there is a long history of discussion of best coding practices and development of tools aimed at promoting them. Notebooks build upon this history, promoting chunked code organization and rich com- mentary, but go a step further and embed analysis output along the code and com- mentary. Consequently, notebooks not only encourage good coding practices, but also facilitate a rich discussion of the code, its relation to the output, and the bearing of this outputJournal of Data Science, Statistics, and Visualisation 11 (A) RStudio Server (B) Jupyter Lab (C) Zeppelin  (1)  text   (2)  code  (3)  plots(1)  text   (2)  code   (3)  plots(1)  text   (2)  code   (3)  plots Figure 5: Interactive notebook environments run through the web browser using (A) RStudio Server , (B) Jupyter Lab , and (C) Zeppelin. While different notebook formats and software tools exist, all notebooks share the feature of organizing analysis as a sequence of chunks of (1) text or (2) code and its associated (3) output. Indeed, embedding output directly alongside the code allows one to document the entire analysis pipeline including expository plots such as diagnostic and exploratory plots that may inform small decisions made in the course of analysis. These types of plotsareoftennotincludedinmanuscriptsorsupplementarymaterialsbecausetheyare difficult to motivate and connect to the analysis when divorced from the actual code. Nonetheless, documentation of these types of micro-decisions is important for properly documenting an analysis pipeline and is necessary for transparent and reproducible research (National Academies of Sciences and Medicine 2019). This can be useful in a research context where both code and output evolve over time and it is easy to mismatch ver- sions of results/figures to the correct versions of the underlying analysis. Both of these practices have the potential to make confusing notebooks where re-running the code sequentially does not reproduce the immortalized output (or may even produce errors). Similarly, Jupyter lab maintains a numeric label for each code chunk to indicate the order in which the chunks have been run. Nonetheless, we still recommend that before sharing notebooks they are re-run sequentially to ensure they work as intended12 Containerization for Reproducible Analysis and, in particular, containerizing the analysis provides a good opportunity to do this. Another advantage of using notebooks for explaining and showcasing analysis is that they give users the option to run the code and explore it interactively. Since chunks can be edited and run one at a time, each chunk provides a natural entry-point into a small portion of the analysis. For example, one can pick a segment of the analysis they wish to explore, edit the chunk of code, run it, and observe the subsequent change in output. This encourages one to experiment with small changes to code, e.g., testing different tuning parameters or optional arguments to functions, and immediately observe the changes to local output. This can be used to provide a natural way to play with code in order to build up an understanding of how the code works and test the robustness of the analysis to alterations. By default, a containerized analysis requires the user to interact with the code entirely through the command line. However, if we containerize notebook software in addition to the code, data, and other dependencies, then we can bring the full power of popular coding environments as an interactive interface to our containerized analysis. In this case, we can run the notebook back-end from within the container but access the interactive computing interface from the host computer\u2019s browser. This combination is the best of both worlds as it brings the native feel of doing analysis on one\u2019s own computer to completely self-contained and reproducible analyses. A summary of this comparison is presented in Table 2 and examples of the software interfaces are illustrated in Figure 5. While Jupyterrequires that all code chunks in a notebook use the same language, both RStudioandZeppelin allow notebooks to mix and match languages across chunks. Furthermore, RStudiohas extensive support forreticulate , which allows analysis using both RandPythonat the same time in a shared computing environment.Journal of Data Science, Statistics, and Visualisation 13 An important distinction is the format of the notebook file and how it interacts with third-party software. This is useful for showcasing results because, unlike a traditional code scripts, the notebook has output embedded and one need not re-run the code to view the results. In particular, one cannot easily track changes to these notebooks in a human-readable format using version control software like Git since small changes to output can prompt a cascading change to hundreds of lines of the dense encoding. An advantage of such an approach is that the input code and commentary are saved in a human-readable format which is more versatile for edit- ing by general software and can be meaningfully tracked by version control schemes. The shareable HTML rendering also contains an embedded downloadable copy of the R Markdown file if one wishes to download the underpinning R Markdown code. Despite these format differences, from the viewpoint of interacting and exploring analyses all three of RStudio,JupyterandZeppelin have broadly similar behavior, and allow users to edit and run code chunks one at time, viewing output in-line in the editor. To allow conversion between formats, Jupyterhas the Jupytext plugin which allows one to conduct analysis using Jupyter, whilst maintaining a simultaneous synchronized version in R markdown or as a simple executable script. A common challenge when using notebooks is that chunks need to be run sequentially and so to explore chunks later in the analysis one needs to run earlier time-intensive14 Containerization for Reproducible Analysis code. Here, we conduct analysis with Jupyterand then use Jupytext to mirror the analysis into R Markdown , a code script, and a HTML rendering for showcasing. Once running, the container is accessible through the host computer\u2019s web browser where a start-page offers several options to interact with the analysis including browsing the files (e.g., to view the HTML rendering) or opening the notebooks in a graphical interface like JupyterorRStudio. (B) We build the image and name it adding the tag :2to indicate it is version 2 of our previous example. Subsequently, we may run the image interactively with-it, naming it with \u2013nameand correctly mapping ports with -p. (C) The start page for the interactive container. (D) We may browse the files or (E) open the notebooks with one of several choices of graphical web-based interfaces running from the container. Containerized notebooks may also be used as a tool for teaching allowing distribution of identical code, data, and a computing environments to all students. While a small amount of time would need to be devoted to teaching students some simple mechanics of containerization, in our estimation this is not more complicated than other coding tasks required in many courses and would provide an opportunity for a discussion with students about research reproducibility, replicability as well as good coding practices. Beyond the direct benefits of making code more easily shareable, the act of container- izing analyses can itself serve as a helpful review step in a scientific pipeline. This encourages simpli-16 Containerization for Reproducible Analysis fication and refactoring of code, as well as writing of the associated documentation and commentary. It also provides an opportunity to re-run the analysis in a hands-off manner to ensure that the notebooks and the entire code pipeline actually correctly produce the results when run sequentially. If the final results included in a manuscript are the output of a container then one can be ensured the results are computation- ally reproducible. N\u00fcst, D., Eddelbuettel, D., Bennett, D., Cannoodt, R., Clark, D., Daroczi, G., Ed- mondson, M., Fay, C., Hughes, E., Kjeldgaard, L., Lopp, S., Marwick, B., Nolis, H., Nolis, J., Ooi, H., Ram, K., Ross, N., Shepherd, L., S\u00f3lymos, P., Swetnam, T. L., Turaga, N., Van Petegem, C., Williams, J., Willis, C., and Xiao, N. (2020).18 Containerization for Reproducible Analysis The Rockerverse: Packages and Applications for Containerization with R. R Jour- nal, 12(1):437\u2013461, DOI: 10.32614/rj-2020-007 ,https://arxiv.org/abs/2001. Hunt Department of Mathematics William & Mary Williamsburg, VA 23185 E-mail:ghunt@wm.edu Journal of Data Science, Statistics, and Visualisation https://jdssv.org/ published by the International Association for Statistical Computing http://iasc-isi.org/ ISSN 2773-0689 March 2023, Volume III, Issue I Submitted: 2021-08-04 doi:10.52933/jdssv.v3i1.53 Accepted: 2022-06-09"
    }
  ]
}