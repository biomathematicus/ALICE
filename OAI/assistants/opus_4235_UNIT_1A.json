{
  "CONFIG": {
    "general_instructions": "This project is an AI assistant for a course. The output of each request must be a response that guides a student in understanding a topic.",
    "description": "The Data and AI Intensive Research with Rigor and Reproducibility (DAIR-3) program is funded by Award 5R25GM151182 of the National Institute of General Medical Sciences, one of the 27 institutes of the National Institutes of Health of the United States. The principal investigators are Jing Liu (University of Michigan) and Juan B. Guti\u00c3\u00a9rrez (University of Texas at San Antonio). \\nThe rigor of scientific research and the reproducibility of research results are essential for the validity of research findings and the trustworthiness of science. However, research rigor and reproducibility remains a significant challenge across scientific fields, especially for research with complex data types from heterogeneous sources, and long data manipulation pipelines. This is especially critical as data science and artificial intelligence (AI) methods emerge at lightning speed and researchers scramble to seize the opportunities that the new methods bring.  \\n\\nWhile researchers recognize the importance of rigor and reproducibility, they often lack the resources and the technical know-how to achieve this consistently in practice. With funding from the National Institutes of Health, a multi-university team offers a nationwide program to equip faculty and technical staff in biomedical sciences with the skills needed to improve the rigor and reproducibility of their research, and help them transfer such skills to their trainees. \\n\\nTrainees will then be guided over a one-year period to incorporate the newly acquired mindset, skills and tools into their research; and develop training for their own institutions.  \\n\\nThe DAIR3 team and instructors include faculty and staff research leaders from the University of Michigan, the College of William and Mary, Jackson State University, and University of Texas San Antonio. This highly diverse team will model the culture of diversity that we promote, and will support trainees who are demographically, professionally and scientifically diverse, and are from a diverse range of institutions, including those with limited resources.",
    "harmonizer_code": "gpt-4o",
    "harmonizer_temperature": 0.1,
    "harmonizer_name": "Harmonizer"
  },
  "MODELS": [
    {
      "model_code": "gpt-4o",
      "model_name": "OpenAI GPT 4o",
      "temperature": 0.15,
      "agent_name": "ALICE AI Agent"
    }
  ],
  "knowledgeBase": [
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Assessment .pdf",
      "summary": "A wearable device that monitors vital signs and uses AI to detect potential health emergencies A."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Discussion.pdf",
      "summary": "Describe the AI system you have developed, the ethical considerations you identified, and the researchers\u2019 responsibilities. A large pharmaceutical company has approached the university requesting access to both the biospecimens and associated data to develop an AI diagnostic tool using machine learning techniques. Describe the scenario, the ethical considerations you identified, and the university\u2019s position. Describe the scenario, the ethical considerations you identified, and how you will address representation and privacy."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Presentation.pdf",
      "summary": "Sociotechnical systems  Source: NIOSH  https://www.cdc.gov/niosh/learning/safetyculturehc/module-1/3.htmlhttps://business.leeds.ac.uk/research-stc/doc/socio-technical-systems-theory Sociotechnical ethics of digital health (Shaw and Donia, 2021)\u2022Domains of analysis\u2022Identify interdependencies \u2022Expand view of technology\u2022Upstream and downstream impacts \u2022Individual and population-level impacts   Sociotechnical ethical analysis Other ethical considerations \u2022Privacy and security \u2022Consent \u2022Group harms \u2022Conflict of interest \u2022Transparency \u2022Trust \u2022Ownership \u2022Engagement / Empowerment \u2022Benefits\u2022Equity \u2022Unintended consequences The case for holistic approaches  Alternatives: Expanding sets of principles\u2022Adaptivity\u2022Flexibility \u2022Inclusiveness\u2022Reflexivity \u2022Responsiveness \u2022MonitoringCaveats \u2022Principles are a first step \u2022Beware of assumptions of equity\u2022Requires time and making time for asking questions \u2022Who is in the room?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\Pre-reading material for participants\\obermeyer.pdf",
      "summary": "Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at https://about.jstor.org/terms American Association for the Advancement of Science  is collaborating with JSTOR to digitize, preserve and  extend access to Science This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsRESEARCH ARTICLES\u25e5 ECONOMICS Dissecting racial bias in an algorithm used to manage the health of populations Ziad Obermeyer1,2*, Brian Powers3, Christine Vogeli4, Sendhil Mullainathan5*\u2020 Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. It is one of the largest and most typical examples of a class of commercial risk-prediction tools that, by industry estimates, are applied to roughly 200 million people in the United States each year. First, the specific problem solved by this algorithm has analogies in many other sectors: The pre- dicted risk of some future outcome (in our case, health care needs) is widely used to tar- get policy interventions under the assumption that the treatment effect is monotonic in that risk, and the methods used to build the algo- rithm are standard. By any standard \u2014e.g., number of lives affected, life-and-death consequences of the decision \u2014 health is one of the most important and wide- spread social sectors in which algorithms are already used at scale today, unbeknownst to many. This approach allowed us to study one particular racial difference of social and historical interest between patients who self-identified as Black and patients who self-identified as White without another race or ethnicity; it has the disadvantage of not allowing for the study of intersectional racialRESEARCH SCIENCE sciencemag.org 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 447 1School of Public Health, University of California, Berkeley, Berkeley, CA, USA.2Department of Emergency Medicine, Brigham and Women \u2019s Hospital, Boston, MA, USA. Some definitions focus on calibration [i.e., whether the realized value of some variable of interest Ymatches the risk score R(2,22,23)]; others on statis- t i c a lp a r i t yo fs o m ed e c i s i o n Dinfluenced by the algorithm ( 10); and still others on balance of average predictions, conditional on the real- ized outcome ( 22). Given this multiplicity and the growing recognition that not all condi- tions can be simultaneously satisfied ( 3,10,22), we focus on metrics most relevant to the real- world use of the algorithm, which are related to calibration bias [formally, comparing Blacks Band Whites W,E\u00bdYjR;W/C138\u00bcE\u00bdYjR;B/C138indi- cates the absence of bias (here, Eis the ex- pectation operator)]. Thus, we compare the algorithmic risk score for patient iin year t (Ri,t), formed on the basis of claims data Xi,(t\u22121) from the prior year, to data on patients \u2019real- ized health Hi,t, assessing how well the algo- rithmic risk score is calibrated across race for health outcomes Hi,t. To measure H, we link predictions to a wide range of outcomes in electronic health record data, including all diagnoses (in the form of International Classification of Diseases codes) as well as key quantitative laboratory studies and vital signs capturing the severity of chro- nic illnesses. These data, and the rationale for the specific measures of H used in this study, are described in more detail in the supplementary materials.Health disparities conditional on risk score We begin by calculating an overall measure of health status, the number of active chronic conditions [or \u201ccomorbidity score, \u201da metric used extensively in medical research ( 24) to provide a comprehensive view of a patient \u2019s health ( 25)] by race, conditional on algorith- mic risk score. We then turn to a more multidimensional pic- ture of the complexity and severity of patients \u2019 health status, as measured by biomarkers that index the severity of the most common chro- nic illnesses in our sample (as shown in Table 1). (The materials and methods section describes several experiments to rule out a large effect of the program on these health measures in year t; had there been such an effect, we could not easily use the measures to assess the accuracy of the algorithm \u2019s predictions on health, because the program is allocated as a function of algorithm score.) Mechanism of bias A nu n u s u a la s p e c to fo u rd a t a s e ti st h a tw e observe the algorithm \u2019s inputs and outputsas well as its objective function, providing us a unique window into the mechanisms by which bias arises. ( B) Fraction of Black patients at or above a given risk score for the original algorithm ( \u201coriginal \u201d) and for a simulated scenario that removes algorithmic bias ( \u201csimulated \u201d: at each threshold of risk, defined at a given percentile on the xaxis, healthier Whites above the threshold arereplaced with less healthy Blacks below the threshold, until the marginal patient is equally healthy). The dashed vertical lines show the auto-identification threshold (the black line, which denotes the 97th percentile) and the screening threshold (the gray line, which denotes the 55th percentile).RESEARCH |RESEARCH ARTICLES This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsBecause these programs are used to target patients with high costs, these results are large- ly inconsistent with algorithmic bias, as mea- sured by calibration: Conditional on risk score, p r e d i c t i o n sd on o tf a v o rW h i t e so rB l a c k sa n y - where in the risk distribution. On the other hand, there are many opportunities for a wedge to creep in between needing health care and receiving health care\u2014 and crucially, we find that wedge to be correlated with race, as shown in Fig. At a given level of health (again measured by number of chronic illnesses), Blacks generate lower costs than Whites \u2014on average, $1801 less per year, holding constant the number of chron- ic illnesses (or $1144 less, if we instead hold constant the specific individual illnesses that contribute to the sum). For example, it has long been documented that Black patients have reduced trust in the health care system ( 33), a fact that some studies trace to the revelations of the Tuskegee study and other adverse experiences ( 34). Problem formulation Our findings highlight the importance of the choice of the label on which the algorithm is trained. On the one hand, the algorithm man- ufacturer \u2019s choice to predict future costs is rea- sonable: The program \u2019s goal, at least in part, is 450 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 sciencemag.org SCIENCERace Black White 0.00.10.20.3 Fraction with uncontrolled blood pressureA Hypertension: Fraction clinic visits with SBP >139 mmHg 5.56.06.57.07.5 Mean HbA1c (%)B Diabetes severity: HbA1c 90100110 10 20 30 40 50 60 70 80 90 100Mean LDL (mg/dL)C Bad cholesterol: LDL  \u22120.10.00.10.2Mean creatinine (log mg/dL)D Renal failure: creatinine (log) Referred for screenDefaulted into program Defaulted into programReferred for screenDefaulted into program Referred for screen Defaulted into program Referred for screenDefaulted into program Referred for screen 32.535.037.540.042.545.0 Percentile of Algorithm Risk ScorePercentile of Algorithm Risk Score Percentile of Algorithm Risk ScorePercentile of Algorithm Risk Score Percentile of Algorithm Risk Score Mean Hematocrit (%)E Anemia severity: hematocrit0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100Fig. The dashed vertical lines show the auto-identification threshold (black line: 97th percentile) and the screening threshold (gray line: 55th percentile).RESEARCH |RESEARCH ARTICLES This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsto reduce costs, and it stands to reason that patients with the greatest future costs could have the greatest benefit from the program. The dilemma of which label to choose re- lates to a growing literature on \u201cproblem formu- lation \u201din data science: the task of turning an often amorphous concept we wish to predict into a concrete variable that can be predicted in a given dataset (38 ). So although the choice of label is perhaps the single most important decision made in the development of a prediction al- gorithm, in our setting and in many others, there is often a confusingly large array of different options, each with its own profile of costs and benefits.Experiments on label choice Through a series of experiments with our data- set, we can gain some insight into how label choice affects both predictive performance and racial bias. We develop three new predictive algorithms, all trained in the same way, to predict the following outcomes: total cost in year t(this tailors cost predictions to our own dataset rather than the national training set), avoidable cost in year t(due to emergency visits and hospitalizations), and health in year t(measured by the number of chronic condi- tions that flare up in that year). The first finding is that all algorithms perform reasonably well for predicting not only the outcome on which they were trained but also the other outcomes: The concentra- tion of realized outcomes in those at or above the 97th percentile is notably similar for all algorithms across all outcomes. The largest difference in performance across algorithms is seen for cost prediction: Of all costs in the holdout set, the fraction generated by those at or above the 97th percentile is 16.5% for the cost predictor versus 12.1% for the predictor SCIENCE sciencemag.org 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 4511,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100 Percentile of Al gorithm Risk ScoreMean Total Medical ExpenditureRace Black White 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100 Chronic IllnessesMean Total Medical ExpenditureRace Black WhiteDefaulted into program Referred for screen 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100Race Black White 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100Race Black WhiteAB Fig. We find that the racial composition of this highest-risk group varies far more across algo- rithms: The fraction of Black patients at or above these risk levels ranges from 14.1% for the cost predictor to 26.7% for the predictor of chronic conditions. Thus, although there could be many reasonable choices of label \u2014 all predictions are highly correlated, and any could be justified as a measure of patients \u2019 likely benefit from the program \u2014they have markedly different implications in terms of bias, with nearly twofold variation in composi- tion of Black patients in the highest-risk groups. Specifically, for patients at or above a certain level of predicted risk (the 55th per- centile), doctors are presented with contex- tual information from patients \u2019electronic health records and insurance claims and are promp- ted to consider enrolling them in the prog- ram. Table 3 shows statistics on those enrolled in the program, accounting for 1.3% of observa- tions in our sample: The enrolled individuals are 19.2% Black (versus 11.9% Black in our en- tire sample) and account for 2.9% of all costs and 3.3% of all active chronic conditions in the population as a whole. Finally, we compare this to simply assigning those with the highest predicted costs, or the highest number of active chronic conditions, to the program (also using our own algorithms detailed above), which would yield 17.2 and 29.2% Black patients, respectively. For those enrolled in the high-risk care management program (1.3% of our sample), we first show the fraction of the population that is Black, as well as the fraction of all costs and chronic conditions accounted for by these observations. We first calculate the programenrollment rate within each percentile bin of predicted risk from the original algorithm and either (i) randomly sample patients or (ii) sample those with the highest predicted number of active chronic conditions within a bin and assign them to the program. The resultant values are then compared with values obtained by simply assigning the aforementioned 1.3% of our sample with (iii) the highest predicted cost or (iv) the highest number of active chronic conditions to the program. For each new algorithm, we show the label on which it was trained (rows) and the concentration of a given outcome of interest (columns) at or above the 97th percentile of predicted risk. Building on these results, we are establishing an ongoing (unpaid) collaboration to convert the results of Table 3 into a better, scaled predictor of multi- dimensional health measures, with the goal of rolling these improvements out in a future round of algorithm development. There were no confidentiality agreements that limited reporting of the work or its results, no material transfer agreements, no oversight in the preparation of this article (besides ethical oversight from the approving IRB, which was based at a non-profit academic health system), and no formal relationship of any kind between any of the authors and the manufacturer."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\Pre-reading material for participants\\shaw.pdf",
      "summary": "Front.Digit.Health3:725088. doi:10.3389/fdgth.2021.725088The Sociotechnical Ethics of Digital Health: A Critique and Extension of Approaches From Bioethics JamesA.Shaw1,2*andJosephDonia1 1InstituteofHealthPolicy,ManagementandEvaluation,Univ ersityofToronto,Toronto,ON,Canada,2Women\u2019sCollege Hospital,Toronto,ON,Canada The widespread adoption of digital technologies raises imp ortant ethical issues in health care and public health. Bioethical appro aches to the assessment of digital health technologies are typically con\ufb01ned to ethic al issues raised by features of thetechnology itself.Wesuggest thatanethicalperspecti vecon\ufb01ned tofunctionsof the technology is insuf\ufb01cient to assess the broader impact of th e adoption of technologies on the care environment and the broader health-related ecos ystem of which it is a part. In this paper we review existing approaches to the bioethics of digital health, and draw on concepts from design ethics and science & technology stud ies (STS) to critique a narrowviewofthebioethicsofdigitalhealth.Wethendescr ibethesociotechnicalsystem produced by digital health technologies when adopted in hea lth care environments, and outline the various considerations that demand attention f or a comprehensive ethical analysisofdigitalhealthtechnologiesinthisbroadpersp ective.Weconcludebyoutlining the importance of social justice for ethical analysis from a sociotechnical perspective. Documented perspectives among patients and the public about t he use of digital technologies within health care systems are generally positi ve (3\u20135), and digital health is viewed at the policy level as a strategy to achieve more e\ufb03cient and co nvenient health care delivery (6,7).TheWorldHealthOrganization(WHO)establishedits\ufb01rst globalstrategyondigitalhealth for the years 2020\u20132025 ( 8), and several guidelines have been produced for the evaluati on and implementation of digital health technologies in practice ( 9\u201311). Despite the persistent challenges inachievingmeaningfulimplementationanduseofdigitalte chnologiesinhealthcare( 12),thereis ageneralsenseofoptimismthatdigitalhealthwillplayanimpor tantandpositiveroleinpromoting healthandimprovinghealthcareintothefuture( 13).Shaw and Donia Sociotechnical Ethics of Digital Health The optimism around the potential of digital health and the commitmenttoadvancingadigitalhealthagendarepresenton ly a partial perspective on the nature and implications of digitall y- enabled health care. We align here with Marent and Henwood who bring four forms of technology-enabled care under the de\ufb01nition of digital health ( 2): telemedicine (synchronous or asynchronous care at a distance), eHealth (searching and exchange of health information), mHealth (use of mobile digi tal devices for health-related reasons) and algorithmic medic ine (incorporatingadvancesindatascienceandarti\ufb01cialintel ligence in health care). THE BIOETHICS OF DIGITAL HEALTH: A CRITIQUE Given the relatively recent emergence of the language of \u201cdigital health\u201d as a way to demarcate the broader collectio n of applications of technologies we place into that category, it is understandable that bioethical analyses of digital he althtechnologieshavebeguntodeveloponlyrecently( 21).However, severalpublicationsexistthathavesoughttoadvanceschol arship and practice on the bioethics of digital health, as the recent growth of interest has generated a community of scholars proposing various approaches to understanding this domain of bioethical inquiry ( 22\u201325). The \ufb01rst type of contribution to the bioethics of digital healthliteraturethatweidentifywerefertoas\u201c applyingethical theory.\u201dInthisbodyofliterature,scholarsadopttheperspective of an existing ethical theory and assess a subset of normativ ely relevant issues in digital health from that perspective ( 21,26). The most common is some form of principlist approach, one thatreliesonaseriesofbioethicalprinciplestoguideasses sment of the ethical implications of any given area of human activit y (23,24,27,28).The\ufb01eldofbioethicsisdominatedbyaprinciplist approach to ethical thinking ( 20,29), and it is therefore not surprising that the bioethics of digital health would also be dominated by such an approach. Harms include issues clo ser to the technology, such as privacy or trust in digital health technologies ( 25,31), and others farther from the technology itself such as the unequal resources available to procure and implement digital health technologies around the world ( 26). First, that the \ufb01eld of bioethics is built on a foundational belief about the existence of moral universals that are essentially free fro m the in\ufb02uence of social, cultural, and political realities in di\ufb00e rent jurisdictions around the world ( 33,36,37). The \ufb01rst two categories of the bioethics of digital health contributions, \u201capplying ethical theory\u201d and \u201ctranslating e thics for practice,\u201d rely on a collection of existing ethical theor ies to address various issues in the \ufb01eld of digital health. However, relying on conventional approaches t o bioethical theory is increasingly understood as problemati c. Critiques of bioethics from the social sciences have clearly illustrated the problems with an assumed universal morality, which as Fox and Swazey have made clear, \u201cis reinforced by the \ufb01eld\u2019s commitment to identifying and fostering universal e thicalprinciples that constitute a \u201ccommon morality\u201d (sometimes referredtoas\u201cthecommonmorality\u201d),describedbyphilosophe rs Tom Beauchamp and James Childress as \u201cthe set of norms that all morally serious persons... in all places... share.\u201d (p. 278) (38).Suchanorientationtowardethicsneglectsthefundamenta l operations of power and culture in shaping moral beliefs ( 39, 40), and ignores the ways in which bioethics is infused with assumptions that reinforce e\ufb00orts to maintain the status quo of existing systems of power ( 37,41,42). The \ufb01nal category of the bioethics of digital health, \u201cidentifying ethical harms,\u201d is subject to a related but distinct critique: that bioethics practitioners tend to acc ept theboundariesplacedaroundethicaldiscoursebyproponentso f agivenatechnology( 34).Thiscritiquehasbeenadvancedclearly by Hedgecoe, who studied the work of bioethicists in the \ufb01eld of pharmacogenetics ( 34). Although we acknowledgethisisanover-simpli\ufb01cationofprivacyandsecur ity as normative issues, the contrast with issues such as digita lly- driven inequities and corporate capture in public health care systemsillustratetheimmensecomplexityofpotentialnormat ive harms that tend to be obscured or avoided in bioethical debat e. In our work, we aim to situate the issues most commonly acknowledgedinbioethicalliteratureondigitalhealthwi thinthe broader context of the social, cultural, and political reali ties that position them as such in the \ufb01rst place. STS is an interdisciplinary \ufb01eld of research that examines th e Frontiers in Digital Health | www.frontiersin.org 3 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health TABLE 1 | Domains of analysis in a sociotechnical approach to digital health ethics. Infrastructures The infrastructure that is required for dig ital health to function, including material realities such as the buildings in which health care providers work when delivering virtual care, the cable s and wires that enable digital signals to travel over distance, a nd the corporate structures of the organizations that make digita l communication availableLack of access to the Internet for people living in rural and remote areas. The term \u201csociotechnical\u201d refers to the observation that issues pertaining to technolo gies such as applications of digital health are never solely about th e material technology itself, but about the mutual dependenci es between technologies and the social arrangements in which they are built and used ( 46,47). By the same token, \u201csocial arrangements\u201d are always infused with various technologie s, ranging from the chairs and whiteboards in design rooms to the smartphone applications and videoconferencing software thatmediatehumaninteractions.Theterm\u201csociotechnical \u201dthus denotes a broadening of focus from the issues de\ufb01ned by a technology itself, to the broader universe of issues opened u p by the recognition that technologies are built and embedded in the social world in ways that profoundly shape and are shaped by humanlife( 48,49). We take the phrase sociotechnical system from the work of Selbst et al. on \u201cfairness and abstraction in sociotechni cal systems\u201d( 47).Intheiranalysis,Selbstetal.outlinehowaseriesof biasesariseinapplicationsofdata-intensivetechnologies notasa result of the technologies themselves, but as a result of the social and material systems in which they are built and embedded. In additiontotheirwork,thetheoreticalprecursorstoouruse ofthe notionofasociotechnicalsystemaremany,butforthepurpose s ofthisanalysis,wecanspecifytwo:infrastructurestudies andthe politicaleconomyofdigitaldata.Infrastructure studies refers to an approach in the \ufb01eld of STS that examines the often neglected material foundations t hat makeeverydaylifepossible( 50,51).Oneconsequenceoffocusing on infrastructure is to uncover the inter-connectedness of the infrastructures on which many activities rely by tracing th eir extension and distance from a given site of analysis. The sociotechnical approach has the e\ufb00ect of introducing a new series of potential ethical harms that requ ire consideration in ethical analyses of technologies, and in s o doing has a higher order impact on our ethical analysis: It Frontiers in Digital Health | www.frontiersin.org 4 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health more explicitly orients our ethical attention to the questio n of what kind of world we hope to bring about through the design and deployment of a given technology. As opposed to simply assessing a range of issues that have been determined at the outset to be ethically relevant, this approach allows on e to pursue a range of issues more distally connected to the technology that might also require ethical attention; inde ed, ethicalanalysisisconsideredincompleteuntilthisbroade rrange of ethical issues is acknowledged, particularly in relation to their consequences for the e\ufb00ort to achieve the sort of world we hope to bring about. The purpose of this framework is simply to provide structure to a sociotechnical ethics approach to digital heal th, whereintheanalystcandevelopasenseofwhereonemightloo k to identify the broader range of ethical issues we have refer red to.Thesedomainsarenotintendedtobecomprehensiveofever y feasible area of ethical relevance, but are intended to repre sent many of the most ethically salient considerations in the eth ical analysis of sociotechnical systems in digital health. Material Devices and Supply Chains The actual material used to build and distribute the devices through which humans interact with digital health technolo gies are often ignored in ethical analyses, but are highly releva nt for a comprehensive perspective on the ethics of digital health. The systems created by such supply chains and the ever-advancing cycle of digital consumption in high-inco me countries deepens the entrenchment of geopolitical relation s, structural racism, and the climate crisis ( 55), reinforcing their ethical relevance in a broad perspective on the ethics of digit al health. Although acknowledging the relevance of the supply chain and the material that makes up the devices required for digital health creates immense challenges for an ethics of digital health, this does not mean they should be excluded fro m ethicalanalysis. A di\ufb00erent example is the in\ufb02uence of technology-mediated communication on the relationship betweenhealthcareproviderandpatient( 61).Althoughtheexact Frontiers in Digital Health | www.frontiersin.org 5 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health implications of digital health and provider-patient relation ships is as yet unclear, the comparison of in-person and digitally- mediatedcareremainsethicallyrelevanttodigitalhealth . The ways in which health-related organizations navigate the transiti on from analog to digital work environments is likely to have substa ntial implications for the nature of health care work and the nature of patient care ( 12,53). TOWARD THE WORLD WE WANT If the \ufb01rst important move of a sociotechnical approach to the ethics of digital health is to broaden the scope of issues under consideration, then the second important move is to focus on world-building. As opposed to a phenomenological notion of world-building, by world-building we mean the distributed contributions to producing a particular sort of world that are made by the practices and institutions that enable the sustained development of a given technology. This understandingofworld-buildingisalignedwithliterature inSTS more broadly that attends to the multiple sites of activity that constitute innovation, and the avenues of inquiry from crit ical political economy approaches that explore whether a particular innovation contributes to the sort of world we hope to bring about(52,66).Thebroaderfocusencouragedbyasociotechnical approach raises awareness of the many ways in which the buildinganddisseminationofatechnologycanimpacttheworl d inethicallyrelevantways.Inourview,theactofattending tosuch a broad range of issues invites a summary understanding of th e kind of world that is being brought about by the consequences of a technology and the ways in whichit is built. In this way, t he summative assessment of a technology from the perspective of a sociotechnical ethics relies on an understanding of the so rt of world it helps to create, who bene\ufb01ts in that world, and who is disadvantaged.Suchanapproachprioritizessocialjustice. When tracing the links in the sociotechnical system, the interconnections b etween communities that are otherwise considered unconnected come into view, and the interdependence between them becomes ethicallysalient.Alignedwithrecentapproachestopubliche alth ethics, such an approach calls for ethical attention to the glob al balance of bene\ufb01ts and burdens in the nested geographies of th e local, the national, and the planetary ( 19). Acting on such an approach requires methods that are familiar to ethically-informed governance in doma ins separatefrombutalliedtobioethics,andwenowturntoconce pts fromanticipatorygovernancetodescribetwoofthesemethod s. Engagement and Foresight for Sociotechnical Ethics A sociotechnical approach to the ethics of digital health resonates strongly with the notion of anticipatory governan ce Frontiers in Digital Health | www.frontiersin.org 6 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health (67). Although a sociotechnical approach to the ethics of digital health has a more modest aim of informing more immediate ethical analyses, it does draw two linked and important insights from anticipatory governance: the respect ive importanceof\u201cengagement\u201dand\u201cforesight.\u201d The \ufb01rst insight drawn from anticipatory governance is the importance of engaging diverse lay publics to provide input into the meaning and desirability of a technology ( 67,68). In relation to a sociotechni cal approach to the ethics of digital health, this is simply about anticipating the potential impacts of the broader range of ethical issues identi\ufb01ed in the various sociotechnical dom ains outlined. The purpose is to anchor decision-making in a cleare r understanding of the kind of world that is encouraged by the digital health technology of focus, and what its consequenc es will be for the inter-connected communities a\ufb00ected by its developmentanddistribution. CONCLUSION The sociotechnical ethics of digital health we propose in this paper is based on a critique of the epistemic and normative foundations of much work done on digital health from within the \ufb01eld of bioethics. Informed by such a critique, we propose a view that draws attention to a much wider range of issues represented by the sociotechnical system implicated by a given digital health technology and the well-being of the many communities connected to it. Frontiers in Digital Health | www.frontiersin.org 7 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health DATA AVAILABILITY STATEMENT The original contributions presented in the study are includ ed in the article/supplementary material, further inquiries ca n be directedtothecorrespondingauthor.AUTHOR CONTRIBUTIONS JS led the drafting of the manuscript."
    }
  ]
}