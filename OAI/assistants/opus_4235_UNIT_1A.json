{
  "CONFIG": {
    "general_instructions": "This project is an AI assistant for a given lesson. The output of each request must be response that guides an student in understanding a topic.  \\n",
    "description": "The Data and AI Intensive Research with Rigor and Reproducibility (DAIR\u00b3) program is funded by Award 5R25GM151182 of the National Institute of General Medical Sciences, one of the 27 institutes of the National Institutes of Health of the United States. The principal investigators are Jing Liu (University of Michigan) and Juan B. Guti\u00e9rrez (University of Texas at San Antonio). \\nThe rigor of scientific research and the reproducibility of research results are essential for the validity of research findings and the trustworthiness of science. However, research rigor and reproducibility remains a significant challenge across scientific fields, especially for research with complex data types from heterogeneous sources, and long data manipulation pipelines. This is especially critical as data science and artificial intelligence (AI) methods emerge at lightning speed and researchers scramble to seize the opportunities that the new methods bring.  \\n\\nWhile researchers recognize the importance of rigor and reproducibility, they often lack the resources and the technical know-how to achieve this consistently in practice. With funding from the National Institutes of Health, a multi-university team offers a nationwide program to equip faculty and technical staff in biomedical sciences with the skills needed to improve the rigor and reproducibility of their research, and help them transfer such skills to their trainees. \\n\\nTrainees will then be guided over a one-year period to incorporate the newly acquired mindset, skills and tools into their research; and develop training for their own institutions.  \\n\\nThe DAIR3 team and instructors include faculty and staff research leaders from the University of Michigan, the College of William and Mary, Jackson State University, and University of Texas San Antonio. This highly diverse team will model the culture of diversity that we promote, and will support trainees who are demographically, professionally and scientifically diverse, and are from a diverse range of institutions, including those with limited resources.",
    "harmonizer_code": "gpt-4o",
    "harmonizer_temperature": 0.1,
    "harmonizer_name": "Harmonizer"
  },
  "MODELS": [
    {
      "model_code": "gpt-4o",
      "model_name": "OpenAI GPT 4o",
      "temperature": 0.15,
      "agent_name": "ALICE AI Agent"
    }
  ],
  "knowledgeBase": [
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Assessment .pdf",
      "summary": "A wearable device that monitors vital signs and uses AI to detect potential health emergencies A. What ethical concerns arise from the use of the technology?"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Discussion.pdf",
      "summary": "Case 1: Predicting population health needs  A research team at your university has developed an AI system that analyzes Electronic Health Records (EHRs) to predict which communities may experience increased healthcare disparities. Your state health department wants to implement the AI system to allocate resources for community health initiatives. How would you apply the sociotechnical ethical framework to evaluate this system beyond the technology itself? [Time permitting] Find a group that chose this or a different scenario. Describe the AI system you have developed, the ethical considerations you identified, and the researchers\u2019 responsibilities. A large pharmaceutical company has approached the university requesting access to both the biospecimens and associated data to develop an AI diagnostic tool using machine learning techniques. [Time permitting] Find a group that chose this or a different scenario. Describe the scenario, the ethical considerations you identified, and the university\u2019s position. [Time permitting] Find a group that chose this or a different scenario. Describe the scenario, the ethical considerations you identified, and how you will address representation and privacy."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\S1_Presentation.pdf",
      "summary": "Determination of a course of action that blends professional knowledge with community values\u201c\u201dToby Citrin, JD, MPH (paraphrase) Session 1 learning objectives \u2022Analyze the sociotechnical system of biomedical data science \u2022Differentiate between traditional bioethical, sociotechnical, and other ethical approaches to data science research and applications\u2022Evaluate key ethical challenges in biomedical data scienceWhat makes data science different? Sociotechnical systems  Source: NIOSH  https://www.cdc.gov/niosh/learning/safetyculturehc/module-1/3.htmlhttps://business.leeds.ac.uk/research-stc/doc/socio-technical-systems-theory Sociotechnical ethics of digital health (Shaw and Donia, 2021)\u2022Domains of analysis\u2022Identify interdependencies \u2022Expand view of technology\u2022Upstream and downstream impacts \u2022Individual and population-level impacts   Sociotechnical ethical analysis Other ethical considerations \u2022Privacy and security \u2022Consent \u2022Group harms \u2022Conflict of interest \u2022Transparency \u2022Trust \u2022Ownership \u2022Engagement / Empowerment \u2022Benefits\u2022Equity \u2022Unintended consequences The case for holistic approaches  Alternatives: Expanding sets of principles\u2022Adaptivity\u2022Flexibility \u2022Inclusiveness\u2022Reflexivity \u2022Responsiveness \u2022MonitoringCaveats \u2022Principles are a first step \u2022Beware of assumptions of equity\u2022Requires time and making time for asking questions \u2022Who is in the room? (n\u2009=\u20091436)\u00a0Public comfort with use of data Summary of findings\u2022Comfort with the use of sensitive data is low for all respondents \u2022Sensitive data defined by policy (e.g., genetic information, mental health) does not match these findings \u2022Trust in health systems (integrity and competency) associated with greater comfort for all three data types \u2022Experiences of discrimination negatively impacts comfort Small group discussionAssessment"
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\Pre-reading material for participants\\obermeyer.pdf",
      "summary": "Dissecting racial bias in an algorithm used to manage the health of populations   Author(s): Ziad Obermeyer, Brian Powers, Christine Vogeli and Sendhil Mullainathan   Source: Science , 25 OCTOBER 2019, Vol. 447-453    Published by: American Association for the Advancement of Science   Stable URL: https://www.jstor.org/stable/10.2307/26843725     REFERENCES  Linked references are available on JSTOR for this article: https://www.jstor.org/stable/10.2307/26843725?seq=1&cid=pdf- reference#references_tab_contents  You may need to log in to JSTOR to access the linked references. Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at https://about.jstor.org/terms American Association for the Advancement of Science  is collaborating with JSTOR to digitize, preserve and  extend access to Science This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsRESEARCH ARTICLES\u25e5 ECONOMICS Dissecting racial bias in an algorithm used to manage the health of populations Ziad Obermeyer1,2*, Brian Powers3, Christine Vogeli4, Sendhil Mullainathan5*\u2020 Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. For example, job search ads for highly paid positions are less likely to be presented to women (4 ), searches for distinctively Black-sounding names are more likely to trigger ads for arrest records (5), and image searches for professions such as CEO produce fewer images of women ( 6). With- out an algorithm \u2019s training data, objective func- tion, and prediction methodology, we can only guess as to the actual mechanisms for the important algorithmic disparities that arise. It is one of the largest and most typical examples of a class of commercial risk-prediction tools that, by industry estimates, are applied to roughly 200 million people in the United States each year. These programs seek to improve the care of patients with complex health needs by providing additional resources, including greater attention from trained providers, to help ensure that care is well coordinated. Because the programs are themselves expensive \u2014with costs going toward teams of dedicated nurses, extra primary care appoint- ment slots, and other scarce resources \u2014health systems rely extensively on algorithms to iden- tify patients who will benefit the most ( 18,19). To solve this problem, health systems make a key assumption: Those with the great- est care needs will benefit the most from the program. It contains both the algorithm \u2019s predic- tions as well as the data needed to understand its inner workings: that is, the underlying in- gredients used to form the algorithm (data, objective function, etc.) Because we have the inputs, outputs, and eventual outcomes, our data allow us a rare opportunity to quantify racial disparities in algorithms and isolate the mechanisms by which they arise. Rather, it is emblematic of a generalized ap- proach to risk prediction in the health sec- tor, widely adopted by a range of for- and non-profit medical centers and governmental agencies ( 21). First, the specific problem solved by this algorithm has analogies in many other sectors: The pre- dicted risk of some future outcome (in our case, health care needs) is widely used to tar- get policy interventions under the assumption that the treatment effect is monotonic in that risk, and the methods used to build the algo- rithm are standard. Second, even beyond our particular finding, we hope that this exercise illustrates the im- portance, and the large opportunity, of study- ing algorithmic bias in health care, not just as a model system but also in its own right. By any standard \u2014e.g., number of lives affected, life-and-death consequences of the decision \u2014 health is one of the most important and wide- spread social sectors in which algorithms are already used at scale today, unbeknownst to many. This approach allowed us to study one particular racial difference of social and historical interest between patients who self-identified as Black and patients who self-identified as White without another race or ethnicity; it has the disadvantage of not allowing for the study of intersectional racialRESEARCH SCIENCE sciencemag.org 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 447 1School of Public Health, University of California, Berkeley, Berkeley, CA, USA.2Department of Emergency Medicine, Brigham and Women \u2019s Hospital, Boston, MA, USA. Our main sample thus consisted of (i) 6079 patients who self-identified as Black and (ii) 43,539 patients who self- identified as White without another race or ethnicity, whom we observed over 11,929 and 88,080 patient-years, respectively (1 patient- year represents data collected for an indivi- dual patient in a calendar year). In the health system we studied, risk scores are generated for each patient during the enrollment period for the system \u2019s care management program. Those above the 55th percentile are referred to their pri- mary care physician, who is provided with contextual data about the patients and asked to consider whether they would benefit from program enrollment. Some definitions focus on calibration [i.e., whether the realized value of some variable of interest Ymatches the risk score R(2,22,23)]; others on statis- t i c a lp a r i t yo fs o m ed e c i s i o n Dinfluenced by the algorithm ( 10); and still others on balance of average predictions, conditional on the real- ized outcome ( 22). Given this multiplicity and the growing recognition that not all condi- tions can be simultaneously satisfied ( 3,10,22), we focus on metrics most relevant to the real- world use of the algorithm, which are related to calibration bias [formally, comparing Blacks Band Whites W,E\u00bdYjR;W/C138\u00bcE\u00bdYjR;B/C138indi- cates the absence of bias (here, Eis the ex- pectation operator)]. The algorithm \u2019s stated goal is to predict complex health needs for the purpose of targeting an intervention that manages those needs. Thus, we compare the algorithmic risk score for patient iin year t (Ri,t), formed on the basis of claims data Xi,(t\u22121) from the prior year, to data on patients \u2019real- ized health Hi,t, assessing how well the algo- rithmic risk score is calibrated across race for health outcomes Hi,t. To measure H, we link predictions to a wide range of outcomes in electronic health record data, including all diagnoses (in the form of International Classification of Diseases codes) as well as key quantitative laboratory studies and vital signs capturing the severity of chro- nic illnesses. These data, and the rationale for the specific measures of H used in this study, are described in more detail in the supplementary materials.Health disparities conditional on risk score We begin by calculating an overall measure of health status, the number of active chronic conditions [or \u201ccomorbidity score, \u201da metric used extensively in medical research ( 24) to provide a comprehensive view of a patient \u2019s health ( 25)] by race, conditional on algorith- mic risk score. We can quantify these differences by choosing one point on the xaxis that corresponds toa very-high-risk group (e.g., patients at the 97th percentile of risk score, at which patients are auto-identified for program enrollment), where Blacks have 26.3% more chronic ill- nesses than Whites (4.8 versus 3.8 distinct conditions; P< 0.001). Specifically, at some risk threshold a, we identify the supramarginal White patient (i ) with Ri>aand compare this patient \u2019s health to that of the inframarginal Black patient ( j) with Rj<a. IfHi>Hj,a sm e a s u r e db yn u m b e r of chronic medical conditions, we replace the (healthier, but supramarginal) White patient with the (sicker, but inframarginal) Black patient. 1B shows the results: At all risk thresholds aabove the 50th percentile, this procedure would increase the fraction of Black patients. For example, at a= 97th percentile, among those auto-identified for the program, the fraction of Black patients would rise from 17.7 to 46.5%. We then turn to a more multidimensional pic- ture of the complexity and severity of patients \u2019 health status, as measured by biomarkers that index the severity of the most common chro- nic illnesses in our sample (as shown in Table 1). (The materials and methods section describes several experiments to rule out a large effect of the program on these health measures in year t; had there been such an effect, we could not easily use the measures to assess the accuracy of the algorithm \u2019s predictions on health, because the program is allocated as a function of algorithm score.) Across all of these impor- tant markers of health needs\u2014 severity of diabe- tes, high blood pressure, renal failure, cholesterol, and anemia \u2014we find that Blacks are substan- tially less healthy than Whites at any level of algorithm predictions, as shown in Fig. The magnitudes of these differences are large: For example, differences in severity of hyper- tension (systolic pressure: 5.7 mmHg) and diabetes [glycated hemoglobin (HbA1c): 0.6%] imply differences in all-cause mortality of 7.6% (27)a n d3 0 %( 28), respectively, calculated using data from clinical trials and longitudinal studies. Mechanism of bias A nu n u s u a la s p e c to fo u rd a t a s e ti st h a tw e observe the algorithm \u2019s inputs and outputsas well as its objective function, providing us a unique window into the mechanisms by which bias arises. In our setting, the algorithm takes in a large set of raw insurance claims data Xi,t\u22121(features) over the year t\u22121: demo- graphics (e.g., age, sex), insurance type, diag- nosis and procedure codes, medications, and detailed costs. As a first check on this potential mechanism of bias, we calculate the distribution of real- ized costs Cversus predicted costs R.B yt h i s metric, one could call the algorithm unbiased. For example, at the med- ian risk score, Black patients had costs of $5147 versus $4995 for Whites (U.S. dollars); in the t o p5 %o fa l g o r i t h m - p r e d i c t e dr i s k ,c o s t sw e r e $35,541 for Blacks versus $34,059 for Whites. SCIENCE sciencemag.org 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 449 Defaulted into programDefaulted into program Referred for screen Referred for screen Percentile of Al gorithm Risk Score Percentile of Al gorithm Risk ScoreFraction BlackNumber of active chronic conditionsRace Black WhiteOriginal SimulatedAB Fig. ( B) Fraction of Black patients at or above a given risk score for the original algorithm ( \u201coriginal \u201d) and for a simulated scenario that removes algorithmic bias ( \u201csimulated \u201d: at each threshold of risk, defined at a given percentile on the xaxis, healthier Whites above the threshold arereplaced with less healthy Blacks below the threshold, until the marginal patient is equally healthy). The dashed vertical lines show the auto-identification threshold (the black line, which denotes the 97th percentile) and the screening threshold (the gray line, which denotes the 55th percentile).RESEARCH |RESEARCH ARTICLES This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsBecause these programs are used to target patients with high costs, these results are large- ly inconsistent with algorithmic bias, as mea- sured by calibration: Conditional on risk score, p r e d i c t i o n sd on o tf a v o rW h i t e so rB l a c k sa n y - where in the risk distribution. On the one hand, this is surprising: Health care costs and health needs are highly correlated, as sicker patients need and receive more care, on average. On the other hand, there are many opportunities for a wedge to creep in between needing health care and receiving health care\u2014 and crucially, we find that wedge to be correlated with race, as shown in Fig. At a given level of health (again measured by number of chronic illnesses), Blacks generate lower costs than Whites \u2014on average, $1801 less per year, holding constant the number of chron- ic illnesses (or $1144 less, if we instead hold constant the specific individual illnesses that contribute to the sum). These results suggest that the driv- ing force behind the bias we detect is that Black patients generate lesser medical ex- penses, conditional on health, even when we account for specific comorbidities. Although the population we study is entirely insured, there are many other mechanisms by which poverty can lead to disparities in use of health care: geography and differential access to trans- portation, competing demands from jobs or child care, or knowledge of reasons to seek care (29\u201331). A recent trial randomly assigned Black patients to a Black or White primary care provider and found significantly higher uptake of recom- mended preventive care when the provider was Black (32). This is perhaps the most rigorous demonstration of this effect, and it fits with a larger literature on potential mechanisms by which race can affect health care directly. For example, it has long been documented that Black patients have reduced trust in the health care system ( 33), a fact that some studies trace to the revelations of the Tuskegee study and other adverse experiences ( 34). Thus, whether it is communi- cation, trust, or bias, something about the inter- actions of Black patients with the health care system itself leads to reduced use of health care. The collective effect of these many channels is t ol o w e rh e a l t hs p e n d i n gs u b s t a n t i a l l yf o rB l a c kpatients, conditional on need \u2014a finding that has been appreciated for at least two decades ( 37). Problem formulation Our findings highlight the importance of the choice of the label on which the algorithm is trained. On the one hand, the algorithm man- ufacturer \u2019s choice to predict future costs is rea- sonable: The program \u2019s goal, at least in part, is 450 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 sciencemag.org SCIENCERace Black White 0.00.10.20.3 Fraction with uncontrolled blood pressureA Hypertension: Fraction clinic visits with SBP >139 mmHg 5.56.06.57.07.5 Mean HbA1c (%)B Diabetes severity: HbA1c 90100110 10 20 30 40 50 60 70 80 90 100Mean LDL (mg/dL)C Bad cholesterol: LDL  \u22120.10.00.10.2Mean creatinine (log mg/dL)D Renal failure: creatinine (log) Referred for screenDefaulted into program Defaulted into programReferred for screenDefaulted into program Referred for screen Defaulted into program Referred for screenDefaulted into program Referred for screen 32.535.037.540.042.545.0 Percentile of Algorithm Risk ScorePercentile of Algorithm Risk Score Percentile of Algorithm Risk ScorePercentile of Algorithm Risk Score Percentile of Algorithm Risk Score Mean Hematocrit (%)E Anemia severity: hematocrit0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100Fig. (Ato E) Racial differences in a range of biological measures of disease severity, conditional on algorithm risk score, for the most common diseases in the population studied. The yaxis in (D) has been trimmed for readability, so the highest percentiles of values for Black patients are not shown. The dashed vertical lines show the auto-identification threshold (black line: 97th percentile) and the screening threshold (gray line: 55th percentile).RESEARCH |RESEARCH ARTICLES This content downloaded from \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000141.211.4.224 on Thu, 01 May 2025 01:04:38 UTC\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 All use subject to https://about.jstor.org/termsto reduce costs, and it stands to reason that patients with the greatest future costs could have the greatest benefit from the program. For example, the Society of Actuaries \u2019s compre- hensive evaluation of the 10 most widely used algorithms, including the particular al- gorithm we study, used cost prediction as its accuracy metric ( 21). As noted in the report, the enthusiasm for cost prediction is not restricted to industry: Similar algorithms are developed and used by non-profit hospitals, academic groups, and governmental agen- cies, and are often described in academic literature on targeting population health interventions ( 18,19). Rather, these programs primar- ily work to prevent acute health decompensa- tions that lead to catastrophic health care utilization (indeed, they actually work to in- crease other categories of costs, such as pri- mary care and home health assistance; see table S2). Alternatively, rather than predicting costs at all, we could simply predict a measure of health; e.g., the number of active chronic health conditions. Because the program ultimately operates to improve the management of these conditions, patients with the most encoun- ters related to them could also be a promis- ing group on which to deploy preventative interventions. The dilemma of which label to choose re- lates to a growing literature on \u201cproblem formu- lation \u201din data science: the task of turning an often amorphous concept we wish to predict into a concrete variable that can be predicted in a given dataset (38 ). Health care costs, though well measured and readily available in insurance claims data, are also the result of a complex aggregation process with a number of distortions due to structural inequality, incentives, and ineffi- ciency. So although the choice of label is perhaps the single most important decision made in the development of a prediction al- gorithm, in our setting and in many others, there is often a confusingly large array of different options, each with its own profile of costs and benefits.Experiments on label choice Through a series of experiments with our data- set, we can gain some insight into how label choice affects both predictive performance and racial bias. We develop three new predictive algorithms, all trained in the same way, to predict the following outcomes: total cost in year t(this tailors cost predictions to our own dataset rather than the national training set), avoidable cost in year t(due to emergency visits and hospitalizations), and health in year t(measured by the number of chronic condi- tions that flare up in that year). Fur- thermore, as with the original algorithm, we exclude race from the feature set (more details are in the materials and methods). The first finding is that all algorithms perform reasonably well for predicting not only the outcome on which they were trained but also the other outcomes: The concentra- tion of realized outcomes in those at or above the 97th percentile is notably similar for all algorithms across all outcomes. The largest difference in performance across algorithms is seen for cost prediction: Of all costs in the holdout set, the fraction generated by those at or above the 97th percentile is 16.5% for the cost predictor versus 12.1% for the predictor SCIENCE sciencemag.org 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 4511,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100 Percentile of Al gorithm Risk ScoreMean Total Medical ExpenditureRace Black White 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100 Chronic IllnessesMean Total Medical ExpenditureRace Black WhiteDefaulted into program Referred for screen 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100Race Black White 1,0003,0008,00020,00060,000 0 1 02 03 04 05 06 07 08 09 0 100Race Black WhiteAB Fig. We then test for label choice bias, defined analogously to calibra- tion bias above: For two algorithms trained to predict YandY', and using a threshold t indexing a (similarly sized) high-risk group, we would test p\u00bdBjR>t/C138\u00bcp\u00bdBjR\u2032>t/C138(here, pdenotes probability and Brepresents Black patients). We find that the racial composition of this highest-risk group varies far more across algo- rithms: The fraction of Black patients at or above these risk levels ranges from 14.1% for the cost predictor to 26.7% for the predictor of chronic conditions. Thus, although there could be many reasonable choices of label \u2014 all predictions are highly correlated, and any could be justified as a measure of patients \u2019 likely benefit from the program \u2014they have markedly different implications in terms of bias, with nearly twofold variation in composi- tion of Black patients in the highest-risk groups. Specifically, for patients at or above a certain level of predicted risk (the 55th per- centile), doctors are presented with contex- tual information from patients \u2019electronic health records and insurance claims and are promp- ted to consider enrolling them in the prog- ram. Table 3 shows statistics on those enrolled in the program, accounting for 1.3% of observa- tions in our sample: The enrolled individuals are 19.2% Black (versus 11.9% Black in our en- tire sample) and account for 2.9% of all costs and 3.3% of all active chronic conditions in the population as a whole. First, we calculate the realized program enrollment rate within each percentile of the original algorithm \u2019s pre-dicted risk bins and randomly sample patients in each bin for enrollment. Second, rather than randomly sampling, we sample those with the highest predicted number of active chronic conditions within a risk bin (using our ex- perimental algorithm described above); this would yield a population that is 26.9% Black. Finally, we compare this to simply assigning those with the highest predicted costs, or the highest number of active chronic conditions, to the program (also using our own algorithms detailed above), which would yield 17.2 and 29.2% Black patients, respectively. Discussion Bias attributable to label choice \u2014the difference between some unobserved optimal prediction and the prediction of an algorithm trained on an observed label \u2014is a useful framework through which to understand bias in algorithms, both 452 25 OCTOBER 2019 \u2022VOL 366 ISSUE 6464 sciencemag.org SCIENCETable 3. For those enrolled in the high-risk care management program (1.3% of our sample), we first show the fraction of the population that is Black, as well as the fraction of all costs and chronic conditions accounted for by these observations. We first calculate the programenrollment rate within each percentile bin of predicted risk from the original algorithm and either (i) randomly sample patients or (ii) sample those with the highest predicted number of active chronic conditions within a bin and assign them to the program. The resultant values are then compared with values obtained by simply assigning the aforementioned 1.3% of our sample with (iii) the highest predicted cost or (iv) the highest number of active chronic conditions to the program. For each new algorithm, we show the label on which it was trained (rows) and the concentration of a given outcome of interest (columns) at or above the 97th percentile of predicted risk. As a first step, we sug- gested using the existing model infrastructure \u2014 sample, predictors (excluding race, as before), training process, and so forth \u2014but changing the label: Rather than future cost, we created an index variable that combined health pre- diction with cost prediction. This approach reduced the number of excess active chronic conditions in Blacks, conditional on risk score, to 7758, an 84% reduction in bias. Building on these results, we are establishing an ongoing (unpaid) collaboration to convert the results of Table 3 into a better, scaled predictor of multi- dimensional health measures, with the goal of rolling these improvements out in a future round of algorithm development. But because the manufacturer of the algorithm we study is widely viewed as an industry leader in data and analytics, we are hopeful that this en- deavor will prompt other manufacturers to implement similar fixes. Rather, we must change the data we feed the algorithm \u2014specifically, the labels we give it. Producing new labels requires deep understanding of the domain, the ability to identify and extract relevant data elements, and the capacity to iterate and experiment. But there is precedent for all of these func- tions in the literature and, more concretely, in the private companies that invest heavily in developing new and improved labels to predict factors such as consumer behavior (45). In addition, although health \u2014as well as criminal justice, employment, and other socially important areas \u2014presents substan- tial challenges to measurement, the impor- tance of these sectors emphasizes the value of investing in such research. Because labels are the key determinant of both predictive quality and predictive bias, careful choice can allow us to enjoy the benefits of algo- rithmic predictions while minimizing their risks. There were no confidentiality agreements that limited reporting of the work or its results, no material transfer agreements, no oversight in the preparation of this article (besides ethical oversight from the approving IRB, which was based at a non-profit academic health system), and no formal relationship of any kind between any of the authors and the manufacturer."
    },
    {
      "file": "C:\\temp\\Units\\UNIT_1A - RCR - Jodyn\\Pre-reading material for participants\\shaw.pdf",
      "summary": "Front.Digit.Health3:725088. doi:10.3389/fdgth.2021.725088The Sociotechnical Ethics of Digital Health: A Critique and Extension of Approaches From Bioethics JamesA.Shaw1,2*andJosephDonia1 1InstituteofHealthPolicy,ManagementandEvaluation,Univ ersityofToronto,Toronto,ON,Canada,2Women\u2019sCollege Hospital,Toronto,ON,Canada The widespread adoption of digital technologies raises imp ortant ethical issues in health care and public health. In this sense, a sociotechnic al system refers to the broadercollectionofmaterialdevices,interpersonalrel ationships,organizationalpolicies, corporate contracts, and government regulations that shap e the ways in which digital health technologies are adopted and used. Bioethical appro aches to the assessment of digital health technologies are typically con\ufb01ned to ethic al issues raised by features of thetechnology itself.Wesuggest thatanethicalperspecti vecon\ufb01ned tofunctionsof the technology is insuf\ufb01cient to assess the broader impact of th e adoption of technologies on the care environment and the broader health-related ecos ystem of which it is a part. In this paper we review existing approaches to the bioethics of digital health, and draw on concepts from design ethics and science & technology stud ies (STS) to critique a narrowviewofthebioethicsofdigitalhealth.Wethendescr ibethesociotechnicalsystem produced by digital health technologies when adopted in hea lth care environments, and outline the various considerations that demand attention f or a comprehensive ethical analysisofdigitalhealthtechnologiesinthisbroadpersp ective.Weconcludebyoutlining the importance of social justice for ethical analysis from a sociotechnical perspective. Documented perspectives among patients and the public about t he use of digital technologies within health care systems are generally positi ve (3\u20135), and digital health is viewed at the policy level as a strategy to achieve more e\ufb03cient and co nvenient health care delivery (6,7).TheWorldHealthOrganization(WHO)establishedits\ufb01rst globalstrategyondigitalhealth for the years 2020\u20132025 ( 8), and several guidelines have been produced for the evaluati on and implementation of digital health technologies in practice ( 9\u201311). Despite the persistent challenges inachievingmeaningfulimplementationanduseofdigitalte chnologiesinhealthcare( 12),thereis ageneralsenseofoptimismthatdigitalhealthwillplayanimpor tantandpositiveroleinpromoting healthandimprovinghealthcareintothefuture( 13).Shaw and Donia Sociotechnical Ethics of Digital Health The optimism around the potential of digital health and the commitmenttoadvancingadigitalhealthagendarepresenton ly a partial perspective on the nature and implications of digitall y- enabled health care. The COVID-19 pandemic raised awareness ofthelargebodyofworkdocumentingthepotentialroleofdig ital technologiesinexacerbatinghealthinequities( 14,15),alongwith issues such as the in\ufb02uence of large technology companies ove r publichealthpolicy( 16).Furthermore,thedistributionofdigital technologies is linked with important changes to the ways in which people view and structure their lives, and these changes aredeeplyconnectedwiththepracticesandinstitutionsofhe alth andhealthcare( 3). These latter observations raise crucial questions about th e many consequences of digital health and the ways in which societies might want digital health to develop into the futu re. These are normative issues connected to imaginaries of the roles that digital health technologies ought to play in promot ing health and delivering health care ( 17,18). However, research and writing on the normative foundations of digital health a nd its implications for health and health care has been limited. Although there are alternative perspectives in the broad \ufb01eld of applied health ethics on which we could focus in our critique, such as public health ethics ( 19), we focus speci\ufb01cally on bioethics because it is the dominant approach to ethical analysis for issues in heal th care and medicine ( 20). Our critique is thus limited to the body of work analyzing digital health from a conventional bioeth ical perspective, but the critiques are relevant for related approac hes to applied ethics outside of health and medicine as well. We align here with Marent and Henwood who bring four forms of technology-enabled care under the de\ufb01nition of digital health ( 2): telemedicine (synchronous or asynchronous care at a distance), eHealth (searching and exchange of health information), mHealth (use of mobile digi tal devices for health-related reasons) and algorithmic medic ine (incorporatingadvancesindatascienceandarti\ufb01cialintel ligence in health care). THE BIOETHICS OF DIGITAL HEALTH: A CRITIQUE Given the relatively recent emergence of the language of \u201cdigital health\u201d as a way to demarcate the broader collectio n of applications of technologies we place into that category, it is understandable that bioethical analyses of digital he althtechnologieshavebeguntodeveloponlyrecently( 21).However, severalpublicationsexistthathavesoughttoadvanceschol arship and practice on the bioethics of digital health, as the recent growth of interest has generated a community of scholars proposing various approaches to understanding this domain of bioethical inquiry ( 22\u201325). The \ufb01rst type of contribution to the bioethics of digital healthliteraturethatweidentifywerefertoas\u201c applyingethical theory.\u201dInthisbodyofliterature,scholarsadopttheperspective of an existing ethical theory and assess a subset of normativ ely relevant issues in digital health from that perspective ( 21,26). The most common is some form of principlist approach, one thatreliesonaseriesofbioethicalprinciplestoguideasses sment of the ethical implications of any given area of human activit y (23,24,27,28).The\ufb01eldofbioethicsisdominatedbyaprinciplist approach to ethical thinking ( 20,29), and it is therefore not surprising that the bioethics of digital health would also be dominated by such an approach. For example, i n a paper on the ethics of digital phenotyping for health-related uses, Mulvenna et al. simply state that \u201cthe four ethical pillar s of medicine are autonomy (right to choice), bene\ufb01cence (doi ng good),non-male\ufb01cence(donoharm),andjustice(equalacces s), and these pillars should not be overlooked when democratizing digital phenotyping\u201d (p. 8) ( 28). Contributions in the \u201capplyin g ethical theory\u201d category have illuminated various dimensi ons of a set of well-de\ufb01ned normative issues in digital health fr om the perspectives of commonly known bioethical theories. \u201d This type of contribution is focused on enhancing the ability of stakeholders in the digital health ecosystem to understand and apply bioethical concepts in meaningful ways. Approaches in this category aim to simplify and specify the implications of bioethical theory for the actual work of building and deploying digital health technologies( 27). Frontiers in Digital Health | www.frontiersin.org 2 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health The \ufb01nal type of contribution that we identify we refer to as \u201cidentifying ethical harms. \u201d Contributions in this category aim to identify and describe the ethically relevant harms or normative issues presented by the domain of digital health. Harms include issues clo ser to the technology, such as privacy or trust in digital health technologies ( 25,31), and others farther from the technology itself such as the unequal resources available to procure and implement digital health technologies around the world ( 26). For example, Vayena et al. specify that where trust is a challenge with digital health technologies, accountabil ity is a strategy to promote trust in the \ufb01eld of digital health over th e longer term. The three approaches summarized here have each made important contributions to the global discussion on the ethi cal challenges presented by digital health technologies and pote ntial strategies to address them. However, th ey aresubjecttoimportantcritiquesthatinformourownapproach to understanding digital health ethics, based on the critiq ue of bioethics as a \ufb01eld of research and practice ( 20,33\u201335). First, that the \ufb01eld of bioethics is built on a foundational belief about the existence of moral universals that are essentially free fro m the in\ufb02uence of social, cultural, and political realities in di\ufb00e rent jurisdictions around the world ( 33,36,37). And second, that the common practice in bioethics is to accept the boundaries around a given advancement in health or medical technology that are established by the clinical or technological stake holders supporting its implementation ( 34,35). The \ufb01rst two categories of the bioethics of digital health contributions, \u201capplying ethical theory\u201d and \u201ctranslating e thics for practice,\u201d rely on a collection of existing ethical theor ies to address various issues in the \ufb01eld of digital health. Thes e contributions rarely if ever include a detailed justi\ufb01cati on of the particular ethical approach taken in the analysis, and nor could they; an applied ethics paper is fundamentally not about the philosophical or theoretical justi\ufb01cation of a particular eth ical theory itself. However, relying on conventional approaches t o bioethical theory is increasingly understood as problemati c. Critiques of bioethics from the social sciences have clearly illustrated the problems with an assumed universal morality, which as Fox and Swazey have made clear, \u201cis reinforced by the \ufb01eld\u2019s commitment to identifying and fostering universal e thicalprinciples that constitute a \u201ccommon morality\u201d (sometimes referredtoas\u201cthecommonmorality\u201d),describedbyphilosophe rs Tom Beauchamp and James Childress as \u201cthe set of norms that all morally serious persons... in all places... share.\u201d (p. 278) (38).Suchanorientationtowardethicsneglectsthefundamenta l operations of power and culture in shaping moral beliefs ( 39, 40), and ignores the ways in which bioethics is infused with assumptions that reinforce e\ufb00orts to maintain the status quo of existing systems of power ( 37,41,42). The \ufb01nal category of the bioethics of digital health, \u201cidentifying ethical harms,\u201d is subject to a related but distinct critique: that bioethics practitioners tend to acc ept theboundariesplacedaroundethicaldiscoursebyproponentso f agivenatechnology( 34).Thiscritiquehasbeenadvancedclearly by Hedgecoe, who studied the work of bioethicists in the \ufb01eld of pharmacogenetics ( 34). Challenges such as privacy and security can be cast as technical challenges, and it is in the interest of technol ogy developers and other supporters of digital health to keep attention focused on technical challenges that can be conta ined and addressed using technical approaches ( 34). Although we acknowledgethisisanover-simpli\ufb01cationofprivacyandsecur ity as normative issues, the contrast with issues such as digita lly- driven inequities and corporate capture in public health care systemsillustratetheimmensecomplexityofpotentialnormat ive harms that tend to be obscured or avoided in bioethical debat e. In our work, we aim to situate the issues most commonly acknowledgedinbioethicalliteratureondigitalhealthwi thinthe broader context of the social, cultural, and political reali ties that position them as such in the \ufb01rst place. TOWARD A SOCIOTECHNICAL ETHICS OF DIGITAL HEALTH The sociotechnical approach to the ethics of digital health we propose in our paper arises directly from work in STS. STS is an interdisciplinary \ufb01eld of research that examines th e Frontiers in Digital Health | www.frontiersin.org 3 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health TABLE 1 | Domains of analysis in a sociotechnical approach to digital health ethics. Domain of analysis Brief description Example ethical issue Application Software The lines of code that constitute a giv en digital health technology and the health-related practices they compel and discourag eAlgorithms that perform with lesser degrees of accuracy for structurally marginalized communities. Material devices and supply chains The actual material used to build and distribute the devices through which humans interact with digital health technolo giesThe negative environmental effects of mining for materials to build digital devices. Infrastructures The infrastructure that is required for dig ital health to function, including material realities such as the buildings in which health care providers work when delivering virtual care, the cable s and wires that enable digital signals to travel over distance, a nd the corporate structures of the organizations that make digita l communication availableLack of access to the Internet for people living in rural and remote areas. Individual health-related practices The activities and rou tines that are compelled by the use of digital health technologiesAdverse mental health implications of continual health-related surveillance. Interpersonal relationships Digital health technologies h ave the capacity to impact interpersonal relationships, through shaping the sources of information, expectations, and modes of interaction avail able to peopleNegative impacts on interpersonal relationships as a result of health-related misinformation shared on social media. Organizational policies The structure, function and routi nes that characterize organizations, and the ways in which these are formalized in organizational rules and policiesThe institution of corporate surveillance on staff. Government policy and regulatory capture The rules and appr oaches to governance put in place by state actors, and the in\ufb02uence of digital health stakeholders such as large technology corporations over health-related govern ment policyThe growth in in\ufb02uence of large corporate technology companies over health-related policy. The term \u201csociotechnical\u201d refers to the observation that issues pertaining to technolo gies such as applications of digital health are never solely about th e material technology itself, but about the mutual dependenci es between technologies and the social arrangements in which they are built and used ( 46,47). By the same token, \u201csocial arrangements\u201d are always infused with various technologie s, ranging from the chairs and whiteboards in design rooms to the smartphone applications and videoconferencing software thatmediatehumaninteractions.Theterm\u201csociotechnical \u201dthus denotes a broadening of focus from the issues de\ufb01ned by a technology itself, to the broader universe of issues opened u p by the recognition that technologies are built and embedded in the social world in ways that profoundly shape and are shaped by humanlife( 48,49). We take the phrase sociotechnical system from the work of Selbst et al. on \u201cfairness and abstraction in sociotechni cal systems\u201d( 47).Intheiranalysis,Selbstetal.outlinehowaseriesof biasesariseinapplicationsofdata-intensivetechnologies notasa result of the technologies themselves, but as a result of the social and material systems in which they are built and embedded. In additiontotheirwork,thetheoreticalprecursorstoouruse ofthe notionofasociotechnicalsystemaremany,butforthepurpose s ofthisanalysis,wecanspecifytwo:infrastructurestudies andthe politicaleconomyofdigitaldata.Infrastructure studies refers to an approach in the \ufb01eld of STS that examines the often neglected material foundations t hat makeeverydaylifepossible( 50,51).Oneconsequenceoffocusing on infrastructure is to uncover the inter-connectedness of the infrastructures on which many activities rely by tracing th eir extension and distance from a given site of analysis. In a related vein, work on the political economy of digital datahasoutlinedthetypicallyhiddenincentivesthatchara cterize the collection, manipulation, and use of data for digital heal th technologies. In her introduction to a special issue on the to pic, Prainsackoutlinedhowstudiesofthepoliticaleconomyofdi gital data encourage attention to the institutions that govern an d enableparticularactorstogeneratevaluefromdata( 52).Suchan approachurgesattentiontotheworkingsofpowerinaglobalized capitalist economy that makes demands of local institutions to go along with the most recent capitalist trends. In this way, w e also attend to these broader \ufb02ows of power that shape the \ufb01eld of digital health, and encourage attention to them as importa nt normativeissues. The broadening of perspective from the technology to the sociotechnical system raises attention to potential ethica l issues that might have been overlooked from a technology-focused perspective. The sociotechnical approach has the e\ufb00ect of introducing a new series of potential ethical harms that requ ire consideration in ethical analyses of technologies, and in s o doing has a higher order impact on our ethical analysis: It Frontiers in Digital Health | www.frontiersin.org 4 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health more explicitly orients our ethical attention to the questio n of what kind of world we hope to bring about through the design and deployment of a given technology. As opposed to simply assessing a range of issues that have been determined at the outset to be ethically relevant, this approach allows on e to pursue a range of issues more distally connected to the technology that might also require ethical attention; inde ed, ethicalanalysisisconsideredincompleteuntilthisbroade rrange of ethical issues is acknowledged, particularly in relation to their consequences for the e\ufb00ort to achieve the sort of world we hope to bring about. For example, in beginning with the design of a digitalhealthtechnology,one mightendup analyzingthepoli cy framework in a given jurisdiction related to the presence of f or- pro\ufb01t technology corporations in\ufb02uencing health policy ( 53). Thehealthpolicyquestioninthisscenariomighthaveimporta nt implications for the structure of the health system as a public good, and therefore play an important role in the overarching ethicalanalysisrelatedtotheworldwehopetoachieve. The purpose of this framework is simply to provide structure to a sociotechnical ethics approach to digital heal th, whereintheanalystcandevelopasenseofwhereonemightloo k to identify the broader range of ethical issues we have refer red to.Thesedomainsarenotintendedtobecomprehensiveofever y feasible area of ethical relevance, but are intended to repre sent many of the most ethically salient considerations in the eth ical analysis of sociotechnical systems in digital health. Much work has been done on the topic of the ethics of health-related arti\ufb01cial intell igence (AI) applications, related to the algorithms that determine t he functioning of a particular digital health technology ( 30,32). Although considerations such as transparency and fairness i n the algorithms themselves are certainly important, it is als o crucial to acknowledge that the ethical salience of these is sues is closely linked with the broader systems of which they are a part (47). Material Devices and Supply Chains The actual material used to build and distribute the devices through which humans interact with digital health technolo gies are often ignored in ethical analyses, but are highly releva nt for a comprehensive perspective on the ethics of digital health. The systems created by such supply chains and the ever-advancing cycle of digital consumption in high-inco me countries deepens the entrenchment of geopolitical relation s, structural racism, and the climate crisis ( 55), reinforcing their ethical relevance in a broad perspective on the ethics of digit al health. Although acknowledging the relevance of the supply chain and the material that makes up the devices required for digital health creates immense challenges for an ethics of digital health, this does not mean they should be excluded fro m ethicalanalysis. These infrastructures include the buildings in which healt h care providers work when delivering virtual care, the cables and wires that enable digital signals to travel over distance , and the corporate structures of the organizations that make digital communication available ( 56,57). Although the consequences of such self-policing can include enhanced hea lth and prevented illness, there are broader questions to be posed regarding the power of self-tracking and \u201cnudge\u201d technologi es to shape and constrain human behavior ( 58). A di\ufb00erent example is the in\ufb02uence of technology-mediated communication on the relationship betweenhealthcareproviderandpatient( 61).Althoughtheexact Frontiers in Digital Health | www.frontiersin.org 5 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health implications of digital health and provider-patient relation ships is as yet unclear, the comparison of in-person and digitally- mediatedcareremainsethicallyrelevanttodigitalhealth . Organizational Policies Digital technologies have the potential to dramatically res hape everyday work practices, and therefore to also reshape the structure and function of organizations ( 62). The ways in which health-related organizations navigate the transiti on from analog to digital work environments is likely to have substa ntial implications for the nature of health care work and the nature of patient care ( 12,53). The ways in which health care systems operateisverymuchinthepublicinterest,broadeningtheran ge of ethical issues deemed relevant to the ethical analysis of d igital health.Oneimportantpointworthmentioninghereistheimpact of organizations such as insurance companies that use digita l health technologies to collect information about individu al behaviors and shape their product o\ufb00erings accordingly ( 63). Government Policy and Regulatory Capture In the context of the growing corporate investment in collecting and analyzing large amounts of health-related d ata, government regulations become extremely important. However, the rapid advancement of digital health technologies and the corporat e practices of the organizations developing them pose important problems even for the GDPR. For example, Marelli et al. outline a series of practices in digital health that are not e\ufb00ectively addressed by the GDPR, including the growing in\ufb02uence of new corporate actors, creating stronger links between healt h careandlifestyle,increasingrelianceonpredictiveanalyt ics,and socialsortingtoplacetechnologyusersintodistinctgroups (64). Beyondthecapacityofexistingpolicytocovercurrentcorpora te digitalhealthpracticesisthegrowingin\ufb02uenceofsuchcorpo rate actors over the strategy and operations of health care system s. The increasing movement of for-pro\ufb01t technology corporation s into the digital health \ufb01eld highlights the urgent need for e thical attentiontothecon\ufb02ictingmotivationsoftechnologycompa nies andhealthcaresystems( 16,65). These domains in which ethically salient harms might be identi\ufb01ed in a sociotechnical approach to digital health ethics represent a departure from the more limited perspective conventionally associated with the \ufb01eld of bioethics ( 34,35). A sociotechnicalapproachencouragestheethicalanalysttoeng age in the work necessary to develop a clearer understanding of t he ethical issues presented by a given application of digital heal th in these various domains. Such an e\ufb00ort might require a review of social science literature on these topics, or new empirical research to uncover the implications of a particular technolo gy and the ways in which it is produced and distributed. However,after the potential harms of such a technology are identi\ufb01ed and understood, what would be the approach to adjudicating between those harms and the purported bene\ufb01ts to arriving at a meaningful ethical conclusion? TOWARD THE WORLD WE WANT If the \ufb01rst important move of a sociotechnical approach to the ethics of digital health is to broaden the scope of issues under consideration, then the second important move is to focus on world-building. As opposed to a phenomenological notion of world-building, by world-building we mean the distributed contributions to producing a particular sort of world that are made by the practices and institutions that enable the sustained development of a given technology. This understandingofworld-buildingisalignedwithliterature inSTS more broadly that attends to the multiple sites of activity that constitute innovation, and the avenues of inquiry from crit ical political economy approaches that explore whether a particular innovation contributes to the sort of world we hope to bring about(52,66).Thebroaderfocusencouragedbyasociotechnical approach raises awareness of the many ways in which the buildinganddisseminationofatechnologycanimpacttheworl d inethicallyrelevantways.Inourview,theactofattending tosuch a broad range of issues invites a summary understanding of th e kind of world that is being brought about by the consequences of a technology and the ways in whichit is built. In this way, t he summative assessment of a technology from the perspective of a sociotechnical ethics relies on an understanding of the so rt of world it helps to create, who bene\ufb01ts in that world, and who is disadvantaged.Suchanapproachprioritizessocialjustice. Broadening one\u2019s ethical perspective to the many elements of a sociotechnical system has the e\ufb00ect of broadening ones understanding of its normative implications. When tracing the links in the sociotechnical system, the interconnections b etween communities that are otherwise considered unconnected come into view, and the interdependence between them becomes ethicallysalient.Alignedwithrecentapproachestopubliche alth ethics, such an approach calls for ethical attention to the glob al balance of bene\ufb01ts and burdens in the nested geographies of th e local, the national, and the planetary ( 19). It is this attention to social justice, motivated by commitment to solidarity with the many inter-connected communities a\ufb00ected by a given digital health technology, that characterizes a sociotechnical et hics of digital health. Acting on such an approach requires methods that are familiar to ethically-informed governance in doma ins separatefrombutalliedtobioethics,andwenowturntoconce pts fromanticipatorygovernancetodescribetwoofthesemethod s. Engagement and Foresight for Sociotechnical Ethics A sociotechnical approach to the ethics of digital health resonates strongly with the notion of anticipatory governan ce Frontiers in Digital Health | www.frontiersin.org 6 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health (67). Although a sociotechnical approach to the ethics of digital health has a more modest aim of informing more immediate ethical analyses, it does draw two linked and important insights from anticipatory governance: the respect ive importanceof\u201cengagement\u201dand\u201cforesight.\u201d The \ufb01rst insight drawn from anticipatory governance is the importance of engaging diverse lay publics to provide input into the meaning and desirability of a technology ( 67,68). Engagement in this way is intended to ensure tha t under-represented views in innovation, policy, and technolo gy are brought to the discussion and have bearing on the ways in which ethical issues are framed. In relation to a sociotechni cal approach to the ethics of digital health, this is simply about anticipating the potential impacts of the broader range of ethical issues identi\ufb01ed in the various sociotechnical dom ains outlined. The purpose is to anchor decision-making in a cleare r understanding of the kind of world that is encouraged by the digital health technology of focus, and what its consequenc es will be for the inter-connected communities a\ufb00ected by its developmentanddistribution. The approach articulated here relies on both the engagement of diverse perspectives and the articulation of a future that i s more desirable than the present. It is one that intend s to analyze the normative viewpoints of various contributors in relation to the implications of a particular technology, an d then to assess their implications for the future. The practical implications of the approach we articulate here for health system and organizational leaders relate to the two practical insights just outlined. When health system sare intending to adopt new technologies, they can engage in a systematic process of community engagement to establish a process and governance approach that is meaningful and acceptable to diverse publics. Building on the insights of diverse community engagement, such potential negative consequences extend beyond the implications for clinicians who use the technology to the altered roles of administrative sta\ufb00, leaders, patients, and other stakehold ers who contribute to building, distributing, and managing thetechnology. Although this is an emergin g space, speci\ufb01c consultation on the ethics of digital health technologieswillbecomeincreasinglyimportantasdigitalh ealth plays a more prominent role in health systems around the world. The broader view we articulate in this paper, and the practical implications we introduce here, help to promote the sustainable and ethical adoption of digital health technolo gies intothefuture. CONCLUSION The sociotechnical ethics of digital health we propose in this paper is based on a critique of the epistemic and normative foundations of much work done on digital health from within the \ufb01eld of bioethics. Informed by such a critique, we propose a view that draws attention to a much wider range of issues represented by the sociotechnical system implicated by a given digital health technology and the well-being of the many communities connected to it. When normative concern is directed to the well-being of these many communities, the value of solidarity and a commitment to social justice become more prominent in ethical analysis. The view we outline in this paper carries forward a position that it is not only the technology itself that requires ethica l attention, but also the world into which it is implemented and that it, in turn, creates. The digital health ethics community will need to engage with this basic insight in determining the most appropriate strategies for the ethical analysis of emerging technologies in health care and publichealth. Frontiers in Digital Health | www.frontiersin.org 7 September 2021 | Volume 3 | Article 725088Shaw and Donia Sociotechnical Ethics of Digital Health DATA AVAILABILITY STATEMENT The original contributions presented in the study are includ ed in the article/supplementary material, further inquiries ca n be directedtothecorrespondingauthor.AUTHOR CONTRIBUTIONS JS led the drafting of the manuscript. Understanding digital health: productive t ensions at the intersection of sociology of health and science and techno logy studies. Cham: Springer (2016).doi:10.1007/978-3-319-23282-9 Con\ufb02ict of Interest: The authors declare that the research was conducted in the absence of any commercial or \ufb01nancial relationships that could be c onstrued as a potentialcon\ufb02ictofinterest. The use, distribution or reproduction in other forums is permitted, p rovided the original author(s) and the copyright owner(s) are credited and that th e original publication in this journal is cited, in accordance with accepted academ ic practice."
    }
  ]
}